<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">
<link rel="preconnect" href="https://fonts.googleapis.com" crossorigin>
<link rel="preconnect" href="https://cdnjs.cloudflare.com" crossorigin>
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32.ico">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16.ico">
  <link rel="mask-icon" href="/images/avatar.jpeg" color="#222">
  <meta name="google-site-verification" content="d2tAnXrr34Y8JpdeBBtXb3s6KJuDmbZk7Kq1mlFW3qs">

<link rel="stylesheet" href="/css/main.css">

<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&display=swap&subset=latin,latin-ext">

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.1/css/all.min.css" integrity="sha256-wiz7ZSCn/btzhjKDQBms9Hx4sSeUYsDrTLg7roPstac=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-minimal.css">
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script>

<script class="next-config" data-name="main" type="application/json">{"hostname":"vnicl.github.io","root":"/","images":"/images","scheme":"Mist","darkmode":false,"version":"8.19.2","exturl":true,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":true,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":true,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"path":"/search.xml","localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":true,"preload":false}}</script><script src="/js/config.js"></script>

    <meta name="description" content="在机器学习算法中，算法的实现过程固然重要，但是作为算法训练的输入也决定算法好坏和算法预测结果准确性的重要因素。我们知道作为机器学习算法的输入是训练样本集，训练样本集中包含很多样本，并且每个样本都会有很多的特征作为机器学习算法的计算依据，所以在样本特征的选取和处理也显得格外重要。   特征工程（Feature Engineering）需要解决的问题就是将传统的数据内容处理为对算法有用的特征内容，">
<meta property="og:type" content="article">
<meta property="og:title" content="机器学习中的特征工程">
<meta property="og:url" content="https://vnicl.github.io/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/index.html">
<meta property="og:site_name" content="攻城狮也文艺">
<meta property="og:description" content="在机器学习算法中，算法的实现过程固然重要，但是作为算法训练的输入也决定算法好坏和算法预测结果准确性的重要因素。我们知道作为机器学习算法的输入是训练样本集，训练样本集中包含很多样本，并且每个样本都会有很多的特征作为机器学习算法的计算依据，所以在样本特征的选取和处理也显得格外重要。   特征工程（Feature Engineering）需要解决的问题就是将传统的数据内容处理为对算法有用的特征内容，">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2017-06-13T07:03:37.000Z">
<meta property="article:modified_time" content="2017-07-13T02:29:00.000Z">
<meta property="article:author" content="Iceberg">
<meta property="article:tag" content="TF-IDF">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://vnicl.github.io/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":false,"isPost":true,"lang":"zh-CN","comments":true,"permalink":"https://vnicl.github.io/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/","path":"2017/06/13/机器学习中的特征工程/","title":"机器学习中的特征工程"}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>机器学习中的特征工程 | 攻城狮也文艺</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <p class="site-title">攻城狮也文艺</p>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">渺小但执着</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="搜索" role="button">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签</a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>站点地图</a></li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup"><div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off" maxlength="80"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close" role="button">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div class="search-result-container no-result">
  <div class="search-result-icon">
    <i class="fa fa-spinner fa-pulse fa-5x"></i>
  </div>
</div>

    </div>
  </div>

</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-nav-active sidebar-toc-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
            <div class="post-toc animated"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E8%AF%8D"><span class="nav-number">1.</span> <span class="nav-text">分词</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-Mllib%E4%B8%AD%E5%AE%9E%E7%8E%B0"><span class="nav-number">1.1.</span> <span class="nav-text">Spark Mllib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%81%9C%E7%94%A8%E8%AF%8D%E8%BF%87%E6%BB%A4"><span class="nav-number">2.</span> <span class="nav-text">停用词过滤</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0"><span class="nav-number">2.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TF-IDF"><span class="nav-number">3.</span> <span class="nav-text">TF-IDF</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TF"><span class="nav-number">3.1.</span> <span class="nav-text">TF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#IDF"><span class="nav-number">3.2.</span> <span class="nav-text">IDF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#TF-IDF-1"><span class="nav-number">3.3.</span> <span class="nav-text">TF-IDF</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-1"><span class="nav-number">3.4.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Word2Vec"><span class="nav-number">4.</span> <span class="nav-text">Word2Vec</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-2"><span class="nav-number">4.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#N-Gram%EF%BC%88N%E5%85%83%E6%A8%A1%E5%9E%8B%EF%BC%89"><span class="nav-number">5.</span> <span class="nav-text">N-Gram（N元模型）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-3"><span class="nav-number">5.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E4%BA%8C%E5%80%BC%E5%8C%96%EF%BC%88Binarizer%EF%BC%89"><span class="nav-number">6.</span> <span class="nav-text">二值化（Binarizer）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-4"><span class="nav-number">6.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PCA%EF%BC%88%E4%B8%BB%E5%85%83%E5%88%86%E6%9E%90%EF%BC%89"><span class="nav-number">7.</span> <span class="nav-text">PCA（主元分析）</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-5"><span class="nav-number">7.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%A4%9A%E9%A1%B9%E5%BC%8F%E6%89%A9%E5%B1%95"><span class="nav-number">8.</span> <span class="nav-text">多项式扩展</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-6"><span class="nav-number">8.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DCT"><span class="nav-number">9.</span> <span class="nav-text">DCT</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-7"><span class="nav-number">9.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%B4%A2%E5%BC%95%E5%8F%98%E6%8D%A2"><span class="nav-number">10.</span> <span class="nav-text">索引变换</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-8"><span class="nav-number">10.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%8B%AC%E7%83%AD%E7%BC%96%E7%A0%81"><span class="nav-number">11.</span> <span class="nav-text">独热编码</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-9"><span class="nav-number">11.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E7%B1%BB%E5%9E%8B%E7%B4%A2%E5%BC%95%E5%8C%96"><span class="nav-number">12.</span> <span class="nav-text">向量类型索引化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-10"><span class="nav-number">12.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%9B%B8%E4%BA%92%E4%BD%9C%E7%94%A8"><span class="nav-number">13.</span> <span class="nav-text">相互作用</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-11"><span class="nav-number">13.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%B3%9B%E6%95%B0p-norm%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-number">14.</span> <span class="nav-text">泛数p-norm规范化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-12"><span class="nav-number">14.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#z-score%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-number">15.</span> <span class="nav-text">z-score规范化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-13"><span class="nav-number">15.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E6%9C%80%E5%A4%A7-%E6%9C%80%E5%B0%8F%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-number">16.</span> <span class="nav-text">最大-最小规范化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-14"><span class="nav-number">16.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E7%BB%9D%E5%AF%B9%E5%80%BC%E8%A7%84%E8%8C%83%E5%8C%96"><span class="nav-number">17.</span> <span class="nav-text">绝对值规范化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-15"><span class="nav-number">17.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%88%86%E7%AE%B1%E5%99%A8"><span class="nav-number">18.</span> <span class="nav-text">分箱器</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Spark-MLlib%E4%B8%AD%E5%AE%9E%E7%8E%B0-16"><span class="nav-number">18.1.</span> <span class="nav-text">Spark MLlib中实现</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Hadamard%E4%B9%98%E7%A7%AF"><span class="nav-number">19.</span> <span class="nav-text">Hadamard乘积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%90%91%E9%87%8F%E5%88%87%E7%89%87%E6%9C%BA"><span class="nav-number">20.</span> <span class="nav-text">向量切片机</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#R%E6%A8%A1%E5%9E%8B%E5%85%AC%E5%BC%8F"><span class="nav-number">21.</span> <span class="nav-text">R模型公式</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%8D%A1%E6%96%B9%E7%89%B9%E5%BE%81%E9%80%89%E6%8B%A9%E5%99%A8"><span class="nav-number">22.</span> <span class="nav-text">卡方特征选择器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%B1%80%E9%83%A8%E6%95%8F%E6%84%9F%E5%93%88%E5%B8%8C"><span class="nav-number">23.</span> <span class="nav-text">局部敏感哈希</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LSH%E8%BF%90%E7%AE%97"><span class="nav-number">24.</span> <span class="nav-text">LSH运算</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#LSH%E7%AE%97%E6%B3%95"><span class="nav-number">25.</span> <span class="nav-text">LSH算法</span></a></li></ol></div>
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="Iceberg"
      src="/images/avatar.jpeg">
  <p class="site-author-name" itemprop="name">Iceberg</p>
  <div class="site-description" itemprop="description">一个理想主义者 · 空想家 · LOSER</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">30</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">10</span>
        <span class="site-state-item-name">分类</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">33</span>
        <span class="site-state-item-name">标签</span></a>
      </div>
  </nav>
</div>
  <div class="cc-license animated" itemprop="license">
    <span class="exturl cc-opacity" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLW5kLzQuMC9kZWVkLnpoLWhhbnM="><img src="https://cdnjs.cloudflare.com/ajax/libs/creativecommons-vocabulary/2020.11.3/assets/license_badges/small/by_nc_nd.svg" alt="Creative Commons"></span>
  </div>

        </div>
      </div>
    </div>

    
        <div class="pjax">
        <div class="sidebar-inner sidebar-post-related">
          <div class="animated">
              <div class="links-of-blogroll-title"><i class="fa fa-signs-post fa-fw"></i>
    相关文章
  </div>
  <ul class="popular-posts">
    <li class="popular-posts-item">
      <a class="popular-posts-link" href="/2017/06/02/Spark%E6%A6%82%E8%BF%B0/" rel="bookmark">
        <time class="popular-posts-time">2017-06-02</time>
        <br>
      Spark概述
      </a>
    </li>
  </ul>

          </div>
        </div>
        </div>
  </aside>


    </div>

    <div class="main-inner post posts-expand">


  


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="https://vnicl.github.io/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.jpeg">
      <meta itemprop="name" content="Iceberg">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="攻城狮也文艺">
      <meta itemprop="description" content="一个理想主义者 · 空想家 · LOSER">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="机器学习中的特征工程 | 攻城狮也文艺">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          机器学习中的特征工程
        </h1>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">发表于</span>

      <time title="创建时间：2017-06-13 15:03:37" itemprop="dateCreated datePublished" datetime="2017-06-13T15:03:37+08:00">2017-06-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">更新于</span>
      <time title="修改时间：2017-07-13 10:29:00" itemprop="dateModified" datetime="2017-07-13T10:29:00+08:00">2017-07-13</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-folder"></i>
      </span>
      <span class="post-meta-item-text">分类于</span>
        <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
          <a href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/" itemprop="url" rel="index"><span itemprop="name">大数据</span></a>
        </span>
    </span>

  
    <span class="post-meta-item" title="本文字数">
      <span class="post-meta-item-icon">
        <i class="far fa-file-word"></i>
      </span>
      <span class="post-meta-item-text">本文字数：</span>
      <span>5.2k</span>
    </span>
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody"><p>  在机器学习算法中，算法的实现过程固然重要，但是作为算法训练的输入也决定算法好坏和算法预测结果准确性的重要因素。我们知道作为机器学习算法的输入是训练样本集，训练样本集中包含很多样本，并且每个样本都会有很多的特征作为机器学习算法的计算依据，所以在样本特征的选取和处理也显得格外重要。</p>
<p>  特征工程（Feature Engineering）需要解决的问题就是将传统的数据内容处理为对算法有用的特征内容，包括文档的切词、值的二值化、分箱／分区、进行离散化等处理方式，本文重点介绍在机器学习领域常见的一些特征处理，包括特征的提取、转化和选择。</p>
<p>  在进行机器学习算法训练前的特征选择时，我们需要尽可能的考虑业务规则，即基于业务的理解去选择是否使用一个特征进行机器学习算法的训练，因为在算法训练的过程中，我们除了需要考虑算法的准确性外还应该考虑算法的训练和计算性能，如果选择一个无关的特征可能会对算法结果有影响和影响算法性能。此外在特征选择时我们还应该考虑特征在算法训练样本集中的覆盖率、准确率、信息量评估、差别性评估等，如果我们打算使用的特征需要及时去获取，那么我们还应该考虑该特征的获取难度，即对选择特征的可用性评估，我们不能捡了芝麻而丢了西瓜啊。</p>
<p>  接下来我们要做的就是进行特征的处理，包括数据的清洗和数据的预处理，根据我们选择的算法模型进行特征的处理工作，使特征更适合我们选择的算法模型。下面介绍几种常见的特征处理方式和实现方案：</p>
<h2 id="分词"><a href="#分词" class="headerlink" title="分词"></a>分词</h2><hr>
<p>  分词是机器学习算法中简单常用的操作，例如将文档样本生成向量特征的时候经常会使用分词器进行文档的分词切割，常用的方法就是以空格作为分隔符将文档分隔成单词群。</p>
<h3 id="Spark-Mllib中实现"><a href="#Spark-Mllib中实现" class="headerlink" title="Spark Mllib中实现"></a>Spark Mllib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkTokenizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkTokenizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 Tokenizer 分词器以空格作为分隔符分隔文档</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 RegexTokenizer 分词器分词</span></span><br><span class="line"><span class="comment">         * 可以使用正则表达式的方式作为分隔符</span></span><br><span class="line"><span class="comment">         * 当设置 gaps 参数为 false 时正则表达式作用为提取关键词</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">RegexTokenizer</span> <span class="variable">regexTokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexTokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                <span class="comment">//设置 gaps 参数</span></span><br><span class="line">                .setGaps(<span class="literal">false</span>)</span><br><span class="line">                .setPattern(<span class="string">&quot;\\\\W&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        wordsDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="停用词过滤"><a href="#停用词过滤" class="headerlink" title="停用词过滤"></a>停用词过滤</h2><hr>
<p>  停用词是在进行分词的时候去除一些在文档中频繁出现，但是未携带太多意义的词语，因为这些没意义的单词不应该参与算法运算。</p>
<h3 id="Spark-MLlib中实现"><a href="#Spark-MLlib中实现" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStopWordsRemover</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkStopWordsRemover&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line"></span><br><span class="line">        <span class="type">StopWordsRemover</span> <span class="variable">stopWordsRemover</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StopWordsRemover</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;filtered&quot;</span>)</span><br><span class="line">                <span class="comment">//设置停用词</span></span><br><span class="line">                <span class="comment">//.setStopWords(new String[]&#123;&quot;i&quot;, &quot;the&quot;, &quot;are&quot;&#125;)</span></span><br><span class="line">                <span class="comment">//设置是否区分大小写</span></span><br><span class="line">                .setCaseSensitive(<span class="literal">true</span>);</span><br><span class="line">        Dataset&lt;Row&gt; filteredDF = stopWordsRemover.transform(wordsDF);</span><br><span class="line">        filteredDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="TF-IDF"><a href="#TF-IDF" class="headerlink" title="TF-IDF"></a>TF-IDF</h2><hr>
<p>  TF-IDF（Term Frequency-Inverse Document Frequency）被叫做词频-逆向文档频率。是一种在文本挖掘中广泛使用的特征向量化方法，用来反映一个单词在语料库文档中的重要性。</p>
<p>  我们把很多文档的集合叫做语料库，我们需要计算语料库文档中每个单词$t$在整个语料库文档中的权重度量用来表示该单词对于该类文档的重要性，通常我们使用概率来确定该度量信息，然后通过机器学习算法进行预测文档类别的时候，通过单词的权重来确定该文档更相似于语料库中哪篇文档来达到预测的目的。</p>
<h3 id="TF"><a href="#TF" class="headerlink" title="TF"></a>TF</h3><p>  TF（Term Frequency）即词频，表示单词$t$在文档$d$中的的出现频率，所以有<br>$$<br>TF(t,d) &#x3D; \frac{n_{t,d}}{\sum_k n_{k,d}}<br>$$</p>
<h3 id="IDF"><a href="#IDF" class="headerlink" title="IDF"></a>IDF</h3><p>  IDF（Inverse Document Frequency）即逆向文档频率，表示如果单词$t$在语料库中出现的频率极高，那么该词及有可能没有携带针对文档的某些特殊信息，例如的、是和我等词，所以我们需要降低该词的权重信息，我们将语料库表示为$D$，所以有<br>$$<br>IDF(t,D) &#x3D; log \frac {\mid D\mid}{\mid DF(t,D)\mid}<br>$$<br>其中$\mid D\mid$表示为语料库中文档总数，$\mid DF(t,D)\mid$表示为单词$t$在语料库中出现的次数，为了避免分母为0的情况，所以公式更新为<br>$$<br>IDF(t,D) &#x3D; log \frac {\mid D\mid+1}{\mid DF(t,D)\mid+1}<br>$$<br>因为取对数的缘故，当单词$t$出现在所有文档中时，$IDF(t,D)$的值为0，合理的下降了单词$t$的权重。</p>
<h3 id="TF-IDF-1"><a href="#TF-IDF-1" class="headerlink" title="TF-IDF"></a>TF-IDF</h3><p>  最终我们TF-IDF的结果会被表示为<br>$$<br>TFIDF(t,d,D) &#x3D; TF(t,d)·IDF(t,D)<br>$$</p>
<h3 id="Spark-MLlib中实现-1"><a href="#Spark-MLlib中实现-1" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkTFIDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">&quot;SparkTFIDF&quot;</span>)</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0.0</span>, <span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">0.0</span>, <span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1.0</span>, <span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;label&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; sentenceData = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>().setInputCol(<span class="string">&quot;sentence&quot;</span>).setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsData = tokenizer.transform(sentenceData);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 HashingTF 进行词频统计</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * HashingTF 运用 Hashing trick 方法进行进行特征降维处理</span></span><br><span class="line"><span class="comment">         * 哈希函数使用 murmurHash 3</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">HashingTF</span> <span class="variable">hashingTF</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashingTF</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;rawFeatures&quot;</span>)</span><br><span class="line">                <span class="comment">//设置为以二进制方式进行词频统计，即单词出现被记录为1，不出现记录为0</span></span><br><span class="line">                <span class="comment">//.setBinary(true)</span></span><br><span class="line">                <span class="comment">//设置输出维数，默认维数为 262144</span></span><br><span class="line">                .setNumFeatures(<span class="number">20</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 CountVectorizer 进行词频统计</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * CountVectorizer 是使用文档中单词计数的方式进行特征提取</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">CountVectorizerModel</span> <span class="variable">countVectorizerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountVectorizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;rawFeatures&quot;</span>)</span><br><span class="line">                <span class="comment">//设置为以二进制方式进行词频统计，即单词出现被记录为1，不出现记录为0</span></span><br><span class="line">                <span class="comment">//.setBinary(true)</span></span><br><span class="line">                <span class="comment">//设置输出向量的结果维数，或理解为Top n的词列表</span></span><br><span class="line">                .setVocabSize(<span class="number">20</span>)</span><br><span class="line">                <span class="comment">//设置最小输出</span></span><br><span class="line">                .setMinDF(<span class="number">0</span>)</span><br><span class="line">                .fit(wordsData);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; featurizedData = hashingTF.transform(wordsData);</span><br><span class="line">        <span class="type">IDF</span> <span class="variable">idf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IDF</span>().setInputCol(<span class="string">&quot;rawFeatures&quot;</span>).setOutputCol(<span class="string">&quot;features&quot;</span>);</span><br><span class="line">        <span class="type">IDFModel</span> <span class="variable">idfModel</span> <span class="operator">=</span> idf.fit(featurizedData);</span><br><span class="line">        Dataset&lt;Row&gt; rescaledData = idfModel.transform(featurizedData);</span><br><span class="line">        rescaledData.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Word2Vec"><a href="#Word2Vec" class="headerlink" title="Word2Vec"></a>Word2Vec</h2><hr>
<p>  word2vec是将一个文档用分布式特征向量的方式表示出来，便于在机器学习算法中进行文档相似度等计算。该方式将每个单词映射到一个唯一的固定维度大小的向量中，向量被表示为每个词在空间向量中的距离，可以理解为语义相似度。</p>
<h3 id="Spark-MLlib中实现-2"><a href="#Spark-MLlib中实现-2" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkWord2Vec</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkWord2Vec&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>().setInputCol(<span class="string">&quot;sentence&quot;</span>).setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        <span class="type">Word2Vec</span> <span class="variable">word2Vec</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Word2Vec</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;result&quot;</span>)</span><br><span class="line">                <span class="comment">//设置最终输出的向量长度</span></span><br><span class="line">                .setVectorSize(<span class="number">3</span>)</span><br><span class="line">                <span class="comment">//因为有使用梯度下降算法计算最大似然估计，所以可以设置迭代次数</span></span><br><span class="line">                .setMaxIter(<span class="number">100</span>)</span><br><span class="line">                .setMinCount(<span class="number">0</span>);</span><br><span class="line">        <span class="type">Word2VecModel</span> <span class="variable">model</span> <span class="operator">=</span> word2Vec.fit(wordsDF);</span><br><span class="line">        Dataset&lt;Row&gt; result = model.transform(wordsDF);</span><br><span class="line">        result.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="N-Gram（N元模型）"><a href="#N-Gram（N元模型）" class="headerlink" title="N-Gram（N元模型）"></a>N-Gram（N元模型）</h2><hr>
<p>  n-gram被表示为一个长度为n的单词的序列，即将输入的特征值重新组合为以空格为分隔符的两个单词为单位的特征，常用的在Word2Vec中被用作上下文表示。例如[a, b, c]会生成[a b, b c]，即输出某个单词在相对的语义环境中的表示。</p>
<h3 id="Spark-MLlib中实现-3"><a href="#Spark-MLlib中实现-3" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkNGram</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkNGram&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        <span class="type">NGram</span> <span class="variable">ngram</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NGram</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;ngrams&quot;</span>)</span><br><span class="line">          		<span class="comment">//设置n的值</span></span><br><span class="line">                .setN(<span class="number">2</span>);</span><br><span class="line">        Dataset&lt;Row&gt; ngramDataFrame = ngram.transform(wordsDF);</span><br><span class="line">        ngramDataFrame.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="二值化（Binarizer）"><a href="#二值化（Binarizer）" class="headerlink" title="二值化（Binarizer）"></a>二值化（Binarizer）</h2><hr>
<p>  二值化是将特征值转化为二进制（0&#x2F;1）的过程，在实际使用中我们需要确定一个阈值，如果特征值大于我们确定的阈值则特征被二值化为1，否则为0。</p>
<h3 id="Spark-MLlib中实现-4"><a href="#Spark-MLlib中实现-4" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkBinarizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkBinarizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;feature&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; continuousDataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Binarizer</span> <span class="variable">binarizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Binarizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;feature&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;binarized_feature&quot;</span>)</span><br><span class="line">                .setThreshold(<span class="number">0.5</span>);</span><br><span class="line">        Dataset&lt;Row&gt; binarizedDataFrame = binarizer.transform(continuousDataFrame);</span><br><span class="line">        binarizedDataFrame.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="PCA（主元分析）"><a href="#PCA（主元分析）" class="headerlink" title="PCA（主元分析）"></a>PCA（主元分析）</h2><hr>
<p>  PCA（Principal Components Analysis）即主成分分析，也叫主元分析。PCA在机器学习算法的经常在特征值降维中使用，就是将原本复杂的特征在不影响原信息表示的前提下从高维降至低维特征，使特征可以更方便的进行机器学习算法的计算。</p>
<blockquote>
<p>关于PCA原理和推导的文档：</p>
<p>[PCA]: <span class="exturl" data-url="aHR0cDovL3d3dy4zNjBkb2MuY29tL2NvbnRlbnQvMTMvMTEyNC8wMi85NDgyXzMzMTY4ODg4OS5zaHRtbA==">http://www.360doc.com/content/13/1124/02/9482_331688889.shtml<i class="fa fa-external-link-alt"></i></span>	“PCA数学原理”</p>
</blockquote>
<h3 id="Spark-MLlib中实现-5"><a href="#Spark-MLlib中实现-5" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkPCA</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkPCA&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.sparse(<span class="number">5</span>, <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;<span class="number">1</span>, <span class="number">3</span>&#125;, <span class="keyword">new</span> <span class="title class_">double</span>[]&#123;<span class="number">1.0</span>, <span class="number">7.0</span>&#125;)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">4.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">PCAModel</span> <span class="variable">pca</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PCA</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;pcaFeatures&quot;</span>)</span><br><span class="line">                .setK(<span class="number">3</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; result = pca.transform(df);</span><br><span class="line">        result.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="多项式扩展"><a href="#多项式扩展" class="headerlink" title="多项式扩展"></a>多项式扩展</h2><hr>
<p>  多项式扩展（Polynomial expansion）也叫做多项式展开，是将特征从低维扩展为高维空间的过程。</p>
<h3 id="Spark-MLlib中实现-6"><a href="#Spark-MLlib中实现-6" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkPoly</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkPoly&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">0.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">3.0</span>, -<span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line"></span><br><span class="line">        <span class="type">PolynomialExpansion</span> <span class="variable">polyExpansion</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PolynomialExpansion</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;polyFeatures&quot;</span>)</span><br><span class="line">                .setDegree(<span class="number">3</span>);</span><br><span class="line">        Dataset&lt;Row&gt; polyDF = polyExpansion.transform(df);</span><br><span class="line">        polyDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="DCT"><a href="#DCT" class="headerlink" title="DCT"></a>DCT</h2><hr>
<p>  DCT（Discrete Cosine Transform）即离散余弦变换，是将时域的N维实数序列转换为频域的N维实数序列</p>
<h3 id="Spark-MLlib中实现-7"><a href="#Spark-MLlib中实现-7" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkDCT</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkDCT&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">1.0</span>, -<span class="number">2.0</span>, <span class="number">3.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(-<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, -<span class="number">7.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">14.0</span>, -<span class="number">2.0</span>, -<span class="number">5.0</span>, <span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line"></span><br><span class="line">        <span class="type">DCT</span> <span class="variable">dct</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DCT</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;featuresDCT&quot;</span>)</span><br><span class="line">                .setInverse(<span class="literal">false</span>);</span><br><span class="line">        Dataset&lt;Row&gt; dctDf = dct.transform(df);</span><br><span class="line">        dctDf.select(<span class="string">&quot;featuresDCT&quot;</span>).show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="索引变换"><a href="#索引变换" class="headerlink" title="索引变换"></a>索引变换</h2><hr>
<p>  索引变换有两种，一种是字符串到索引的变换，一种是索引到字符串的变换，简单理解就是将复杂的特征值变换为简单的按照特征值出现的频率排序的索引列表。</p>
<h3 id="Spark-MLlib中实现-8"><a href="#Spark-MLlib中实现-8" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkIndex</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkIndex&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="string">&quot;c&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;category&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 字符串到索引的变换</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">StringIndexer</span> <span class="variable">stringIndexer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryIndex&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 索引到字符串的变换</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">IndexToString</span> <span class="variable">indexToString</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexToString</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;index&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; categoryIndexDF = stringIndexer.fit(df).transform(df);</span><br><span class="line">        Dataset&lt;Row&gt; indexDF = indexToString.transform(categoryIndexDF);</span><br><span class="line">        indexDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="独热编码"><a href="#独热编码" class="headerlink" title="独热编码"></a>独热编码</h2><hr>
<p>  独热编码（One-hot encoding）是将一列标签索引映射到一列二进制向量，并且最多只有一个单值。</p>
<p>  独热编码往往被用来处理不是连续值的特征，如分类值等，因为算法分类器默认数据是连续的并且有序的，所以当输入特征随机分配的属性值或分类值时，我们需要找一种特征解决方案将这样的特征值进行变换。</p>
<p>  独热编码使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意的时候其中只有一位有效，例如有以下特征<br>$$<br>[male, female]<br>$$<br>如果将上述特征用数字表示，在算法处理时效率会高很多，我们对该特征做简单的索引映射<br>$$<br>[0,1]<br>$$<br>因为分类器默认的算法数据是连续有序的，所以上述经过映射过的特征也不能直接在分类器中使用，我们采用独热编码的方式进行特征转换<br>$$<br>[00, 10]<br>$$<br>因此原来的特征内容被转换为一个稀疏特征，直接输入到分类器进行模型训练。</p>
<h3 id="Spark-MLlib中实现-9"><a href="#Spark-MLlib中实现-9" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkOnehotEncode</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkOnehotEncode&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="string">&quot;c&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;category&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">StringIndexerModel</span> <span class="variable">indexer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; indexed = indexer.transform(df);</span><br><span class="line">        <span class="type">OneHotEncoder</span> <span class="variable">encoder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OneHotEncoder</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryVec&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; encoded = encoder.transform(indexed);</span><br><span class="line">        encoded.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="向量类型索引化"><a href="#向量类型索引化" class="headerlink" title="向量类型索引化"></a>向量类型索引化</h2><hr>
<p>  向量类型索引化（Vector Index）可以帮助指定向量数据集中的分类特征，它可以自动确定哪些特征值是分类的，并将原始值转换为类别索引。</p>
<p>  向量类型索引化的功能就是将特征中的类别特征重新进行编号，将向量内部原始的值离散化为索引值，用来提高决策树或随机森林等算法的模型分类效果。</p>
<h3 id="Spark-MLlib中实现-10"><a href="#Spark-MLlib中实现-10" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><p>  在Spark MLlib中，指定一列输入的向量列后需要指定maxCategrries参数，表明如果某个特征值不重复个数小于等于maxCategrries参数，那么VectorIndexer会将该特征进行从索引0开始的离散化操作。</p>
<figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkVectorIndexer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkVectorIndexer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">0.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">3.0</span>, -<span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">VectorIndexerModel</span> <span class="variable">vectorIndexerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;feat&quot;</span>)</span><br><span class="line">                .setMaxCategories(<span class="number">2</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; featDF = vectorIndexerModel.transform(df);</span><br><span class="line">        featDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="相互作用"><a href="#相互作用" class="headerlink" title="相互作用"></a>相互作用</h2><hr>
<p>  该特征变换采用两个向量类型的特征值进行变换后生成一个单个向量的特征，即将每个输入列中值的组合乘积后生成一个新的向量特征。</p>
<h3 id="Spark-MLlib中实现-11"><a href="#Spark-MLlib中实现-11" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkInteraction</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkInteraction&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">3</span>),</span><br><span class="line">                RowFactory.create(<span class="number">6</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id1&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id2&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id3&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id4&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id5&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id6&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id7&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">VectorAssembler</span> <span class="variable">assembler1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorAssembler</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id2&quot;</span>, <span class="string">&quot;id3&quot;</span>, <span class="string">&quot;id4&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;vec1&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; assembled1 = assembler1.transform(df);</span><br><span class="line">        <span class="type">VectorAssembler</span> <span class="variable">assembler2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorAssembler</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id5&quot;</span>, <span class="string">&quot;id6&quot;</span>, <span class="string">&quot;id7&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;vec2&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; assembled2 = assembler2.transform(assembled1).select(<span class="string">&quot;id1&quot;</span>, <span class="string">&quot;vec1&quot;</span>, <span class="string">&quot;vec2&quot;</span>);</span><br><span class="line">        <span class="type">Interaction</span> <span class="variable">interaction</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Interaction</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id1&quot;</span>,<span class="string">&quot;vec1&quot;</span>,<span class="string">&quot;vec2&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;interactedCol&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; interacted = interaction.transform(assembled2);</span><br><span class="line">        interacted.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="泛数p-norm规范化"><a href="#泛数p-norm规范化" class="headerlink" title="泛数p-norm规范化"></a>泛数p-norm规范化</h2><hr>
<p>  p-norm即p-泛数，机器学习算法中对特征进行P-泛数规范化操作，使得算法有更好的表现。</p>
<p>  p-泛数的定义在自定义p值的前提下进行泛数计算，常用的为2-泛数，即$L^2$，单位P-泛数的定义为<br>$$<br>\mid\mid x \mid\mid_p &#x3D; (\mid x_1\mid^p + \mid x_2 \mid^p+\cdots+\mid x_n\mid^p)^{\frac1p}<br>$$<br>当p取1，2和$\infty$时的三种简单情形<br>$$<br>\begin{align}<br>&amp; 1-泛数(L^1):\mid\mid x \mid\mid &#x3D; \mid x_1\mid + \mid x_2 \mid+\cdots+\mid x_n\mid<br>\<br>&amp; 2-泛数(L^2):\mid\mid x \mid\mid_2 &#x3D; (\mid x_1\mid^2 + \mid x_2 \mid^2+\cdots+\mid x_n\mid^2)^{\frac12}<br>\<br>&amp; \infty-泛数(L^\infty):\mid\mid x \mid\mid_\infty &#x3D;max (\mid x_1\mid, \mid x_2 \mid,\cdots+\mid x_n\mid)<br>\end{align}<br>$$<br>  对某个特征进行P-泛数规范即将该特征组成的特征向量计算其P-泛数，然后对特征向量中的每个元素除以P-泛数后组成新的特征向量。</p>
<h3 id="Spark-MLlib中实现-12"><a href="#Spark-MLlib中实现-12" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3> <figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkNormalizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkNormalizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; l1NormData = normalizer.transform(dataFrame);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.0 / ( |1.0| + |0.1| + |-8.0| ) 0.1 / ( |1.0| + |0.1| + |-8.0| ) -0.8 / ( |1.0| + |0.1| + |-8.0| )</span></span><br><span class="line"><span class="comment">         * 2.0 / ( |2.0| + |1.0| + |-4.0| ) 1.0 / ( |2.0| + |1.0| + |-4.0| ) -4.0 / ( |2.0| + |1.0| + |-4.0| )</span></span><br><span class="line"><span class="comment">         * 4.0 / ( |4.0| + |10.0| + |8.0| ) 10.0/ ( |4.0| + |10.0| + |8.0| )  8.0 / ( |4.0| + |10.0| + |8.0| )</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        l1NormData.show(<span class="literal">false</span>);</span><br><span class="line">        Dataset&lt;Row&gt; lInfNormData = normalizer.transform(dataFrame, normalizer.p().w(Double.POSITIVE_INFINITY));</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.0 / max(1.0, 0.1, -8.0) ...</span></span><br><span class="line"><span class="comment">         * ...</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        lInfNormData.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="z-score规范化"><a href="#z-score规范化" class="headerlink" title="z-score规范化"></a>z-score规范化</h2><hr>
<p>  z-score规范化或称作零均值规范化是将特征进行基于特征值均值和标准差进行规范化的操作。特征v的z-score规范化被表示为<br>$$<br>v&#96;&#x3D;\frac{v_i-avg_v}{\delta_v}<br>$$<br>其中$avg_v$为特征v的平均值，$\delta_v$为特征的标准差。</p>
<p>  当特征v的最大值和最小值未知或有离群点影响最大最小规范化时z-score规范化是一个有效的特征规范化手段。</p>
<h3 id="Spark-MLlib中实现-13"><a href="#Spark-MLlib中实现-13" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStandardScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkStandardScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">StandardScalerModel</span> <span class="variable">standardScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StandardScaler</span>()</span><br><span class="line">                <span class="comment">//是否启用均值计算，将均值移到0，对稀疏矩阵不可用</span></span><br><span class="line">                .setWithMean(<span class="literal">false</span>)</span><br><span class="line">                <span class="comment">//是否将方差缩放到1</span></span><br><span class="line">                .setWithStd(<span class="literal">true</span>)</span><br><span class="line">          		.setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = standardScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="最大-最小规范化"><a href="#最大-最小规范化" class="headerlink" title="最大-最小规范化"></a>最大-最小规范化</h2><hr>
<p>  最大-最小规范化是将特征向量的值线性地变换到指定最大-最小值之间。经常的我们在使用算法进行模型训练的时候，因为每个特征的取值大小不同或差距很大，这导致在算法训练的时候数值较大的特征对模型结果起决定性作用，为了解决这种问题所以引入最大最小规范化的特征处理方式，该方式使得特征值最后落在$[0, 1]$范围内。</p>
<p>  常用的最大-最小规范化方式为<br>$$<br>newValue&#x3D;\frac{oldValue-minValue}{maxValue-minValue}\times (E_{max}-E_{min})+E_{min}<br>$$<br>其中$E_{max}$和$E_{min}$是指定的区间范围。</p>
<h3 id="Spark-MLlib中实现-14"><a href="#Spark-MLlib中实现-14" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkMinMaxScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkMinMaxScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">MinMaxScalerModel</span> <span class="variable">minMaxScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MinMaxScaler</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = minMaxScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="绝对值规范化"><a href="#绝对值规范化" class="headerlink" title="绝对值规范化"></a>绝对值规范化</h2><hr>
<p>  绝对值规范化是将各个特征值除以该特征的最大绝对值，因此可以将特征值缩放到$[-1,1]$之间，并且不会移动和居中中心点，所以不会破坏向量的稀疏性。但是唯一需要考虑的就是如果该最大绝对值是一个利群点，这种规范化方式就会很不合理。</p>
<h3 id="Spark-MLlib中实现-15"><a href="#Spark-MLlib中实现-15" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkMaxAbsScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkMaxAbsScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">MaxAbsScalerModel</span> <span class="variable">maxAbsScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MaxAbsScaler</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = maxAbsScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="分箱器"><a href="#分箱器" class="headerlink" title="分箱器"></a>分箱器</h2><hr>
<p>  分箱器是将连续的特征值按照我们提供的数值区间按照$[x,y)$进行切割，输出区间索引并生成新的特征。</p>
<h3 id="Spark-MLlib中实现-16"><a href="#Spark-MLlib中实现-16" class="headerlink" title="Spark MLlib中实现"></a>Spark MLlib中实现</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkBinarizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkBinarizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;feature&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; continuousDataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Binarizer</span> <span class="variable">binarizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Binarizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;feature&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;binarized_feature&quot;</span>)</span><br><span class="line">                .setThreshold(<span class="number">0.5</span>);</span><br><span class="line">        Dataset&lt;Row&gt; binarizedDataFrame = binarizer.transform(continuousDataFrame);</span><br><span class="line">        binarizedDataFrame.show();</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>

<h2 id="Hadamard乘积"><a href="#Hadamard乘积" class="headerlink" title="Hadamard乘积"></a>Hadamard乘积</h2><hr>
<p>  将我们输入的每个向量乘以一个指定的权重向量来生成一个新的向量值。</p>
<h2 id="向量切片机"><a href="#向量切片机" class="headerlink" title="向量切片机"></a>向量切片机</h2><hr>
<h2 id="R模型公式"><a href="#R模型公式" class="headerlink" title="R模型公式"></a>R模型公式</h2><hr>
<h2 id="卡方特征选择器"><a href="#卡方特征选择器" class="headerlink" title="卡方特征选择器"></a>卡方特征选择器</h2><hr>
<h2 id="局部敏感哈希"><a href="#局部敏感哈希" class="headerlink" title="局部敏感哈希"></a>局部敏感哈希</h2><hr>
<h2 id="LSH运算"><a href="#LSH运算" class="headerlink" title="LSH运算"></a>LSH运算</h2><hr>
<h2 id="LSH算法"><a href="#LSH算法" class="headerlink" title="LSH算法"></a>LSH算法</h2><hr>

    </div>

    
    
    

    <footer class="post-footer">
          <div class="reward-container">
  <div>请我一杯咖啡吧！</div>
  <button>
    赞赏
  </button>
  <div class="post-reward">
      <div>
        <img src="/images/wx.jpg" alt="Iceberg 微信">
        <span>微信</span>
      </div>
      <div>
        <img src="/images/zfb.jpg" alt="Iceberg 支付宝">
        <span>支付宝</span>
      </div>

  </div>
</div>

          

<div class="post-copyright">
<ul>
  <li class="post-copyright-author">
      <strong>本文作者： </strong>Iceberg
  </li>
  <li class="post-copyright-link">
      <strong>本文链接：</strong>
      <a href="https://vnicl.github.io/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/" title="机器学习中的特征工程">https://vnicl.github.io/2017/06/13/机器学习中的特征工程/</a>
  </li>
  <li class="post-copyright-license">
      <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <span class="exturl" data-url="aHR0cHM6Ly9jcmVhdGl2ZWNvbW1vbnMub3JnL2xpY2Vuc2VzL2J5LW5jLW5kLzQuMC9kZWVkLnpoLWhhbnM="><i class="fab fa-fw fa-creative-commons"></i>BY-NC-ND</span> 许可协议。转载请注明出处！
  </li>
</ul>
</div>

          <div class="post-tags">
              <a href="/tags/TF-IDF/" rel="tag"># TF-IDF</a>
          </div>

        

          <div class="post-nav">
            <div class="post-nav-item">
                <a href="/2017/06/03/Spark%E5%85%A5%E9%97%A8/" rel="prev" title="Spark入门">
                  <i class="fa fa-angle-left"></i> Spark入门
                </a>
            </div>
            <div class="post-nav-item">
                <a href="/2017/09/15/Play-Framework%E5%85%A5%E9%97%A8/" rel="next" title="Play Framework入门">
                  Play Framework入门 <i class="fa fa-angle-right"></i>
                </a>
            </div>
          </div>
    </footer>
  </article>
</div>






</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 2009 – 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">Iceberg</span>
  </div>
  <div class="powered-by">由 <span class="exturl" data-url="aHR0cHM6Ly9oZXhvLmlv">Hexo</span> & <span class="exturl" data-url="aHR0cHM6Ly90aGVtZS1uZXh0LmpzLm9yZy9taXN0Lw==">NexT.Mist</span> 强力驱动
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="返回顶部">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>
  <div class="reading-progress-bar"></div>
  <a role="button" class="book-mark-link book-mark-link-fixed"></a>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/next-theme-pjax/0.6.0/pjax.min.js" integrity="sha256-vxLn1tSKWD4dqbMRyv940UYw4sXgMtYcK6reefzZrao=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.33/fancybox/fancybox.umd.js" integrity="sha256-+2+qOqR8CKoHh/AsVR9k2qaDBKWjYNC2nozhYmv5j9k=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/medium-zoom/1.1.0/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="/js/pjax.js"></script>

  <script src="https://cdnjs.cloudflare.com/ajax/libs/hexo-generator-searchdb/1.4.1/search.js" integrity="sha256-1kfA5uHPf65M5cphT2dvymhkuyHPQp5A53EGZOnOLmc=" crossorigin="anonymous"></script>
<script src="/js/third-party/search/local-search.js"></script>




  <script src="/js/third-party/fancybox.js"></script>

  <script src="/js/third-party/pace.js"></script>


  




  

  <script class="next-config" data-name="enableMath" type="application/json">true</script><script class="next-config" data-name="mathjax" type="application/json">{"enable":true,"tags":"none","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mathjax/3.2.2/es5/tex-mml-chtml.js","integrity":"sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI="}}</script>
<script src="/js/third-party/math/mathjax.js"></script>



</body>
</html>
