<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title>一零年一月于广东</title>
    <url>/2010/01/27/%E4%B8%80%E9%9B%B6%E5%B9%B4%E4%B8%80%E6%9C%88%E4%BA%8E%E5%B9%BF%E4%B8%9C/</url>
    <content><![CDATA[<span id="more"></span>
<p>　　好久都不写东西了！<br />
　　寂寞的人儿拖着疲倦的身体，满载着这个世界所应有的一切悲痛与莫名的力量用无奈且突兀的手指敲击出一段一段叫寂寞和悲痛的文字。昏暗的路灯把自己拉的很长很长，错乱的心跳带着不应有的赫兹去解密那些奇奇怪怪的思想，最后却只留下无奈。<br />
　　谁说广东的冬天如妙龄女郎？萎缩在充杂着不能以任何词汇形容的味道的棉大衣里面，身上还是硬生生起了一身的鸡皮疙瘩，气候没有想象中的那么温暖如春，哆嗦着以60度的仰角仰望夜空，无论如何却不知道自己应该寻找什么。南方的夜空比北方的明镜了许多。耳旁永远都是车间里机器嘈杂的声音，偶尔还会传来两声狗吠，竟然莫名地感觉到了一种从未有过的空旷，深邃的让久经尘世的心可以拧出水来。<br />
　　不知从哪冒出这么一个不回家过年的怪念头？这么多年，因为无奈我放弃的东西太多，放下的还是放不下的现在却都已经放下了，我不后悔曾经做过的一切，过去的就该让它过去，有人说翻看过去，抖起的灰尘会迷了双眼。人的负重能力有限，不管来自哪方面，所以我不必在为“这个世界”付出与放下任何东西，我得过我自己的生活，所以我必须长大，我得逼自己长大，尽管只是一种及其虚伪而且只是薄薄的一层糖衣包。把一切来自心灵上的水雾统统都掩埋，然后去种植一种叫做沧桑的东西。<br />
　　有人说笑容是一种最好的防腐剂，可是用来防腐心灵的时候却显得那么苍白，一种悲剧的白。我只喜欢黑色，我认为黑色可以抗拒任何有形亦或无形的软弱，有人说黑色掩盖了软弱，我不这么认为，我认为是黑色创造了坚强，给自己披一件坚强的外衣，不然你拿什么与这个“世界”抗衡？<br />
　　我曾经一度在新浪博客里面写悲惨的小说故事，去映射自己的生活。后来想想，灰白的生活由不得自己去添色彩，最后顶多只是达到一种可怕而单调的渲染，连色彩都显得那么的苍劲，而又何必悲惨着自己的悲惨，文字这东西就是一个游戏，文字游戏里其实也有潜规则，也有输赢，只是所有人都只把她当做工具罢了。不知从什么时候开始，用户名我总喜欢用icecold和iceberg这两个单词，也许真的双鱼座总是一副呆表情，也许真的什么地方都是冷的……<br />
　　爱情在这个年龄不知还有没有懵懂，只知道爱上了却爱的那么彻底，那么的歇斯底里。每个人都不应该有任何痛楚，爱上了就别制造伤害，可是在世俗与理性面前完全没留给我任何选择的余地，在事实面前拥有的只有无奈。我不甘心屈服于那种被叫做命运的东西，却找不到任何解救的理由，分手二字在这个时候真的显得那么的苍白无力，空洞的肉体显得那么的脆弱，说出口的却那么的虚伪而不堪一击，风雨过后留下的只有耳机里那空灵的声音和食指与无名指间那股淡淡的烟草的香味，阳光斜斜地照进来，刺的眼睛里都是水雾。不知从什么时候开始眼睛里常常朦胧于或多或少的水雾，还没来得及拭去脸上却已经有少许的潮湿，湿了的还有那些角落里的尘埃。<br />
　　有谁在意我的心里有多苦，我不愿只做一只永远躲在翅膀底下的一只雏鹰，当有天我挣脱了翅膀的时候，却只能化为一只风筝，去走别人给自己划定的界限，并且挣扎着，而又无可奈何！这个空间里活着的人太多，你不能只为自己活着，你有的只是无止尽的无奈地活着，并且还得笑着，灿烂地掩盖自己，有时你笑的不怎么灿烂了，那么你就是叛逆，背离了世俗好像背离了整个世界。<br />
　　不知是不是每个人身上都有无论如何也祛除不掉的“污垢”，我感觉我有，没有哪个品牌的“沐浴露”有那个高效的除污特效。其实不必太在意它的存在，至少它证明了你的长大与成熟。<br />
　　以前一直以为大学是天堂，我来了，感觉它变成了地域，里面有无止境的落寞，每天清闲的让人感到浑身不自在。<br />
　　晚上睡觉手机照样还是放在枕头边，尽管这样辐射很大，不是怕错过任何一个讯息，我会把闹钟音量开的很大，它叫醒我的第一刻摸摸自己的眼睛鼻子，动动大腿，然后庆幸地说我还活着。阳光从窗户洒进来，长长的烟灰倒影在那双破烂的鞋子上，看着看着世界已经没有了色彩，慢慢的淡了下来，只有一片灰蒙蒙。索性闭上眼睛，音响里飘逸着那么空灵的声音：<br />
　　“心跳乱了节奏，梦亦不自由……”。</p>
]]></content>
      <categories>
        <category>文艺范</category>
        <category>散文</category>
      </categories>
      <tags>
        <tag>散文</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>阴雨天</title>
    <url>/2010/04/03/%E9%98%B4%E9%9B%A8%E5%A4%A9/</url>
    <content><![CDATA[<span id="more"></span>
<p>　　窗外是一如既往的淡，光线阴沉沉的，像极了撒旦的脸。偶尔从开着的窗户上扑进来点凉风，我颤了颤身体，斜斜的看出去，撩开眼角的刘海，外面还是一片灰蒙蒙的，还是淡淡的，一片阴沉沉。小雨淅淅沥沥……<br />
　　天气不知能不能算作阴霾。昏暗的光线让人看着很无力，天空飘着一切乱七八糟的东西。已经很难分辨清楚云朵的轮廊，给人的感觉就像小时候穿了浸了水的棉裤，随时都能拧出水来。<br />
　　我读不懂南方的季节，夏天完了，没有秋季，也好像没有冬季，倒是像极了北方的春天，而又好似没有春天的那份盎然。我就是喜欢这样的单调，一年没什么变化，心中有的就是那么的一如既往，只是我还没有清楚的读懂它是春？是夏？还是别的什么。<br />
　　不知道文字这东西为什么总是写的出现这种无奈和孤寂，而且不是一次的想起马致远的那几句“枯藤老树昏鸦，小桥流水人家，古道西风瘦马，夕阳西下，断肠人在天涯”，断肠人？在天涯？我很自嘲，多大的年龄，开始没完没了的过滤嘴，带着那种可以让人发疯的色彩，坐在阳台那张桌子的犄角，以最合适的舒服的姿势仰望天空，不是很明镜，看着一天又慢慢的溜走，快落山的时的那束余光，照射在脸部，还有头发，那点鱼尾纹，还有那根白的出奇的新生的头发。真的很想看一遍日出与日落，那么的清新脱俗，可还是算了，那样只会显得自己那么的颓废不堪。<br />
　　二十一岁的年龄应该不算什么，但到我这就变了，感觉一切都变了，瞳孔开始找不到焦点，眼角里却只是那么抑郁的色，好多好多事情好像都明白了，却好似还在模糊，懂得了却好像还在糊涂。<br />
　　看完了一整部的《蜗居》，生活真的有那么的迷茫？人生的意义难道就在于一辈子有那么属于自己的一套房子？虽然只是付了首付的。何必把自己搞的一辈子当牛做马，说的现实一点就是跟畜生一样。想想海萍为了一套属于自己的房子，每天吃泡面和挂面，的时候，这个社会的生活已经了然于胸，为了一块钱会和苏醇闹翻，为生活精打细算的时候还是免不了生活给她开个玩笑。当然女人也估计是人类中最傻的一类，海藻作为一个名副其实的二奶，竟然还敢为情人生一个孩子，有道是我又一栋大房子，可是里面不住人，跟没有什么区别，人们的私欲是来自各个方面的，其实幸福是最重要的。爱一个人，你要做的不是给她最好的，而是给她最窝心的。<br />
　　看这种电视剧会让人心疼，演绎的那么的刺骨。<br />
　　回头翻翻前面几篇文字，感觉我现在可真够矫情的，看的会起一身的鸡皮疙瘩。<br />
　　现在胡子开始疯长了，突如其来。前天从同学那里抢了盆仙人球回来，就放在旁边，看着挺合适，那么一种浓浓的绿，看着挺有生气。<br />
　　很长时间不回家了，爸爸估计怪想我的，也许到了这个年龄已经不是恋家的时候，各种金属的大厦，各种五颜六色的LOGO图案让你不得不开始想清楚自己的未来。每个人一辈子都会有一个转型期，只是迟与早的问题，也许我现在就到了这个转型期。<br />
　　借自己以前写过的一篇不算是诗的诗来：<br />
　　当付出没有任何意义<br />
　　当眼泪只在心里默默地流<br />
　　当认为这个世界真的没有什么<br />
　　当寒风还是流过历史的伤口<br />
　　我认为爱已经可以放手！<br />
　　<br />
　　爱<br />
　　其实没有道理<br />
　　恨<br />
　　其实无从说起<br />
　　情<br />
　　其实只是虚谕<br />
　　仇<br />
　　其实只有一句“对不起”<br />
　　大不了就是“baybay”<br />
　　<br />
　　爱与被爱<br />
　　你永远会选择爱<br />
　　因为那才是属于自己的爱<br />
　　被爱只是建立在别人心灵上的爱<br />
　　而我<br />
　　一直错误地以为你会屈服于被爱<br />
　　<br />
　　树<br />
　　开始发芽<br />
　　草<br />
　　开始抽绿<br />
　　春<br />
　　开始走来<br />
　　你<br />
　　永远喜欢春天<br />
　　而我<br />
　　一直怀念冬天<br />
　　<br />
　　这个春季<br />
　　有点太不可思意<br />
　　高高的领口不能掩饰一切<br />
　　心痛只能装在心里<br />
　　慢慢的让她折磨我自己<br />
　　<br />
　　一股明亮的蓝色渐渐变成褐色<br />
　　幻化成许多不同的logo<br />
　　圈圈圆圆圈圈<br />
　　<br />
　　发现以前比现在嫩了不少，爱情，很难说的清楚，为一个人许下一个诺言很简单，去实现这个诺言得有勇气。很少的回念过去，也许这就是人，新生活可以迷灭旧的。</p>
]]></content>
      <categories>
        <category>文艺范</category>
        <category>散文</category>
      </categories>
      <tags>
        <tag>散文</tag>
        <tag>原创</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 7 配置nginx+PHP</title>
    <url>/2015/06/18/CentOS-7-%E9%85%8D%E7%BD%AEnginx-PHP/</url>
    <content><![CDATA[<h2 id="零准备工作">## 零、准备工作</h2>
<p><strong>你需要确保当前环境以及安装过gcc和gcc-c++，否则按照下面的方法安装</strong></p>
<figure class="highlight llvm"><table><tr><td class="code"><pre><span class="line">[root<span class="title">@localhost</span> ~]# yum -y install gcc-<span class="keyword">c</span>++.<span class="keyword">x</span><span class="number">86</span>_<span class="number">64</span></span><br><span class="line">[root<span class="title">@localhost</span> ~]# yum -y install gcc.<span class="keyword">x</span><span class="number">86</span>_<span class="number">64</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<h2 id="一资源下载">## 一、资源下载</h2>
<ul>
<li>nginx：下载页面 <span class="exturl" data-url="aHR0cDovL25naW54Lm9yZy9lbi9kb3dubG9hZC5odG1s">http://nginx.org/en/download.html<i class="fa fa-external-link-alt"></i></span></li>
<li>PHP：下载页面 <span class="exturl" data-url="aHR0cDovL3BocC5uZXQvZG93bmxvYWRzLnBocA==">http://php.net/downloads.php<i class="fa fa-external-link-alt"></i></span></li>
</ul>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line"><span class="comment">/* 下载nginx，文章发表前最新版本为1.8.0 */</span></span><br><span class="line">[<span class="meta">root@localhost iceberg</span>]<span class="meta"># wget http://nginx.org/download/nginx-1.8.0.tar.gz </span></span><br><span class="line"><span class="comment">/* 下载PHP，文章发表前最新版本为5.6.10 */</span> </span><br><span class="line">[<span class="meta">root@localhost iceberg</span>]<span class="meta"># wget http://cn2.php.net/distributions/php-5.6.10.tar.gz </span></span><br><span class="line"><span class="comment">/* 解压压缩包 */</span> </span><br><span class="line">[<span class="meta">root@localhost iceberg</span>]<span class="meta"># tar -xzvf nginx-1.8.0.tar.gz </span></span><br><span class="line">[<span class="meta">root@localhost iceberg</span>]<span class="meta"># tar -xzvf php-5.6.10</span></span><br></pre></td></tr></table></figure>
<h2 id="二安装nginx">## 二、安装nginx</h2>
<h3
id="下载系统中尚未安装的依赖拓展包">1、下载系统中尚未安装的依赖（拓展）包</h3>
<ul>
<li><p>pcre: nginx中很多功能需要pcre包的支持，比如rewrite模块</p>
<p>下载页面：http://sourceforge.net/projects/pcre/files/</p></li>
<li><p>zlib: 使用 nginx支持内容压缩功能</p>
<p>下载页面：http://www.zlib.net/</p></li>
<li><p>OpenSSL: ***</p>
<p>下载页面：http://www.openssl.org/source/</p></li>
</ul>
<figure class="highlight crystal"><table><tr><td class="code"><pre><span class="line">/*截止文章发表前，pcre版本为<span class="number">8.37</span>*<span class="regexp">/</span></span><br><span class="line"><span class="regexp">[root@localhost iceberg]# wget http:/</span><span class="regexp">/ncu.dl.sourceforge.net/project</span><span class="regexp">/pcre/pcre</span><span class="regexp">/8.37/pcre</span>-<span class="number">8.37</span>.tar.gz</span><br><span class="line">[root<span class="variable">@localhost</span> iceberg]<span class="comment"># tar -xzvf pcre-8.37.tar.gz</span></span><br><span class="line"><span class="regexp">/*截止文章发表前，zlib版本为1.2.8*/</span></span><br><span class="line">[root<span class="variable">@localhost</span> iceberg]<span class="comment"># wget http://zlib.net/zlib-1.2.8.tar.gz</span></span><br><span class="line">[root<span class="variable">@localhost</span> iceberg]<span class="comment"># tar -xzvf zlib-1.2.8.tar.gz</span></span><br><span class="line"><span class="regexp">/*openssl*/</span></span><br><span class="line">[root<span class="variable">@localhost</span> iceberg]<span class="comment"># wget http://www.openssl.org/source/openssl-1.0.1p.tar.gz</span></span><br><span class="line">[root<span class="variable">@localhost</span> iceberg]<span class="comment"># tar -xvzf openssl-1.0.1p.tar.gz</span></span><br></pre></td></tr></table></figure>
<h3 id="完成安装">2、完成安装</h3>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd nginx-1.8.0</span></span><br><span class="line">[root<span class="symbol">@localhost</span> nginx<span class="number">-1.8</span><span class="number">.0</span>]<span class="meta"># ./configure --with-pcre=/home/iceberg/pcre-8.37 --with-zlib=/home/iceberg/zlib-1.2.8 --with-http_ssl_module --with-openssl=/home/iceberg/openssl-1.0.1p</span></span><br><span class="line">[root<span class="symbol">@localhost</span> nginx<span class="number">-1.8</span><span class="number">.0</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> nginx<span class="number">-1.8</span><span class="number">.0</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h3 id="启动nginx服务">3、启动nginx服务</h3>
<p><strong>启动前先检查80端口是否被其他程序占用</strong></p>
<figure class="highlight perl"><table><tr><td class="code"><pre><span class="line">[root@localhost iceberg]<span class="comment"># netstat -ano|grep 80</span></span><br><span class="line">如有有被占用，需要先<span class="keyword">kill</span>掉占用的程序后开始启动nginx</span><br><span class="line">[root@localhost iceberg]<span class="comment"># /usr/local/nginx/sbin/nginx</span></span><br></pre></td></tr></table></figure>
<h3 id="其他操作">4、其他操作</h3>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line"><span class="comment">/*编辑nginx配置文件*/</span></span><br><span class="line">[root<span class="meta">@localhost</span> iceberg]# vi <span class="regexp">/usr/</span>local<span class="regexp">/nginx/</span>conf<span class="operator">/</span>nginx.conf</span><br><span class="line"><span class="comment">/*停止nginx服务*/</span></span><br><span class="line">[root<span class="meta">@localhost</span> iceberg]# <span class="regexp">/usr/</span>local<span class="regexp">/nginx/</span>sbin<span class="operator">/</span>nginx <span class="operator">-</span>s stop</span><br><span class="line"><span class="comment">/*使配置文件生效*/</span></span><br><span class="line">[root<span class="meta">@localhost</span> iceberg]# <span class="regexp">/usr/</span>local<span class="regexp">/nginx/</span>sbin<span class="operator">/</span>nginx <span class="operator">-</span>s reload</span><br></pre></td></tr></table></figure>
<h2 id="三安装php">## 三、安装PHP</h2>
<h3 id="依赖拓展包安装">1、依赖（拓展）包安装</h3>
<ul>
<li>libxml2: 实现读、创建、以及操作xml数据功能的C语言库</li>
</ul>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> php<span class="number">-5.6</span><span class="number">.10</span>]<span class="meta"># yum -y install libxml2.x86_64</span></span><br><span class="line">[root<span class="symbol">@localhost</span> php<span class="number">-5.6</span><span class="number">.10</span>]<span class="meta"># yum -y install libxml2-devel.x86_64</span></span><br></pre></td></tr></table></figure>
<h3 id="完成安装-1">2、完成安装</h3>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line">[root<span class="meta">@localhost</span> iceberg]# cd php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span></span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# <span class="operator">./</span>configure <span class="operator">--</span>enable<span class="operator">-</span>fpm <span class="operator">--</span>with<span class="operator">-</span>mysql</span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# make</span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# make install</span><br><span class="line"><span class="comment">/*安装完成，设置PHP*/</span></span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# cp php.ini<span class="operator">-</span>development <span class="regexp">/usr/</span>local<span class="regexp">/php/</span>php.ini</span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# cp <span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="operator">-</span>fpm.conf.default <span class="regexp">/usr/</span>local<span class="regexp">/etc/</span>php<span class="operator">-</span>fpm.conf</span><br><span class="line">[root<span class="meta">@localhost</span> php<span class="operator">-</span><span class="number">5.6</span>.<span class="number">10</span>]# cp sapi<span class="regexp">/fpm/</span>php<span class="operator">-</span>fpm <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span></span><br></pre></td></tr></table></figure>
<h3 id="php操作">3、PHP操作</h3>
<figure class="highlight dns"><table><tr><td class="code"><pre><span class="line">/*启动PHP*/</span><br><span class="line">[root@localhost php-<span class="number">5</span>.<span class="number">6</span>.<span class="number">10</span>]# /usr/local/bin/php-fpm</span><br><span class="line">/*重启PHP*/</span><br><span class="line">[root@localhost iceberg]# ps aux | grep php</span><br><span class="line">root <span class="number">79441 0.0</span> <span class="number">0.6 147960</span> <span class="number">3168</span> ? Ss <span class="number">04:51 0:00</span> php-fpm: master process (/usr/local/etc/php-fpm.conf)</span><br><span class="line">nobody <span class="number">79442 0.0</span> <span class="number">0.5 147960</span> <span class="number">2812</span> ? S <span class="number">04:51 0:00</span> php-fpm: pool www</span><br><span class="line">nobody <span class="number">79443 0.0</span> <span class="number">0.5 147960</span> <span class="number">2812</span> ? S <span class="number">04:51 0:00</span> php-fpm: pool www</span><br><span class="line">root <span class="number">79446 0.0</span> <span class="number">0.1 112640</span> <span class="number">956</span> pts/<span class="number">0</span> S+ <span class="number">04:51 0:00</span> grep --color=auto php</span><br><span class="line">[root@localhost iceberg]# kill -USR<span class="number">2 79441</span></span><br></pre></td></tr></table></figure>
<h2 id="四让nginx支持php">## 四、让nginx支持PHP</h2>
<figure class="highlight php"><table><tr><td class="code"><pre><span class="line">[root@localhost iceberg]<span class="comment"># vi /usr/local/nginx/conf/nginx.conf</span></span><br><span class="line"><span class="comment">/*修改下面的位置，添加index.php,使nginx支持 .php 文件*/</span></span><br><span class="line">location / &#123;</span><br><span class="line">    root   html;</span><br><span class="line">    index  index.html index.htm index.php;</span><br><span class="line">&#125;</span><br><span class="line"><span class="comment">/*保证对于 .php 文件的请求将被传送到后端的 PHP-FPM 模块*/</span></span><br><span class="line">location ~ \.php$ &#123;</span><br><span class="line">    root           html;</span><br><span class="line">    fastcgi_pass   <span class="number">127.0</span>.<span class="number">0.1</span>:<span class="number">9000</span>;</span><br><span class="line">    fastcgi_index  index.php;</span><br><span class="line">    fastcgi_param  SCRIPT_FILENAME  <span class="variable">$document</span>_root<span class="variable">$fastcgi_script_name</span>;</span><br><span class="line">    <span class="keyword">include</span>        fastcgi_params;</span><br><span class="line">&#125;</span><br><span class="line">:wq</span><br><span class="line"><span class="comment">/*重启nginx*/</span></span><br><span class="line">[root@localhost iceberg]<span class="comment"># /usr/local/nginx/sbin/nginx -s reload</span></span><br><span class="line"><span class="comment">/*测试PHP运行*/</span></span><br><span class="line">[root@localhost iceberg]<span class="comment"># vi /usr/local/nginx/html/index.php</span></span><br><span class="line"></span><br><span class="line"><span class="meta">&lt;?php</span></span><br><span class="line"><span class="title function_ invoke__">phpinfo</span>();</span><br><span class="line"></span><br><span class="line">:wq</span><br><span class="line">[root@localhost iceberg]<span class="comment"># </span></span><br></pre></td></tr></table></figure>
<blockquote>
<p><strong>打开浏览器访问http://yourdomain/index.php，如果看到PHP信息就表示安装成功</strong></p>
</blockquote>
]]></content>
      <categories>
        <category>CentOS 7</category>
      </categories>
      <tags>
        <tag>CentOS 7</tag>
        <tag>Nginx</tag>
        <tag>PHP</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 7 PHP安装拓展</title>
    <url>/2015/07/13/CentOS-7-PHP%E5%AE%89%E8%A3%85%E6%8B%93%E5%B1%95/</url>
    <content><![CDATA[<h2 id="一准备以下拓展有选择性安装安装过的不需要安装">##
一、准备（以下拓展有选择性安装，安装过的不需要安装）</h2>
<ul>
<li><p>m4:********</p>
<p>下载页面：<span class="exturl" data-url="aHR0cDovL2Z0cC5nbnUub3JnL2dudS9tNC8=">http://ftp.gnu.org/gnu/m4/<i class="fa fa-external-link-alt"></i></span></p></li>
</ul>
<span id="more"></span>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://ftp.gnu.org/gnu/m4/m4-1.4.17.tar.gz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf m4-1.4.17.tar.gz </span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd m4-1.4.17</span></span><br><span class="line">[root<span class="symbol">@localhost</span> m4<span class="number">-1.4</span><span class="number">.17</span>]<span class="meta"># ./configure </span></span><br><span class="line">[root<span class="symbol">@localhost</span> m4<span class="number">-1.4</span><span class="number">.17</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> m4<span class="number">-1.4</span><span class="number">.17</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>perl：一种语言环境</p>
<p>下载页面：<span class="exturl" data-url="aHR0cHM6Ly93d3cucGVybC5vcmcvZ2V0Lmh0bWwjdW5peF9saWtl">https://www.perl.org/get.html#unix_like<i class="fa fa-external-link-alt"></i></span></p></li>
</ul>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://www.cpan.org/src/5.0/perl-5.22.0.tar.gz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xvzf perl-5.22.0.tar.gz </span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd perl-5.22.0</span></span><br><span class="line">[root<span class="symbol">@localhost</span> perl<span class="number">-5.22</span><span class="number">.0</span>]<span class="meta"># ./configure.gnu </span></span><br><span class="line">[root<span class="symbol">@localhost</span> perl<span class="number">-5.22</span><span class="number">.0</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> perl<span class="number">-5.22</span><span class="number">.0</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<ul>
<li><p>autoconf：根据configure.in和aclocal.m4来产生configure文件</p>
<p>下载页面：http://ftp.gnu.org/gnu/autoconf/</p></li>
</ul>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://ftp.gnu.org/gnu/autoconf/autoconf-2.69.tar.gz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf autoconf-2.69.tar.gz </span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd autoconf-2.69</span></span><br><span class="line">[root<span class="symbol">@localhost</span> autoconf<span class="number">-2.69</span>]<span class="meta"># ./configure </span></span><br><span class="line">[root<span class="symbol">@localhost</span> autoconf<span class="number">-2.69</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> autoconf<span class="number">-2.69</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h2 id="二安装">## 二、安装</h2>
<h3 id="安装igbinary拓展">1、安装igbinary拓展</h3>
<blockquote>
<p>下载页面：<span class="exturl" data-url="aHR0cDovL3BlY2wucGhwLm5ldC9wYWNrYWdlL2lnYmluYXJ5">http://pecl.php.net/package/igbinary<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://pecl.php.net/get/igbinary-1.2.1.tgz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf igbinary-1.2.1.tgz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd igbinary-1.2.1</span></span><br><span class="line">[root<span class="symbol">@localhost</span> igbinary<span class="number">-1.2</span><span class="number">.1</span>]<span class="meta"># /usr/local/bin/phpize </span></span><br><span class="line">[root<span class="symbol">@localhost</span> igbinary<span class="number">-1.2</span><span class="number">.1</span>]<span class="meta"># ./configure --with-php-config=/usr/local/bin/php-config </span></span><br><span class="line">[root<span class="symbol">@localhost</span> igbinary<span class="number">-1.2</span><span class="number">.1</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> igbinary<span class="number">-1.2</span><span class="number">.1</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h3 id="安装curl拓展">2、安装curl拓展</h3>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># yum -y install libcurl-devel.x86_64</span></span><br><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/php-5.6.10/ext/curl/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> curl]<span class="meta"># /usr/local/bin/phpize</span></span><br><span class="line">[root<span class="symbol">@localhost</span> curl]<span class="meta"># ./configure --with-php-config=/usr/local/bin/php-config</span></span><br><span class="line">[root<span class="symbol">@localhost</span> curl]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> curl]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h3 id="安装memcached拓展">3、安装Memcached拓展</h3>
<blockquote>
<ul>
<li>下载页面：<span class="exturl" data-url="aHR0cDovL3BlY2wucGhwLm5ldC9wYWNrYWdlL21lbWNhY2hlZA==">http://pecl.php.net/package/memcached<i class="fa fa-external-link-alt"></i></span><br />
<em>该拓展依赖libmemcached库</em></li>
</ul>
</blockquote>
<blockquote>
<ul>
<li>下载页面：<span class="exturl" data-url="aHR0cHM6Ly9sYXVuY2hwYWQubmV0L2xpYm1lbWNhY2hlZC8rZG93bmxvYWQ=">https://launchpad.net/libmemcached/+download<i class="fa fa-external-link-alt"></i></span></li>
</ul>
</blockquote>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># yum -y install cyrus-sasl.x86_64</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># yum -y install cyrus-sasl-devel.x86_64</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget https://launchpad.net/libmemcached/1.0/1.0.18/+download/libmemcached-1.0.18.tar.gz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf libmemcached-1.0.18</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd libmemcached-1.0.18</span></span><br><span class="line">[root<span class="symbol">@localhost</span> libmemcached<span class="number">-1.0</span><span class="number">.18</span>]<span class="meta"># ./configure --enable-sasl</span></span><br><span class="line">[root<span class="symbol">@localhost</span> libmemcached<span class="number">-1.0</span><span class="number">.18</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> libmemcached<span class="number">-1.0</span><span class="number">.18</span>]<span class="meta"># make install</span></span><br><span class="line">[root<span class="symbol">@localhost</span> libmemcached<span class="number">-1.0</span><span class="number">.18</span>]<span class="meta"># cd ../</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://pecl.php.net/get/memcached-2.2.0.tgz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf memcached-2.2.0.tgz </span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd memcached-2.2.0</span></span><br><span class="line">[root<span class="symbol">@localhost</span> memcached<span class="number">-2.2</span><span class="number">.0</span>]<span class="meta"># /usr/local/bin/phpize </span></span><br><span class="line">[root<span class="symbol">@localhost</span> memcached<span class="number">-2.2</span><span class="number">.0</span>]<span class="meta"># ./configure --with-php-config=/usr/local/bin/php-config --disable-memcached --enable-memcached-igbinary --enable-memcached-json --enable-memcached-sasl</span></span><br><span class="line">[root<span class="symbol">@localhost</span> memcached<span class="number">-2.2</span><span class="number">.0</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> memcached<span class="number">-2.2</span><span class="number">.0</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h3 id="安装redis拓展">4、安装Redis拓展</h3>
<blockquote>
<p>下载页面：<span class="exturl" data-url="aHR0cDovL3BlY2wucGhwLm5ldC9wYWNrYWdlL3JlZGlz">http://pecl.php.net/package/redis<i class="fa fa-external-link-alt"></i></span></p>
</blockquote>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> /]<span class="meta"># cd /home/iceberg/</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># wget http://pecl.php.net/get/redis-2.2.7.tgz</span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># tar -xzvf redis-2.2.7.tgz </span></span><br><span class="line">[root<span class="symbol">@localhost</span> iceberg]<span class="meta"># cd redis-2.2.7</span></span><br><span class="line">[root<span class="symbol">@localhost</span> redis<span class="number">-2.2</span><span class="number">.7</span>]<span class="meta"># /usr/local/bin/phpize</span></span><br><span class="line">[root<span class="symbol">@localhost</span> redis<span class="number">-2.2</span><span class="number">.7</span>]<span class="meta"># ./configure --with-php-config=/usr/local/bin/php-config --disable-redis</span></span><br><span class="line">[root<span class="symbol">@localhost</span> redis<span class="number">-2.2</span><span class="number">.7</span>]<span class="meta"># make</span></span><br><span class="line">[root<span class="symbol">@localhost</span> redis<span class="number">-2.2</span><span class="number">.7</span>]<span class="meta"># make install</span></span><br></pre></td></tr></table></figure>
<h3 id="安装zlib拓展">5、安装zlib拓展</h3>
<figure class="highlight swift"><table><tr><td class="code"><pre><span class="line">[root<span class="meta">@localhost</span> iceberg]# cd <span class="regexp">/home/</span>iceberg<span class="regexp">/php-5.6.10/</span>ext<span class="regexp">/zlib/</span></span><br><span class="line">[root<span class="meta">@localhost</span> zlib]# cp config0.m4 config.m4</span><br><span class="line">[root<span class="meta">@localhost</span> zlib]# <span class="regexp">/usr/</span>local<span class="regexp">/bin/</span>phpize </span><br><span class="line">[root<span class="meta">@localhost</span> zlib]# <span class="operator">./</span>configure <span class="operator">--</span>with<span class="operator">-</span>php<span class="operator">-</span>config<span class="operator">=/</span>usr<span class="regexp">/local/</span>bin<span class="regexp">/php-config --with-zlib-dir=/</span>home<span class="regexp">/iceberg/</span>zlib<span class="operator">-</span><span class="number">1.2</span>.<span class="number">8</span></span><br><span class="line">[root<span class="meta">@localhost</span> zlib]# make</span><br><span class="line">[root<span class="meta">@localhost</span> zlib]# make install</span><br></pre></td></tr></table></figure>
<h2 id="三启用">## 三、启用</h2>
<p><strong>安装完成之后，会打印出生成的.so配置文件位置</strong></p>
<figure class="highlight vim"><table><tr><td class="code"><pre><span class="line">Installing shared extensions: /usr/local/lib/php/extensions/<span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>/</span><br><span class="line">[root@localhost /]# <span class="keyword">cd</span> /usr/local/lib/php/extensions/<span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>/</span><br><span class="line">/*找到刚刚生成的拓展文件文件名*/</span><br><span class="line">[root@localhost <span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>]# <span class="keyword">ls</span></span><br><span class="line">curl.<span class="keyword">so</span>  opcache.<span class="keyword">a</span>  opcache.<span class="keyword">so</span></span><br><span class="line">[root@localhost /]# <span class="keyword">vi</span> /usr/local/lib/php.ini </span><br><span class="line">/*在大概<span class="number">900</span>行左右添加*/</span><br><span class="line">extension=刚刚生成的文件文件名.<span class="keyword">so</span></span><br><span class="line">:<span class="keyword">wq</span></span><br><span class="line"></span><br><span class="line">[root@localhost <span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>]# <span class="keyword">ps</span> aux | <span class="keyword">grep</span> php</span><br><span class="line">root      <span class="number">79567</span>  <span class="number">0.0</span>  <span class="number">0.5</span> <span class="number">148092</span>  <span class="number">2872</span> ?        Ss   <span class="number">05</span>:<span class="number">19</span>   <span class="number">0</span>:<span class="number">00</span> php-fpm: master process (/usr/local/etc/php-fpm.<span class="keyword">conf</span>)</span><br><span class="line">nobody    <span class="number">79568</span>  <span class="number">0.0</span>  <span class="number">0.8</span> <span class="number">148100</span>  <span class="number">4044</span> ?        S    <span class="number">05</span>:<span class="number">19</span>   <span class="number">0</span>:<span class="number">00</span> php-fpm: pool www</span><br><span class="line">nobody    <span class="number">79569</span>  <span class="number">0.0</span>  <span class="number">0.8</span> <span class="number">148100</span>  <span class="number">4020</span> ?        S    <span class="number">05</span>:<span class="number">19</span>   <span class="number">0</span>:<span class="number">00</span> php-fpm: pool www</span><br><span class="line">root     <span class="number">106776</span>  <span class="number">0.0</span>  <span class="number">0.1</span> <span class="number">112640</span>   <span class="number">960</span> <span class="keyword">pts</span>/<span class="number">1</span>    S+   <span class="number">06</span>:<span class="number">41</span>   <span class="number">0</span>:<span class="number">00</span> <span class="keyword">grep</span> --color=auto php</span><br><span class="line">[root@localhost <span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>]# kill -USR2 <span class="number">79567</span></span><br><span class="line">/*验证是否安装成功*/</span><br><span class="line">[root@localhost <span class="keyword">no</span>-<span class="keyword">debug</span>-non-zts-<span class="number">20131226</span>]# /usr/local/sbin/php-fpm -<span class="keyword">m</span></span><br><span class="line">/*查看新安装的拓展在不在下面的列表之内*/</span><br><span class="line">[PHP Modules]</span><br><span class="line">cgi-fcgi</span><br><span class="line">Core</span><br><span class="line">ctype</span><br><span class="line">curl</span><br><span class="line">...</span><br><span class="line">mysql</span><br><span class="line"></span><br><span class="line">[Zend Modules]</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>PHP</tag>
        <tag>PHP Extension</tag>
      </tags>
  </entry>
  <entry>
    <title>CentOS 7 挂载win共享内容</title>
    <url>/2015/07/18/CentOS-7-%E6%8C%82%E8%BD%BDwin%E5%85%B1%E4%BA%AB%E5%86%85%E5%AE%B9/</url>
    <content><![CDATA[<blockquote>
<p>  Web开发，为了使开发环境和服务器环境保持一致，由于服务器环境使用Linux居多，而我们又习惯于使用win系统，所以会经常搭建VMware虚拟机来搭建服务器环境。<br />
  现在问题来了，如何保持VMware虚拟机内的项目代码文件时刻保持最新？我们使用网络共享来解决。</p>
</blockquote>
<p><em>笔者环境：win7+VMware+CentOS-7-x86_64-Minimal</em></p>
<span id="more"></span>
<h2 id="一win系统需要操作部分">## 一、win系统需要操作部分</h2>
<h3
id="找到需要共享的项目文件夹右键----属性----切换到共享tab">1、找到需要共享的项目文件夹，右键----&gt;属性----&gt;切换到共享Tab</h3>
<img src="/2015/07/18/CentOS-7-%E6%8C%82%E8%BD%BDwin%E5%85%B1%E4%BA%AB%E5%86%85%E5%AE%B9/QQ%E5%9B%BE%E7%89%8720150505175211.png" class="" title="[步骤1]">
<h3 id="然后点共享按钮">2、然后点共享按钮</h3>
<img src="/2015/07/18/CentOS-7-%E6%8C%82%E8%BD%BDwin%E5%85%B1%E4%BA%AB%E5%86%85%E5%AE%B9/QQ%E5%9B%BE%E7%89%8720150713141259.jpg" class="" title="[步骤2]">
<p><em>注意选择的登录用户名和权限级别（根据需要选择），然后点击下面的共享按钮，等待修改完成。</em></p>
<h2 id="二服务器端配置">## 二、服务器端配置</h2>
<h3 id="先检查是否有安装cifs-utils">1、先检查是否有安装cifs-utils</h3>
<figure class="highlight csharp"><table><tr><td class="code"><pre><span class="line">[<span class="meta">root@localhost /</span>]<span class="meta"># whereis cifs-utils</span></span><br><span class="line">cifs-utils: /usr/lib64/cifs-utils /etc/cifs-utils <span class="comment">/*已安装*/</span></span><br><span class="line">[<span class="meta">root@localhost /</span>]<span class="meta">#</span></span><br><span class="line"><span class="comment">/*如果没有安装*/</span></span><br><span class="line">[<span class="meta">root@localhost /</span>]<span class="meta"># yum -y install cifs-utils.x86_64</span></span><br></pre></td></tr></table></figure>
<h3 id="开始挂载共享目录">2、开始挂载共享目录</h3>
<figure class="highlight angelscript"><table><tr><td class="code"><pre><span class="line"><span class="string">[root@localhost vhost]</span># mkdir /mnt <span class="comment">/* mnt 创建共享目录挂载的位置*/</span></span><br><span class="line"><span class="string">[root@localhost vhost]</span># mount -t cifs -o username=litl,password=<span class="number">000000</span> <span class="comment">//100.84.56.208/vhosts /mnt/</span></span><br></pre></td></tr></table></figure>
<p><em>输入的密码和两个斜杠（//）中间有空格；</em></p>
<p><em>username的位置需要输入在win端的用户名称，而并不是用户全称，否则会提示Permission
denied（没有权限）</em> <img src="/2015/07/18/CentOS-7-%E6%8C%82%E8%BD%BDwin%E5%85%B1%E4%BA%AB%E5%86%85%E5%AE%B9/QQ%E6%88%AA%E5%9B%BE20150713151032.png" class="" title="[提示]">
<strong>如上图，username=profes，而不是litl</strong></p>
<h3 id="设置开机自动挂载">3、设置开机自动挂载</h3>
<p><strong>编辑/etc/fstab文件，添加代码</strong></p>
<blockquote>
<p>//100.84.56.208/vhosts /mnt/ cifs auto, username=litl,password=000000
0 0</p>
</blockquote>
<h3 id="如果要取消挂载">4、如果要取消挂载</h3>
<figure class="highlight autoit"><table><tr><td class="code"><pre><span class="line">[root<span class="symbol">@localhost</span> vhost]<span class="meta"># umount /mnt/</span></span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>CentOS 7</category>
      </categories>
      <tags>
        <tag>CentOS 7</tag>
        <tag>mnt</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 基础知识</title>
    <url>/2016/06/17/Java-%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86/</url>
    <content><![CDATA[<h4
id="一application-运行于客户端java虚拟机applet运行于支持java的web浏览器中或appletviewer来运行servlet运行在服务端响应客户端请求">一、Application
运行于客户端Java虚拟机；Applet运行于支持Java的Web浏览器中或appletviewer来运行；Servlet运行在服务端，响应客户端请求；</h4>
<h4
id="二static-静态变量类方法可直接调用final-常量终结类终结方法abstract-抽象类抽象方法extends-类继承-interfaceimplements-申明接口接口实现transient-临时常量volatile-共享变量线程native-不同语言集成方法synchronized-多并发线程对共享数据的访问方法">二、static
静态变量/类方法(可直接调用)、final 常量/终结类/终结方法、abstract
抽象类/抽象方法、extends 类继承、 interface/implements
申明接口/接口实现、transient 临时常量、volatile 共享变量(线程)、native
不同语言集成方法、synchronized 多并发线程对共享数据的访问方法；</h4>
<span id="more"></span>
<h4
id="三boolean-instanceof-类型比较调用父类属性构造方法-supersuper">三、boolean
instanceof() 类型比较、调用父类属性/构造方法 super/super()；</h4>
<h4
id="四构造方法和类名相同没有返回类型可重载">四、构造方法和类名相同，没有返回类型，可重载；</h4>
<h4 id="五判断两个对象是否同一">五、“==”判断两个对象是否同一；</h4>
<h4
id="六object所有对象基类java.lang方法">六、Object(所有对象基类)(java.lang)方法：</h4>
<ol type="1">
<li>public final Class getClass() 获取当前对象信息，返回Class类</li>
<li>public String toString() 返回当前对象本身的有关信息</li>
<li>public boolean equals(Object obj) 比较两个对象是否是同一对象</li>
<li>protected Object clone() 生成当前对象的一个备份，返回复制对象</li>
<li>public int hashCode() 返回该对象的哈希代码值</li>
<li>protected void finalize() throws Throwable
定义回收当前对象所需完成的资源释放工作</li>
</ol>
<h4
id="七class类操作类java.lang方法">七、Class(类操作类)(java.lang)方法：</h4>
<ol type="1">
<li>String getName() 返回类名称</li>
<li>Class getSuperclass() 返回类的父类</li>
</ol>
<h4
id="八type数据类型java.lang-方法valueof-转换为接收类型typevalue-转回几本类型parsetype-转换为type类型typedata-转换为type">八、Type(数据类型)(java.lang)
方法：valueOf() 转换为接收类型、typeValue() 转回几本类型、parseTYPE()
转换为TYPE类型，(TYPE)data 转换为TYPE；</h4>
<h4
id="九string常量字符串java.lang方法">九、String(常量字符串)(java.lang)方法：</h4>
<ol type="1">
<li>int length() 返回字符串中字符个数</li>
<li>char charAt(int index) 返回序号index处的字符</li>
<li>int indexOf(String s)
查找子字符串s，匹配繁华第一个字符的序号，否则返回－1</li>
<li>String substring(int begin, int end)
返回从begin开始到end的子字符串</li>
<li>String concat(String s) 返回链接s后的字符串</li>
<li>String replace(char oldChar, char newChar) 替换字符串中的字符</li>
<li>int compareTo(String s)
比较字符串，小于s返回负数，大于s返回正数，否则返回0</li>
<li>boolean equals(String s) 比较两个字符串是否相等</li>
<li>String trim() 去掉字符串两边的空格</li>
<li>String toLowerCase() 将字符串中的字符转换为小写</li>
<li>String toUpperCase() 将字符串中的字符转换为大写</li>
<li>String endsWith(String str) 检测字符串是否以str结尾</li>
</ol>
<h4
id="十stringbuffer变量字符串java.lang方法">十、StringBuffer(变量字符串)(java.lang)方法：</h4>
<ol type="1">
<li>new StringBuffer() 生成容量为16的空字符串对象</li>
<li>new StringBuffer(int size) 生成容量为size的空字符串对象</li>
<li>new StringBuffer(String str)
生成str的一个备份，容量为str的长度＋16</li>
<li>int length() 返回字符串对象的长度</li>
<li>int capacity() 返回字符串对象的容量</li>
<li>void ensureCapacity(int size) 设置字符串对象的容量</li>
<li>void setLength(int len) 设置字符串对象的长度</li>
<li>char charAt(int index) 返回index处的字符</li>
<li>void setCharAt(int index, char c) 将index处的字符设置为c</li>
<li>void getChars(int start, int end, char[] charArray, int newStart)
将start开始到end位置的字符复制到charArray中，从newStart开始</li>
<li>StringBuffer reverse() 返回逆转后的字符串</li>
<li>StringBuffer insert(int index, Object obj)
将obj插入到index的位置</li>
<li>StringBuffer append(Object obj) 将obj链接到字符串的末尾</li>
</ol>
<h4
id="十一character字符处理java.lang方法">十一、Character(字符处理)(java.lang)方法：</h4>
<p><em>字符处理类，用来确定是否是空字符、是否是字母、是否是数字。。。</em></p>
<h4
id="十二stringtokenizer字符串分割java.util方法">十二、StringTokenizer(字符串分割)(java.util)方法：</h4>
<ol type="1">
<li>StringTokenizer(String aString) 用空格分隔aString</li>
<li>StringTokenizer(String aString, String delimiters)
用delimiters[,:;|_()]分隔aString</li>
<li>StringTokenizer(String aString, String delimiters, boolean
returnDelimiters) 是否返回分隔符</li>
<li>countTokens() 单词个数</li>
<li>nextToken() 逐出单词</li>
<li>hasMoreTokens() 是否还有单词；</li>
</ol>
<h4
id="十三math数学类java.lang方法">十三、Math(数学类)(java.lang)方法：</h4>
<ol type="1">
<li>final static
sin/cos/tan/roound(四舍五入)/ceil(向上)/floor(向下)/sqrt(开根)/pow/exp/log/max(最大)/min(最小)/random(随机)()；</li>
</ol>
<h4
id="十四system系统java.lang方法">十四、System(系统)(java.lang)方法：</h4>
<ol type="1">
<li>arraycopy() 复制一个数组</li>
<li>exit() 结束程序</li>
<li>currentTimeMillis() 获取日期时间</li>
<li>gc() 释放资源；</li>
</ol>
<h4
id="十五runtime运行时类java.lang方法">十五、Runtime(运行时类)(java.lang)方法：</h4>
<ol type="1">
<li>totalMemory() 内存总量</li>
<li>freeMemory() 内存剩余空间；</li>
</ol>
<h4
id="十六date日期类java.util方法">十六、Date(日期类)(java.util)方法：</h4>
<ol type="1">
<li>Date() 返回当前时间</li>
<li>Date(long date) 创建date的日期的对象</li>
<li>long getTime() 时间(毫秒)</li>
<li>after(Date d) 是否在d之后</li>
<li>before(Date d) 是否在d之前；</li>
</ol>
<h4
id="十七gregoriancalendar日期类java.util方法">十七、GregorianCalendar(日期类)(java.util)方法：</h4>
<ol type="1">
<li>Date getTime() 获取日期对象</li>
<li>isLeapYear(int year) 是否闰年</li>
<li>get(int field) 获取对象信息</li>
<li>set(int field, int value) 设定值；</li>
</ol>
<h4
id="十八simpledateformat日期格式java.text方法">十八、SimpleDateFormat(日期格式)(java.text)方法：</h4>
<ol type="1">
<li>SimpleDateFormat(formatString) 指定格式构造</li>
<li>format(aDate) 将构造格式应用；</li>
</ol>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 多线程基础</title>
    <url>/2016/06/17/Java-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%9F%BA%E7%A1%80/</url>
    <content><![CDATA[<h4
id="一thread多线程基类java.lang在run方法中重写新线程执行语句">一、Thread(多线程基类)(java.lang)：在run方法中重写新线程执行语句；</h4>
<ol type="1">
<li>public Thread() 构造一个新线程对象</li>
<li>public Thread(Runnable target)
构造一个新线程对象，以Runnable对象为参数</li>
<li>public Thread(String name) 构造一个新线程对象，指定线程名</li>
<li>public static Thread currentThread() 返回当前运行的线程对象</li>
<li>public static void yield() 是当前线程暂停，允许别的线程开始运行</li>
<li>public static void sleep(long milis)
使当前线程暂停运行指定豪秒数，不是去锁旗标</li>
<li>public void start() 启动线程，运行该线程的run方法</li>
<li>public void run()
Thread的子类应重写此方法，内容为要执行的程序任务</li>
<li>public final void stop() 停止线程运行，释放锁旗标</li>
</ol>
<span id="more"></span>
<ol start="10" type="1">
<li>public void interrupt() 中断线程</li>
<li>public final void join()
如果此前启动了线程a，将等待线程a死亡才继续执行当前线程</li>
<li>public final void join(long milis)
如果此前启动了线程a，将等待指定豪秒数或线程a死亡才继续执行当前线程</li>
<li>public final void setPriority(int newPriority)
设置线程优先级，优先级0～10之间</li>
<li>public final void setDaemon(Boolean on)
设置该线程是否为后台线程，start之前使用</li>
<li>public final void checkAccess()
判断当前线程是否有权力修改调用此方法的线程</li>
<li>public final void setName(String name) 修改线程的名称</li>
<li>public final boolean isAlive() 测试线程是否处于活跃状态</li>
</ol>
<h4
id="二runnable多线程共享java.lang-线程间共享数据多个线程处理同一资源">二、Runnable(多线程共享)(java.lang)
线程间共享数据，多个线程处理同一资源</h4>
<h4
id="三锁旗标每个对象都有一个锁旗标">三、锁旗标：每个对象都有一个锁旗标</h4>
<ol type="1">
<li>synchronized(Object){code text}</li>
<li>public synchronized function(){}</li>
</ol>
<h4
id="四后台线程调用setdaemon方法后线程就变成后台线程前台线程结束则后台线程结束">四、后台线程：调用setDaemon()方法后线程就变成后台线程，前台线程结束则后台线程结束</h4>
<h4 id="五线程通信">五、线程通信：</h4>
<ol type="1">
<li>public final void wait()
暂停执行线程进入等待池并释放锁旗标，直到其它线程释放锁旗标唤醒</li>
<li>public void notify() 唤醒正在等待该对象锁旗标的第一个线程</li>
<li>public void notifyAll()
唤醒所有等待该对象锁旗标的线高优先级的线程先执行</li>
</ol>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 对象群体组织</title>
    <url>/2016/06/17/Java-%E5%AF%B9%E8%B1%A1%E7%BE%A4%E4%BD%93%E7%BB%84%E7%BB%87/</url>
    <content><![CDATA[<h4 id="一数组排序方法">一、数组排序方法：</h4>
<ol type="1">
<li>选择排序 <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span> temp;</span><br><span class="line"><span class="type">int</span>[] arr = &#123;<span class="number">4</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">6</span>&#125;;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>; i&lt;arr.length-<span class="number">1</span>; i++)&#123;</span><br><span class="line">    <span class="keyword">for</span>(<span class="type">int</span> j=i+<span class="number">1</span>; j&lt;array.length; j++)&#123;</span><br><span class="line">        <span class="keyword">if</span>(arr[i] &lt; arr[j])&#123;</span><br><span class="line">            temp = arr[i];</span><br><span class="line">           arr[i] = arr[j];</span><br><span class="line">           arr[j] = temp;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></li>
</ol>
<span id="more"></span>
<ol start="2" type="1">
<li>插入排序： <figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">int</span>[] arr = &#123;<span class="number">4</span>, <span class="number">8</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">0</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">6</span>&#125;;</span><br><span class="line"><span class="type">int</span> temp;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;arr.length;i++)&#123;</span><br><span class="line">    temp = arr[i]; </span><br><span class="line">    <span class="type">int</span> <span class="variable">j</span> <span class="operator">=</span> i-<span class="number">1</span>; 　　　　</span><br><span class="line">    <span class="keyword">while</span>(j &gt; -<span class="number">1</span> &amp;&amp; temp &gt; arr[j])&#123;</span><br><span class="line">        arr[j+<span class="number">1</span>] = arr[j];</span><br><span class="line">        j—;</span><br><span class="line">    &#125;</span><br><span class="line">    arr[j+<span class="number">1</span>] = temp;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> ####
二、Collection接口(java.util)：所有子类都可以使用</li>
<li>int size() 返回集合中元素数量</li>
<li>boolean isEmpty() 判断集合中是否包含元素</li>
<li>boolean contains(Object obj) 判断给定对象是否在集合中</li>
<li>boolean containsAll(Collection c) 判断是非包含c中所有元素</li>
<li>boolean add(Object obj) 添加obj到集合对象</li>
<li>boolean addAll(Collection c) 添加c中所有元素到集合中</li>
<li>boolean remove(Object obj) 从集合中删除obj元素</li>
<li>boolean removeAll(Collection c) 从集合中删除c中的所有元素</li>
<li>void clear() 删除集合中的所有元素</li>
</ol>
<h4
id="三set接口collection子接口禁止重复元素如果两个set对象包含相同元素则相等">三、Set接口(Collection子接口)：禁止重复元素，如果两个Set对象包含相同元素，则相等</h4>
<h4
id="四sortedset接口set子接口元素升序排列">四、SortedSet接口(Set子接口)：元素升序排列</h4>
<h4
id="五list接口collection子接口有顺序的可以重复的有数字键值">五、List接口(Collection子接口)：有顺序的、可以重复的、有数字键值</h4>
<h4
id="六map接口java.util从一个关键字到值的映射不能有重复的关键字">六、Map接口(java.util)：从一个关键字到值的映射，不能有重复的关键字</h4>
<ol type="1">
<li>int size() 返回元素个数</li>
<li>boolean isEmpty() 返回map中是否还包含元素</li>
<li>boolean containsKey(Object key) 判断给定的key是否是Map中的键值</li>
<li>boolean containsValue(Object val)
判断给定的val是否是Map中的一个值</li>
<li>Object get(Object key) 返回Map中key的关联值</li>
<li>Collection values() 返回包含所有值的Collection对象</li>
<li>Set keySet() 返回包含Map中所有键值的Set对象</li>
<li>Set entrySet() 返回包含Map中所有项的Set对象</li>
<li>Object put(Object key, Object val) 添加键值对到Map中</li>
<li>void putAll(Map m) 将m中所有的键值对添加到Map中</li>
<li>Object remove(Object key) 删除Map中的key</li>
<li>void clear() 删除所有键值对</li>
</ol>
<h4
id="七sortedmap接口map子接口关键字升序排列">七、SortedMap接口(Map子接口)：关键字升序排列</h4>
<h4 id="八arrays操作数组静态方法">八、Arrays(操作数组静态方法)：</h4>
<ol type="1">
<li>equals(type[] a, type[] b) 比较两个数组</li>
<li>fill(type[] a, type val) 给数组填充</li>
<li>sort(type[] a) 排序</li>
<li>binarySearch() 对数组元素二分法查找</li>
<li>asList(Object[] a) 数组转换为ArrayList</li>
</ol>
<h4
id="九vectorarraylist实现collection实现接口collection中方法">九、Vector/ArrayList(实现Collection)：实现接口Collection中方法</h4>
<ol type="1">
<li>new Vector/ArrayList() 初始容量为10</li>
<li>new Vector/ArrayList(int cap) 初始容量为cap</li>
<li>new Vector/ArrayList(Collection col) 使用集合对象初始化</li>
<li>Object get(int pos) 返回pos位置的元素(取出后需要塑形)</li>
<li>void set(int pos, Object obj) 设置pos位置的值</li>
<li>Object remove(int pos) 删除指定位置的元素，并返回</li>
<li>int indexOf(Object obj)
返回obj在集合中第一次出现的位置，不存在返回－1</li>
<li>Enumeration elements()
返回包含Vector中所有元素的Enumeration类对象</li>
<li>Iterator iterator() 返回所有元素的Iterator类对象</li>
</ol>
<h4
id="十hashtablehashmap实现map接口实现map接口中方法hashtable不允许有空键">十、HashTable/HashMap(实现Map接口)：实现Map接口中方法，HashTable不允许有空键</h4>
<ol type="1">
<li>Enumeration elements() 返回包含值的Enumeration对象</li>
<li>Enumeration keys() 返回包含键的Enumeration对象；</li>
</ol>
<h4
id="十一enumeration类遍历集合不能用于arraylist">十一、Enumeration类(遍历集合)：不能用于ArrayList</h4>
<ol type="1">
<li>hasMoreElements() 判断是否还有剩下的元素</li>
<li>nextElement() 取得下一个元素</li>
</ol>
<h4 id="十二iterator类遍历集合">十二、Iterator类(遍历集合)：</h4>
<ol type="1">
<li>hasNext() 判断是否还有元素</li>
<li>next() 取得下一个元素</li>
<li>remove() 去除元素</li>
</ol>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 种类和运行方式</title>
    <url>/2016/06/17/Java-%E7%A7%8D%E7%B1%BB%E5%92%8C%E8%BF%90%E8%A1%8C%E6%96%B9%E5%BC%8F/</url>
    <content><![CDATA[<h4 id="application">Application</h4>
<p>　　Application是一个运行在客户端Java虚拟机上的Java程序。它可在客户端机器中读写，可使用自己的主窗口、标题栏和菜单，程序可大可小。</p>
<p>　　Application可以运行在最简单的环境中，能够以命令行参数的方式接收来自外部的数据。应用程序从命令行开始运行，其主类必须有一个主方法<code>main()</code>，作为程序运行的入口。</p>
<span id="more"></span>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWord</span>&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String arg[])</span>&#123;</span><br><span class="line">        <span class="comment">//do work code</span></span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h4 id="applet">Applet</h4>
<p>　　Applet被称为小应用程序，运行于支持Java的Web浏览器中。浏览器的解释器把字节码转换成和机器匹配的指令，在网页中执行小程序。Applet和Application的差别来自于运行环境的不同。Applet需要来自Web浏览器的大量信息：它需要知道何时启动、何时放在浏览器窗口中、何时何处激活或者关闭。小应用程序总是放在Web浏览器的图形用户界面中。</p>
<p>　　Applet的优点在于Web浏览器软件包括很多小应用程序运行所需的功能；局限性时不能从客户端主机的文件系统中读/写，不能运行客户端主机的任何程序，仅能在服务器和客户端之间建立联系。
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">import</span> java.awt.Graphics;</span><br><span class="line"><span class="keyword">import</span> java.applet.Applet;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">HelloWord</span> <span class="keyword">extends</span> <span class="title class_">Applet</span>&#123;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">init</span><span class="params">()</span>&#123; </span><br><span class="line">　　　　　<span class="comment">//初始化变量、装载图片、读取参数值等</span></span><br><span class="line">　　&#125;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span>&#123; </span><br><span class="line">　　　　　<span class="comment">//启动程序执行或恢复程序执行</span></span><br><span class="line">　　&#125;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span><span class="params">()</span>&#123; </span><br><span class="line">　　　　　<span class="comment">//挂起正在执行的程序，暂停程序的执行</span></span><br><span class="line">　　&#125;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">destroy</span><span class="params">()</span>&#123; </span><br><span class="line">　　　　　<span class="comment">//终止程序的执行释放资源</span></span><br><span class="line">　　&#125;</span><br><span class="line">　　<span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">paint</span><span class="params">(Graphics g)</span>&#123; </span><br><span class="line">　　　　　<span class="comment">//完成绘制图形等操作</span></span><br><span class="line">　　&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure> <figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>Java Applet<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">applet</span> <span class="attr">code</span>=<span class="string">&quot;HelloWord.class&quot;</span> <span class="attr">width</span>=<span class="string">&quot;400&quot;</span> <span class="attr">height</span>=<span class="string">&quot;200&quot;</span>&gt;</span><span class="tag">&lt;/<span class="name">applet</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure> &gt; 运行方式：appletviewer
***.html或浏览器打开</p>
<h4 id="servlet">Servlet</h4>
<p>　　就像Applet拓展了浏览器的功能一样，Servlet运行在服务器端，响应客户的请求，拓展了服务器的功能。Servlet并没有跟客户端的特定协议绑定，但是通常使用的是超文本传送协议（HTTP）。</p>
<h4 id="jsp">JSP</h4>
<p>　　JSP是JavaServer
Pages的缩写，是Servlet技术的拓展，目的是为了简化动态网页的构建和管理。JSP将Html语句和Java程序代码结合在一起，简化了网页的维护。JSP可以重用JavaBean，创建自定义的标签库以封装复杂的功能。于JSP编程有关的类和接口位于<code>javax.servlet.jsp</code>和<code>javax.servlet.jsp.tagext</code>包中。
　　 <figure class="highlight html"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">title</span>&gt;</span>JSP<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">h1</span>&gt;</span>The time in second is:&lt;%=System.currentTimeMillis()/1000 %&gt;&lt;/h1 &gt;</span><br><span class="line">    <span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">html</span>&gt;</span></span><br></pre></td></tr></table></figure> #### JavaBean</p>
<p>　　JavaBean是一个轻便的、不依赖平台的Java组件模型，它的目的是在其他基于构件的结构中连接Java构件。这是的Java程序可以集成到非Java应用程序中，从而拓展Java的用途。使用JavaBean不必重写程序就能使构件连接到一起，是应用程序开发更容易，提高程序的可复用性。JavaBean是离散的，可复用的。JavaBean的主要特性为：跨平台兼容性；易于即成到当前平台；易于构件间通信；简化应用程序开发。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 语言特性</title>
    <url>/2016/06/17/Java-%E8%AF%AD%E8%A8%80%E7%89%B9%E6%80%A7/</url>
    <content><![CDATA[<h4 id="抽象">抽象</h4>
<p>　　抽象就是忽略问题中与当前目标无关的那些方面，以便更充分的注意与当前目标有关的方面。</p>
<p>　　过程抽象将整个系统的功能划分为若干部分，强调功能完成的过程和步骤，而隐藏其具体的实现。任何一个明确定义的功能操作都可被使用者作为单个的实体看待，尽管这个操作实际上可能由一系列更低级的操作来完成。基于过程抽象的两个标准程序设计技术是过程分解及递归技术。</p>
<p>　　数据抽象是将系统中需要处理的数据和这些数据上的操作结合在一起，抽象成不同的抽象数据类型，每个抽象数据类型既包含了数据，也包含了针对这些数据的操作。相对于过程抽象，数据抽象是更为合理的抽象方法。</p>
<p>　　面向对象的软件开发方法的主要特点之一就是采用了数据抽象的方法来构建程序的类以及对象。</p>
<span id="more"></span>
<h4 id="封装">封装</h4>
<p>　　面向对象的封装特性与抽象特性密切相关。封装是一种信息隐蔽技术，就是利用抽象数据类型将数据和基于数据的操作封装在一起。用户只能看到对象的封装界面信息，对象的内部细节对用户是隐蔽的。封装的目的在于将对象的使用者和设计者分开，使用者不必知道行为实现的细节，只需使用设计者提供的消息来访问对象。</p>
<p>　封装的定义是：</p>
<p>　（1）清楚的边界，所有对象的内部信息被限定在这个边界内；</p>
<p>　（2）接口，既对象向外界提供的方法，外界可以通过这些方法和对象进行交互；</p>
<p>　（3）受保护的内部实现，既软件对象功能的实现细节，实现细节不能从类外访问。</p>
<p>　　通过封装规定了程序如何使用对象的数据，控制用户对类的修改和数据访问权限。多数情况下往往会紧致直接访问对象的数据，只能通过接口访问对象。</p>
<p>　　在面相对象的程序设计中，抽象数据类型是用“类”来实现的，类封装了数据及对数据的操作，是程序中的最小模块。由于封装特性紧致了外界直接操作类中的数据，模块和模块之间只能通过严格控制的接口进行交互，这使得模块之间的耦合度大大降低，从而保证了模块具有很好的独立性，使得程序维护和修改较为容易。</p>
<h4 id="继承">继承</h4>
<p>　　继承是指新的类可以获得已有类（称为父类或基类）的属性和行为，称新类为已有类的派生类（或子类）。继承是类联结的层次模型，为类的重用提供了方便，它提供了明确表述不同类之间的共性的方法。新类从现有类中派生的过程，称为继承。在继承过程中派生类继承了基类的特性，包括方法和实例变量，派生类也可以修改继承的方法或新增新的方法使之更适合特殊的需要。这也体现了自然社会中一般与特殊的关系。继承性很有助于解决软件的可重用性问题。使用继承使程序结构清晰，降低了编码和维护的工作量。</p>
<p>　　在面向对象的继承特性中，还有一个关于单继承和多继承的概念。单继承是指任何一个派生类都只有一个单一的直接父类；而多继承是指一个类可以有一个以上的直接父类。采用单继承的类层次结构为树状结构；采用多继承的类层次为网状结构，设计和实现都比较复杂。</p>
<p>　　Java语言仅支持单继承。</p>
<h4 id="多态">多态</h4>
<p>　　多态是面相对象程序设计的又一个特殊特性。在面向过程的程序设计中，只要工作是编写一个个的过程或函数，这些过程和函数不能重名。</p>
<p>　　在面向对象程序设计中，可以利用“重名”来提高程序的抽象度和简洁性。</p>
<p>　　多态是指一个程序中同名的不同方法共存的情况。主要通过子类对父类方法的覆盖来实现多态。这样一来，不同类的对象可以响应同名的消息（方法）来完成特定的功能，但其具体的实现方法却可以不同。</p>
<p>　　多态性使语言具有灵活、抽象、行为共享、代码共享的优势，很好的解决了应用程序函数同名的问题。</p>
<h4 id="重载">重载</h4>
<p>　　方法的重载（overloading）是指在一个类中可以有名字相同的多个方法，但这些方法的参数必须不同，或者参数的个数不同，或者参数的类型不同。返回值可以相同也可以不同。</p>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>Java 输入输出流</title>
    <url>/2016/06/17/Java-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81/</url>
    <content><![CDATA[<h4
id="一iojava.io操作必须抛出ioexception异常">一、I/O(java.io)：操作必须抛出IOException异常</h4>
<ol type="1">
<li>close() 关闭流；</li>
</ol>
<span id="more"></span>
<h4
id="二inouterr标准输入输出错误流java.lang.system方法">二、in/out/err(标准输入/输出/错误流)(java.lang.System)方法：</h4>
<ol type="1">
<li>System.in是InputStream(字节流)类型</li>
<li>System.out/System.err是printStream类型</li>
<li>System.out.print() 输出字符</li>
<li>System.out.println() 输入字符并换行；</li>
</ol>
<h4 id="三字符流readerwriter">三、字符流Reader/Writer：</h4>
<ol type="1">
<li>write() 写内容到流</li>
<li>read() 读流内容</li>
<li>read(byte b) 读取b大小的数据、返回－1则文件末位</li>
<li>InputStreamReader：读取字节流并转换成字符流</li>
<li>FileReader：打开一个指定文件名的输入流</li>
<li>FileWriter：FileWriter(filename) 新建指定文件名的输出流</li>
<li>FileWriter(filename, Boolean append) 指定文件名的输出流实现续写</li>
<li>BufferedReader：对输入流缓存、readLine()
读取一行数据，如果没数据返回null</li>
<li>BufferedWriter：对输出流缓存、newLine() 输出换行符</li>
</ol>
<h4
id="四字节流inputstreamoutputstream">四、字节流InputStream/OutputStream：</h4>
<ol type="1">
<li>FileOutputStream：打开指定文件名的输出流</li>
<li>FileInputStream：创建指定文件名的输入流</li>
<li>DataOutputStream：提供写基本数据类型的方法</li>
<li>DataInputStream：提供读基本数据类型的方法、文件末位会抛出EOFException异常</li>
<li>BufferedOutputStream：缓存输出流</li>
<li>BufferedInputStream：缓存输入流</li>
</ol>
<h4
id="五处理压缩java.util.zip方法">五、处理压缩(java.util.zip)方法：</h4>
<ol type="1">
<li>GZIPOutputStream：指定输出流的压缩</li>
<li>ZipOutputStream：指定输出流的压缩</li>
<li>putNextEntry(ZipEntry)</li>
<li>GZIPInputStream：指定输入流解压</li>
<li>ZipInputStream：指定输入流解压</li>
<li>getNextEntry()
获取压缩文件内下一个文件，返回ZipEntry对象，没有返回null</li>
<li>ZipEntry：ZipEntry(filename) 压缩文件内每一个文件对象</li>
<li>getName() 返回压缩文件最初名称</li>
<li>isDirectory() 检测是否是文件夹</li>
</ol>
<h4
id="六接口serializable实现对象序列化接口">六、接口Serializable：实现对象序列化接口</h4>
<ol type="1">
<li>ObjectInputStream：对象的输入流</li>
<li>writeObject() 写对象</li>
<li>ObjectOutputStream：对象的输出流</li>
<li>readObject() 读入对象</li>
<li>RandomAccessFile(filename, model)
创建带model权限的一个随机文件读写</li>
<li>seek(Int n) 移到n的地方</li>
<li>writeType() 写Type类型的数据</li>
<li>readType() 读Type类型的数据</li>
</ol>
<h4
id="七file文件读写java.io方法">七、File(文件读写)(java.io)方法：</h4>
<ol type="1">
<li>public File(String name) 指定与File对象关联的文件或目录</li>
<li>public File(String pathToName, String name)
使用pathToName来定位name指定的文件或目录</li>
<li>public File(File directory, String name)
使用现有的File对象来定位name所指定的文件或目录</li>
<li>public File(URI rui) 使用给定的资源定位符来定位文件</li>
<li>public static final String pathSeparator 获取适用于本季的分隔符</li>
<li>boolean canRead() 文件是否可读</li>
<li>boolean canWrite() 文件是否可写</li>
<li>boolean exists() 是否是文件或目录</li>
<li>boolean createNewFile()
如果文件不存在则创建这个文件，返回真，否则返回假</li>
<li>boolean isFile() 是否是一个文件</li>
<li>boolean isDirectory() 是否是一个目录</li>
<li>boolean isAbsolute() 是否是一个文件或绝对路径目录</li>
<li>boolean delete() 删除文件或目录</li>
<li>String getAbsolutePath() 返回一个包含文件或目录绝对路径的字符串</li>
<li>String getName() 返回一个包含文件名或目录名的字符串</li>
<li>String getPath() 返回一个半酣文件或目录路径的字符串</li>
<li>String getParent() 返回父路径</li>
<li>long length() 返回文件的字节长度，目录返回0</li>
<li>long lastModified() 返回文件或目录最近一个修改时间</li>
<li>String[] list() 返回一个目录中内容的字符串数组，不是目录返回null
#### 附件：所有I/O类参考 <img src="/2016/06/17/Java-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81/QQ20151228-2@2x.png" class="" title="[所有I&#x2F;O类 附件1]"><br />
<img src="/2016/06/17/Java-%E8%BE%93%E5%85%A5%E8%BE%93%E5%87%BA%E6%B5%81/QQ20151228-3@2x.png" class="" title="[所有I&#x2F;O类 附件2]"></li>
</ol>
]]></content>
      <categories>
        <category>JAVA</category>
        <category>基础知识</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
      </tags>
  </entry>
  <entry>
    <title>大数据概述</title>
    <url>/2016/06/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<blockquote>
<p><strong>文章中提到的所有内容和名词包括释义都只是<code>博主个人观点</code>。且博主为互联网软件工程师出身，有些观点可能会有<code>偏向性</code>或<code>片面性</code>，请<code>有选择的进行阅读</code>。</strong><br />
另文章为作者原创，如需转载敬请注明出处，谢谢！
本文撰写与<code>2016年6月</code>，所以不保证未来几年内，文中的有些观点还站得住脚。</p>
</blockquote>
<h2 id="零大数据的魅力">零、大数据的魅力</h2>
<img src="/2016/06/23/%E5%A4%A7%E6%95%B0%E6%8D%AE%E6%A6%82%E8%BF%B0/QQ20160621-0@2x.png" class="" title="[一个大数据研究方向的例子]">
<p>  你可能会觉得这个例子比较简单，因为一个每天会上网看新闻的人都应该知道这些娱乐八卦新闻，但是从技术的角度来看，机器并不认识这些娱乐明星，也不会了解他们之间这种繁杂的关系，所以要理清这些娱乐明星的关系，就必须通过一些数据的计算和整理，分析的数据量越多，就越能证明这个关系的准确性。<br />
  机器处理和分析也不会单一的只是例子中给出的人物关系，而是成千上万的娱乐明星、政坛大鳄和历史人物等等等等，如果要考虑人工去一一整理，这无疑是一项巨大且不可能完成的任务，并且维护起来也是很困难的，这样就引入了大数据这个概念。</p>
<span id="more"></span>
<h2 id="一认识大数据">一、认识大数据</h2>
<p>  大数据是什么？多大的数据才能称为大数据？<br />
  就好比上面的例子，怎么才能让机器理清这些人物关系呢？如果是一个历史人物的人物关系，那么一些竟可能多的历史资料则作为研究的样本，即数据，然后将这些数据丢给机器去辨认、学习和整理得出的结果就是人物关系的图谱，而为了使该人物关系图谱更加的准确和可信，我们需要更多的历史资料让机器学习来得到一个能准确描述事实本身的结果数据。这应该可以让我们可以简单了解到大数据。<br />
  其实个人理解，大数据应该属于一个学术范畴或是一个研究过程，而不是简单的指明为量很大的数据，或者说多大量级的数据只是作为一个大数据的载体或是内容形式罢了。大数据应该从根本上来释义的话，应该是对数据的计算、研究、分析和整理然后得到有效应用的过程。<br />
  为什么叫大数据呢？其实大数据从字面上来理解的话其实就是一堆很多的数据，但是事实上，数据的量级并不能直接去定义和解释大数据一词，如果你有上TB或者PB级别的数据，但只是以Log形式简单提供项目运行勘错的能力，那么只能说你有一堆数据，而不见得你有大数据处理的能力；如果你只有GB甚至只是MB级别的数据量，但是你合理分析并将数据分析结果应用到实际项目的发展方向、优化空间和用户研究等，那么可以说你已经具备大数据的能力。<br />
  直接用量型单位大来表述大数据，其直接原因还是对处理数据的量级最直接的表现，因为要保证研究、分析和实验结果的准确性和更贴近事物本身，需要尽可能多的数据样本做支撑，所以习惯意义上我们直呼其为大数据。<br />
  其实大数据不是只局限于对数据、数据处理和数据分析运用本身，大数据是一个很宽泛的概念，其中包括了上面所提到的范畴外，还包含了对大的数据请求、响应和安全储存等方方面面。<br />
  作为日常用户本身，我们生活中方方面面都会接触到大数据，不同的是我们只是关注于大数据给我们生活带来的便利，而不会去关注大数据的处理和反馈过程。举些简单的例子：你每天上网购物、银行流水、购物推荐、上网看电影听音乐等等等等，你应该感觉到这些日常生活中的服务都变得越来越人性化和智能化，这些都完全得益于大数据，得益于那些每天熬夜加班的数据研究工作者和数据工程师们，我们应该真心感谢这些人，因为是他们让我们的生活变得如此的丰富和多姿。</p>
<h2 id="二大数据起源">二、大数据起源</h2>
<p>  数据是大数据的根本所在，所以数据直接决定了大数据的发展或者说大数据的发展和研究成果完全依赖于数据。<br />
  我们生活在一个科技迅猛发展的时代，而数据就像我们日常生活中的生活垃圾，是无时无刻不在产生的。如果你身边放着任何一个正常运行的电子设备，那么你就在不停的生产数据，所以在大数据中，我们每个人充当了一个生产者的角色。<br />
  其实在科技没有很发达甚至互联网不存在的古代，我们也已经充当了数据生产者的角色，举个例子，如果有一家卖馒头的店铺，当有一天买花卷的人很多，花卷的销量很好的时候，很自然的老板会在第二天多蒸一些花卷出来卖，这就是一个简单的大数据例子，当有客人每买一次馒头的同时也生产了一次数据，而馒头店老板通过分析和整理这些数据，他会在第二天多蒸一些花卷来避免花卷热销导致花卷断货而流失的一批喜欢吃花卷客户。把这个例子在进一步假设，如果一个月下来馒头店老板发现有时候还会出现花卷在第一天卖不出去导致第二天就馊了的情况，这无疑是馒头店老板的一笔损失，但是经过对一个月花卷销量的分析和整理，发现每个礼拜天的时候花卷的销量不是很好，反而礼拜五的时候买花卷的人会很多，所以老板就可以在礼拜五适当的比平时多蒸一点花卷出来，而礼拜天的时候控制减少花卷的数量，这样一来就会很好的控制花卷变馊的数量，从而降低老板的损失。我们在购物行为中日积月累生产了一些数据，而馒头店老板做为了这些数据的直接消费者。馒头店的老板刚开始用一天的数据做分析，结果花卷是可以满足市场的需求了，但是销售成本也因为馊了的馒头而上升了。后来通过对一个月的数据做分析后，馒头店老板很好的控制了成本。通过例子很容易理解数据对大数据分析结果可信度和接近事物本身的直接影响。<br />
  博主主要讨论的只是偏向于互联网方向的大数据，对传统数据不做讨论。<br />
  从互联网最初开始的阶段，因为作为数据生产者的人很少，并且生产数据的频次也很低，所以在整个互联网界很难找到一个数据消费者，或者说没有人去主动消费这些数据。随着科技的发展，互联网内容并承井喷式发展，直接参与数据生产的生产者越来越多，数据生产的频率也在直线上升。而一个有意思的现象是，现在的数据直接消费者在互联网发展初期并没有重视对数据的挖掘，而日趋增长的数据量级持续困扰着他们，包括他们要为承井喷式的数据生产者提供不间断稳定的服务、这些<code>数据垃圾</code>存储问题等等，其中数据存储问题算是一个比较小的问题，因为存储消耗的只是成本而已，但是因为数据生产者队伍的不断扩大和生产频率的增加无疑是致命的，比较直接的例子就是<code>12306</code>的订票问题，由于<code>12306</code>的特殊性，导致所有业内互联网公司的并发性访问问题都得到妥善解决的时候，它还是一个国民性大数据难题（虽然已经通过各种限制手段也算是解决了问题）。
  人都是永远不会满足的，也正是因为这个人性的特殊性，所以才使得社会不停的进步，我们所处的世界也会日新月异。当工程师们解决了多并发请求响应的时候，他们的目光转向了那堆消耗成本的<code>数据垃圾</code>上，又不能直接丢了，却要做好成本控制，所以最好的做法就是将垃圾回收，变废为宝嘛。就是这样的，大数据就开始发展起来了。</p>
<h2 id="三拥抱大数据">三、拥抱大数据</h2>
<p>  值得一提的是，国内的大数据还是起步状态，BAT也不例外。所以现在入门大数据做个算法工程师啥的，绝对是牛逼哄哄，现在市场上对大数据工程师是供不应求，只要参与过大数据相关工作的工程师都是抢手货。
  由于国内各大公司的大数据部门也都在摸索阶段，所以业界除了共用一些处理工具（如<code>Hadoop</code>、<code>word2vec</code>...）外，还没有统一的知识体系，研究成果也都各有所长，其实还因为国内技术的闭源环境，使得大数据甚至所有技术都各成一家、各成一派。有人曾经说过，如果把BAT三家互联网公司的数据整合起来，通过对数据的分析可以准确给任何一个数据生产者画像，包括年龄、性别、兴趣、社交关系、社会属性以及购物取向，或者研究的更深点，可以准确预知一个数据生产者将要做的事儿，当然在社会事业上也能大显身手，最直接的就是通过出行意向去调剂交通压力。不过这都是人们意淫而已，因为BAT在忙着掐架，顾不上这件可有可无的<code>大事</code>。
  说了这么多，最后简单说一下博主目前了解的几个大数据研究方向和简单案例吧：</p>
<h3 id="指标统计">指标统计</h3>
<p>  最基础的大数据方向，就是统计页面或站点的<code>PV/UV</code>等基础指标，不过相当一部分的公司会选择直接使用其他现成的统计，免费还不费力。不过当你要统计一个复杂或者是自己想知道的数据就无能为力了。<br />
  如果你尝试从一些仅有的数据中去充分分析而不是简单的只关注<code>PV/UV</code>的时候，你会慢慢的发现你会变得越来越了解你的客户。<br />
  成功从第一步开始，不要让你的数据成就了别人的辉煌。</p>
<h3 id="用户画像">用户画像</h3>
<p>  用户画像顾名思义就是给你的用户画像，就是尽可能真实的从以业务范畴来详细、真实的描述用户的维度，其中可能包括性别、年龄范围、地区、工作性质、贫富状态和兴趣爱好标签等属性维度，比如本文上面说道的BAT数据的例子。<br />
  给一个用户准确的画像在相应的业务场景中使用可以给用户更精准的推荐业务、内容或者是个性化服务。常见的场景包括消息内容推送、商品内容推送等，圈出特定群体的用户去精准推送更垂直的业务。<br />
  为了保证画像的准确性，所以需要量级更大的数据作为支撑。</p>
<h3 id="知识图谱">知识图谱</h3>
<p>  文章开头的百度的例子其实就是一个知识图谱的运用。<br />
  知识图谱是准确描述事实环境中每个实体的画像结构。常见的业务场景就是搜索类工具中使用，其次在做大数据其他方向的运用中可以当作一个工具内容来使用，例如用户画像。</p>
<h3 id="其他">其他</h3>
<p>  进店数据是百度内部的一个项目，据说可以分析计算到用户走在马路上后，走进路边某家店铺的指数。这就是去预估用户消费的一个大数据应用。
  通过提前做好的用户画像数据，指定分析某一个时刻或者是指定某个商场地点的所有用户信息，供商家参考用户消费需求和推出更精准的业务。例如如果分析某商场内老年人的比例达到了80%以上，那么商家肯定不会傻到搞一个比基尼促销活动。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven使用入门</title>
    <url>/2016/07/05/Maven%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<h2 id="笔者使用环境">## 笔者使用环境</h2>
<blockquote>
<p>OS name: OS X Ei Capitan<br />
OS version: 10.11.5<br />
Java version: 1.8.0_91<br />
Apache Maven: 3.3.9</p>
</blockquote>
<span id="more"></span>
<h2 id="创建项目mvn-archetypegenerate">## 创建项目：mvn
archetype:generate</h2>
<blockquote>
<p>如果是第一次运行 Maven 的话，它会从远程 Maven
仓库下载很多需要的程序到你的本地库<br />
本地库（local repository）目录：<code>~/.m2/repository/</code>
也可以不使用交互方式创建<br />
<code>mvn archetype:generate -DgroupId=com.test.helloworld -DartifactId=HelloWorld -DarchetypeArtifactId=maven-archetype-quickstart -DinteractiveMode=false</code></p>
</blockquote>
<ol type="1">
<li>Choose a number or apply filter<br />
选择项目模版ID，直接回车选默认模版，再次回车选默认模版版本。</li>
<li>Define value for property 'groupId': :<br />
填写组织名称，一般使用域名方式，例如：com.test.helloworld</li>
<li>Define value for property 'artifactId': :<br />
填写项目名称，例如：HelloWorld</li>
<li>Define value for property 'version': 1.0-SNAPSHOT: :<br />
填写项目版本，回车默认或手动输入，默认为1.0-SNAPSHOT，例如：1.0</li>
<li>Define value for property 'package': com.test.helloworld: :<br />
填写创建的包名，回车选默认或手动输入，默认使用组织名称，例如：com.test.helloworld</li>
<li>Y: :<br />
确认信息，直接回车</li>
<li>如果终端信息输出<code>BUILD SUCCESS</code>则表明maven项目创建完成。</li>
</ol>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">[INFO] ----------------------------------------------------------------------------</span><br><span class="line">[INFO] Using following parameters <span class="keyword">for</span> creating project from Old (1.x) Archetype: maven-archetype-quickstart:1.1</span><br><span class="line">[INFO] ----------------------------------------------------------------------------</span><br><span class="line">[INFO] Parameter: basedir, Value: /Users/iceberg/dev</span><br><span class="line">[INFO] Parameter: package, Value: com.test.helloworld</span><br><span class="line">[INFO] Parameter: groupId, Value: com.test.helloworld</span><br><span class="line">[INFO] Parameter: artifactId, Value: HelloWorld</span><br><span class="line">[INFO] Parameter: packageName, Value: com.test.helloworld</span><br><span class="line">[INFO] Parameter: version, Value: 1.0</span><br><span class="line">[INFO] project created from Old (1.x) Archetype <span class="keyword">in</span> <span class="built_in">dir</span>: /Users/iceberg/dev/HelloWorld</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 01:11 min</span><br><span class="line">[INFO] Finished at: 2016-07-14T12:03:21+08:00</span><br><span class="line">[INFO] Final Memory: 15M/310M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<img src="/2016/07/05/Maven%E4%BD%BF%E7%94%A8%E5%85%A5%E9%97%A8/QQ20160714-0@2x.png" class="" title="[项目目录结构]">
<h2 id="编译命令mvn-compile">## 编译命令：mvn compile</h2>
<p>  编译成功后，可以在项目目录下面的<code>target/classes</code>目录中找到编译后的<code>.class</code>文件。
&gt; 第一次执行时，会去 Maven 远程仓库下载大量的jar包。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Iceberg-Mac:dev iceberg$ <span class="built_in">cd</span> HelloWorld/</span><br><span class="line">Iceberg-Mac:HelloWorld iceberg$ mvn compile</span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building HelloWorld 1.0</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">......</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 0.856 s</span><br><span class="line">[INFO] Finished at: 2016-07-14T12:06:21+08:00</span><br><span class="line">[INFO] Final Memory: 15M/300M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">Iceberg-Mac:HelloWorld iceberg$ <span class="built_in">cd</span> target/classes/</span><br><span class="line">Iceberg-Mac:classes iceberg$ java com.test.helloworld.App</span><br><span class="line">Hello World!</span><br></pre></td></tr></table></figure>
<h2 id="清除编译mvn-clean">## 清除编译：mvn clean</h2>
<p>  执行完<code>mvn clean</code>后，<code>target</code>目录会被删除。
&gt; 第一次执行时，会去 Maven 远程仓库下载大量的jar包。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Iceberg-Mac:classes iceberg$ <span class="built_in">cd</span> ../../</span><br><span class="line">Iceberg-Mac:HelloWorld iceberg$ mvn clean</span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building HelloWorld 1.0</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-clean-plugin:2.5:clean (default-clean) @ HelloWorld ---</span><br><span class="line">[INFO] Deleting /Users/iceberg/dev/HelloWorld/target</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 0.227 s</span><br><span class="line">[INFO] Finished at: 2016-07-14T12:14:10+08:00</span><br><span class="line">[INFO] Final Memory: 7M/245M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br></pre></td></tr></table></figure>
<h2 id="测试命令mvn-test">## 测试命令：mvn test</h2>
<p>  该命令会执行<code>src/test/java/</code>下用<code>Junit</code>编写的测试代码
&gt; 执行顺序：编译－&gt;测试</p>
<h2 id="打包命令mvn-package">## 打包命令：mvn package</h2>
<p>  将当前的项目打包，并将目标jar包存放在<code>target</code>目录下面
&gt; 第一次执行时，会去 Maven 远程仓库下载大量的jar包。 &gt;
该命令会自动跑测试代码，如果不需要测试，则运行命令<code>clean package -Dmaven.test.skip=true</code>
&gt; 执行顺序：编译－&gt;测试－&gt;打包</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">Iceberg-Mac:HelloWorld iceberg$ mvn package</span><br><span class="line">[INFO] Scanning <span class="keyword">for</span> projects...</span><br><span class="line">[INFO]                                                                         </span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Building HelloWorld 1.0</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">....</span><br><span class="line"></span><br><span class="line">-------------------------------------------------------</span><br><span class="line"> T E S T S</span><br><span class="line"> </span><br><span class="line">-------------------------------------------------------</span><br><span class="line">Running com.test.helloworld.AppTest</span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0, Time elapsed: 0.004 sec</span><br><span class="line"></span><br><span class="line">Results :</span><br><span class="line"></span><br><span class="line">Tests run: 1, Failures: 0, Errors: 0, Skipped: 0</span><br><span class="line"></span><br><span class="line">[INFO] </span><br><span class="line">[INFO] --- maven-jar-plugin:2.4:jar (default-jar) @ HelloWorld ---</span><br><span class="line">[INFO] Building jar: /Users/iceberg/dev/HelloWorld/target/HelloWorld-1.0.jar</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] BUILD SUCCESS</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">[INFO] Total time: 1.493 s</span><br><span class="line">[INFO] Finished at: 2016-07-14T12:22:16+08:00</span><br><span class="line">[INFO] Final Memory: 18M/303M</span><br><span class="line">[INFO] ------------------------------------------------------------------------</span><br><span class="line">Iceberg-Mac:HelloWorld iceberg$ <span class="built_in">cd</span> target/</span><br><span class="line">Iceberg-Mac:target iceberg$ java -classpath HelloWorld-1.0.jar com.test.helloworld.App</span><br><span class="line">Hello World!</span><br></pre></td></tr></table></figure>
<h2 id="安装命令mvn-install">## 安装命令：mvn install</h2>
<p>  该命令会将项目的jar包安装到本地 Maven 仓库中，以便其他项目使用。
&gt; 执行顺序：编译－&gt;测试－&gt;打包-&gt;安装</p>
<h2 id="eclipse中的maven">## Eclipse中的Maven</h2>
<blockquote>
<p>只针对已经创建好Maven项目之后的导入</p>
</blockquote>
<ol type="1">
<li>在eclipse的Marketplace中找到<code>Maven Integration for Eclipse</code>并安装；</li>
<li>在本地创建好 Maven
项目后，在eclipse中选择import，<code>Root Directory</code>中选择 Maven
项目目录，点击<code>Finish</code>完成；</li>
<li>选中项目目录名，<code>Run-&gt;Run As-&gt;*</code>选择相应的 Maven
命令执行。</li>
</ol>
<h2 id="intellij-idea中的maven">## IntelliJ IDEA中的Maven</h2>
<blockquote>
<p>只针对已经创建好的Maven项目的导入</p>
</blockquote>
<ol type="1">
<li>在Intellij欢迎界面点击<code>Import Project</code>；</li>
<li>选择Maven项目中的<code>pom.xml</code>文件，然后一直<code>next</code>；</li>
<li>也可以直接 <code>File -&gt; Open</code>
选择Maven项目中的<code>pom.xml</code>文件。</li>
</ol>
<h2 id="生命周期">## 生命周期</h2>
<p>  clean、default、site是Maven的三个生命周期。<br />
  Maven的生命周期相互独立。每个周期都包含一些有顺序的阶段，后面阶段的运行依赖于前面阶段的结果，所以用户和阶段2交互，则阶段1会自动执行。用户可以和这些生命周期的任何一个阶段交互。
### 项目清理的生命周期：clean 1. pre-clean 清理前工作 2. clean 清理工作
3. post-clean 清理后工作</p>
<h3 id="项目构建的生命周期default">项目构建的生命周期：default</h3>
<ol type="1">
<li>validate 验证项目</li>
<li>initialize 初始化</li>
<li>generate-sources 生成／载入源代码</li>
<li>process-sources 处理源代码</li>
<li>generate-resources 生成／载入资源</li>
<li>process-resources 处理资源文件，设置classpath等</li>
<li>compile 编译项目</li>
<li>process-classes 处理class文件</li>
<li>generate-test-sources 生成／载入测试源文件</li>
<li>process-test-sources 处理测试源文件</li>
<li>generate-test-resources 生成／载入测试资源</li>
<li>process-test-resources 处理测试资源文件</li>
<li>test-compile 编译项目的测试代码</li>
<li>process-test-classes 处理经过编译的项目测试class文件</li>
<li>test 进行项目的单元测试</li>
<li>prepare-package 打包准备</li>
<li>package 项目打包</li>
<li>pre-integration-test 整合之前工作</li>
<li>integration-test 整合测试</li>
<li>post-integration-test 整合之后工作</li>
<li>verify 验证</li>
<li>install 将项目打包生成的jar包安装到本地Maven仓库</li>
<li>deplop 发布项目打包的内容，供其他开发人员和Maven项目使用</li>
</ol>
<h3
id="建立和发布项目站点生命周期site">建立和发布项目站点生命周期：site</h3>
<ol type="1">
<li>pre-site 生成项目站点之前的工作</li>
<li>site 生成项目站点</li>
<li>post-site 生成项目站点之后的工作</li>
<li>site-deploy 发布项目站点</li>
</ol>
<h2 id="maven中的-pom.xml">## Maven中的 pom.xml</h2>
<p>  Maven 中的项目配置内容都在<code>pom.xml</code>文件中。</p>
<h2 id="maven的坐标">## Maven的坐标</h2>
<p>  <code>pom.xml</code>中声明的<code>groupId, artifactId, packaging, version</code>叫做
Maven 的坐标，坐标能唯一的确定一个项目。 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">groupId</span>&gt;</span>com.test.helloworld<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>HelloWorld<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">packaging</span>&gt;</span>jar<span class="tag">&lt;/<span class="name">packaging</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">version</span>&gt;</span>1.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="jar包依赖">## jar包依赖</h2>
<p>  依赖就是项目中需要引入的外部jar包，所有的依赖都声明在<code>pom.xml</code>中的<code>dependencies</code>节点中，例如测试模块依赖的<code>junit</code>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>junit<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.8.1<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">scope</span>&gt;</span>test<span class="tag">&lt;/<span class="name">scope</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure> &gt;
可以看到，添加的<code>dependency</code>节点内容可以构成一个Maven项目的唯一坐标，这样就可以准确加载项目中需要的外部依赖
&gt; 默认依赖类型为jar包</p>
<h3 id="依赖范围scope">依赖范围：scope <classpath的有效阶段></h3>
<ol type="1">
<li>编译依赖范围：compile<br />
默认依赖范围，在编译、测试、运行都有效</li>
<li>测试依赖范围：test<br />
只有在测试的时候有效</li>
<li>已经存在的依赖范围：provided<br />
类似于系统自带的依赖，JDK
或者容器会提供所需的jar文件。例如servlet-api</li>
<li>运行时依赖：runtime</li>
<li>系统依赖范围：system<br />
需要通过设置<code>systemPath</code>元素显式地指定依赖文件的路径</li>
<li>导入依赖范围：import</li>
</ol>
<h3 id="依赖传递">依赖传递</h3>
<p>  当Maven项目依赖一个外部jar包是，这个jar包也是一个Maven项目，并且也有自己的依赖，那么我们不需要将这个外部jar包的依赖也一一在<code>pom.xml</code>中添加<code>dependency</code>节点。Maven会自动将外部jar包的依赖也传递到当前Maven项目中，这就是传递依赖。</p>
<h3 id="排除依赖">排除依赖</h3>
<p>  有时候我们在引入外部jar包的时候，不想让外部jar包的依赖传递到我们的Maven项目中，这时候我们可以在<code>dependency</code>节点中设置<code>exclusions</code>节点来拒绝依赖传递。<code>exclusions</code>可以包含一个或多个<code>exclusion</code>节点，<code>exclusion</code>节点就是想拒绝的依赖内容。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span>    </span><br><span class="line">     <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.springframework<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>spring-core<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">version</span>&gt;</span>2.5.6<span class="tag">&lt;/<span class="name">version</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;<span class="name">exclusions</span>&gt;</span>  </span><br><span class="line">           <span class="tag">&lt;<span class="name">exclusion</span>&gt;</span>      </span><br><span class="line">                <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span>          </span><br><span class="line">                <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-logging<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span>  </span><br><span class="line">           <span class="tag">&lt;/<span class="name">exclusion</span>&gt;</span>  </span><br><span class="line">     <span class="tag">&lt;/<span class="name">exclusions</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Apache Maven</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>JAVA</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>org.apache.commons.cli</title>
    <url>/2016/07/14/org-apache-commons-cli/</url>
    <content><![CDATA[<blockquote>
<p>org.apache.commons.cli version：1.3</p>
</blockquote>
<figure class="highlight xml"><figcaption><span>pom.xml > Maven</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>commons-cli<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>1.3<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure>
<span id="more"></span>
<p><code>org.apache.commons.cli</code>项目是<code>Apache Commons</code>项目中的一个子项目，实现了处理和解析命令行参数的功能。
<figure class="highlight java"><figcaption><span>例子</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="keyword">package</span> com.test.helloworld;</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.CommandLine;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.CommandLineParser;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.DefaultParser;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.Option;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.Options;</span><br><span class="line"><span class="keyword">import</span> org.apache.commons.cli.ParseException;</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * Hello world!</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">App</span> </span><br><span class="line">&#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">( String[] args )</span> <span class="keyword">throws</span> ParseException</span><br><span class="line">    &#123;</span><br><span class="line">    	<span class="type">CommandLineParser</span> <span class="variable">clp</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DefaultParser</span>();</span><br><span class="line">    	<span class="type">CommandLine</span> <span class="variable">cl</span> <span class="operator">=</span> clp.parse(options, args);</span><br><span class="line">    	System.out.println(cl.getOptionValue(<span class="string">&quot;input&quot;</span>));</span><br><span class="line">    	System.out.println(cl.getOptionValue(<span class="string">&quot;output&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="meta">@SuppressWarnings(&quot;serial&quot;)</span></span><br><span class="line">	<span class="keyword">static</span> <span class="type">Options</span> <span class="variable">options</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Options</span>() </span><br><span class="line">	&#123;</span><br><span class="line">		&#123;</span><br><span class="line">			<span class="type">Option</span> <span class="variable">input</span> <span class="operator">=</span> Option.builder(<span class="string">&quot;i&quot;</span>)</span><br><span class="line">					.hasArg()</span><br><span class="line">					.desc(<span class="string">&quot; the input&quot;</span>)</span><br><span class="line">					.longOpt(<span class="string">&quot;input&quot;</span>)</span><br><span class="line">					.build();</span><br><span class="line">			<span class="type">Option</span> <span class="variable">output</span> <span class="operator">=</span> Option.builder(<span class="string">&quot;o&quot;</span>)</span><br><span class="line">					.hasArg()</span><br><span class="line">					.desc(<span class="string">&quot; the output &quot;</span>)</span><br><span class="line">					.longOpt(<span class="string">&quot;output&quot;</span>)</span><br><span class="line">					.build();</span><br><span class="line">			addOption(input);</span><br><span class="line">			addOption(output);</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>JAVA</tag>
        <tag>Jar</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven插件概述</title>
    <url>/2017/03/26/Maven%E6%8F%92%E4%BB%B6%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<img src="/2017/03/26/Maven%E6%8F%92%E4%BB%B6%E6%A6%82%E8%BF%B0/maven-logo-black-on-white.png" class="">
<h2 id="maven">## Maven</h2>
<p>  Maven是一个项目管理工具，它包含了一个项目对象模型 (Project Object
Model)、一组标准集合、一个项目生命周期(Project
Lifecycle)、一个依赖管理系统(Dependency Management
System)和用来运行定义在生命周期阶段(phase)中插件(plugin)目标(goal)的逻辑。
  Maven项目对象模型(POM)，可以通过一小段描述信息来管理项目的构建，报告和文档的软件项目管理工具。
  从Maven的实现和运行方式来讲，Maven是一个插件框架，在Maven内部所有的操作逻辑和项目管理目标都来自插件。
  Maven定义了三个生命周期（clean、default、site），这些生命周期相互独立，并且每个周期内部都包含了一些有序阶段。Maven会将很多插件目标（goal）绑定到每个生命周期中，这使得我们在对Maven发出相关项目指令的时候，Maven会有序的执行相关周期内部的每个小阶段并且触发绑定到每个周期内部阶段上面的插件目标，最后完成相关项目管理指令。例如编译和创建一个JAR文件这样的工作。
  Maven的目的是用来简化项目构建过程，生成一种标准化方式的构建、清晰的方式定义项目的组成、简单的方式发布项目和简单的方式在多个项目中共享JARs。此外，Maven能够很方便的帮你管理项目报告，生成站点，管理JAR文件，等等。</p>
<span id="more"></span>
<h2 id="maven中的插件">## Maven中的插件</h2>
<p>  Maven中主要的角色就是插件，所有的项目管理目标都是由插件执行和完成的。Maven插件由核心插件和拓展插件组成，Maven项目本身提供和开发并随着Maven分发包一起发布的插件是Maven的核心插件。核心插件提供了Maven的基础功能，如Maven项目创建、编译、打包和发布等项目管理目标都是由核心插件完成。拓展插件是对Maven核心插件功能的补充和拓展，完成一些小众需求而实现的插件，如将Maven项目打包成可执行JAR包的插件。
  从完成的项目管理目标功能来区分，Maven插件也可以分为Build插件和Reporting插件，Build插件是在项目build阶段执行的插件，在实际项目中配置于POM文件的<code>&lt;build&gt;</code>节点内；Reporting插件是在项目的site阶段执行的插件，在实际项目中配置于POM文件的<code>&lt;reporting&gt;</code>节点内。Maven项目的官方文档中就是按照该方式去区分插件类别。
  Maven项目本身就提供了大量的Maven插件，覆盖了日常项目管理的很多常用操作，可以在Maven官方插件文档列表中查找项目需要使用的插件。
&gt; 由官方维护的Maven插件列表，地址：<span class="exturl" data-url="aHR0cDovL21hdmVuLmFwYWNoZS5vcmcvcGx1Z2lucy9pbmRleC5odG1s">http://maven.apache.org/plugins/index.html<i class="fa fa-external-link-alt"></i></span></p>
<h2 id="插件定位坐标">## 插件定位／坐标</h2>
<p>  因为Maven插件的多种多样，所以在实际的项目管理过程中，为了快速定位和使用一个插件，Maven为每个插件都定义了一个坐标，使得定位和使用一个插件变得那么复杂和麻烦。插件坐标需要每个插件开发者自定义并且保证其唯一性。
  一个Maven插件至少应该包含以下信息来定义插件的坐标：</p>
<table>
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: left;">Item</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">groupId</td>
<td style="text-align: left;">插件的包路径，类似于Java中的包概念</td>
<td style="text-align: left;">org.apache.maven.plugins</td>
</tr>
<tr class="even">
<td style="text-align: left;">artifactId</td>
<td style="text-align: left;">使用插件的插件名称</td>
<td style="text-align: left;">maven-archetype-plugin</td>
</tr>
<tr class="odd">
<td style="text-align: left;">version</td>
<td style="text-align: left;">插件的版本信息</td>
<td style="text-align: left;">2.4</td>
</tr>
</tbody>
</table>
<blockquote>
<p><code>maven-archetype-plugin</code>插件即为Maven的核心插件内容，创建Maven项目的命令<code>mvn archetype:generate</code>就是执行该插件中的<code>generate</code>目标。</p>
</blockquote>
<h2 id="插件的使用">## 插件的使用</h2>
<p>  Maven插件的使用也很方便，但是前提你要知道该插件的坐标、Goal（目标）列表和配置参数，你可以在该插件的文档中找到相关插件的内容和配置参数。
### 命令行方式   Maven插件可以直接在命令行进行使用。</p>
<figure class="highlight sh"><table><tr><td class="code"><pre><span class="line">mvn [groupId:][artifactId][:version]:[goal] [-D[Parameter]] …</span><br></pre></td></tr></table></figure>
<table>
<thead>
<tr class="header">
<th style="text-align: left;">Item</th>
<th style="text-align: left;">Description</th>
<th style="text-align: left;">Required</th>
<th style="text-align: left;">Example</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: left;">groupId</td>
<td style="text-align: left;">插件包路径</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">org.apache.maven.plugins</td>
</tr>
<tr class="even">
<td style="text-align: left;">artifactId</td>
<td style="text-align: left;">插件名称</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">maven-dependency-plugin</td>
</tr>
<tr class="odd">
<td style="text-align: left;">version</td>
<td style="text-align: left;">插件版本信息</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">3.0.0</td>
</tr>
<tr class="even">
<td style="text-align: left;">goal</td>
<td style="text-align: left;">插件内命令（项目管理目标）</td>
<td style="text-align: left;">true</td>
<td style="text-align: left;">tree</td>
</tr>
<tr class="odd">
<td style="text-align: left;">Parameter</td>
<td style="text-align: left;">命令参数,加<code>-D</code>前缀</td>
<td style="text-align: left;">false</td>
<td style="text-align: left;">-DoutputFile</td>
</tr>
</tbody>
</table>
<figure class="highlight sh"><figcaption><span>Example</span></figcaption><table><tr><td class="code"><pre><span class="line">mvn org.apache.maven.plugins:maven-dependency-plugin:3.0.0:tree -DoutputFile=tree.txt</span><br><span class="line"><span class="comment">#可以简写为</span></span><br><span class="line">mvn dependency:<span class="literal">true</span> -DoutputFile=tree.txt</span><br></pre></td></tr></table></figure>
<h3 id="pom方式">POM方式</h3>
<p>  Maven插件可以绑定到Maven的某一个生命周期阶段运行，使用POM方式配置插件信息和绑定周期。
<figure class="highlight xml"><figcaption><span>pom.xml(part)</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">plugin</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 插件包路径 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 插件名称 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>maven-dependency-plugin<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 插件版本信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">version</span>&gt;</span>3.0.0<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 具体任务块 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">executions</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 单个任务 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">execution</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 自定义唯一ID --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">id</span>&gt;</span>tree<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 项目管理目标列表 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">goals</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- 具体目标 --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">goal</span>&gt;</span>tree<span class="tag">&lt;/<span class="name">goal</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">goals</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 绑定到的周期阶段，即什么时候执行 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">phase</span>&gt;</span>package<span class="tag">&lt;/<span class="name">phase</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!-- 插件运行参数配置 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">configuration</span>&gt;</span></span><br><span class="line">                <span class="comment">&lt;!-- 参数配置 --&gt;</span></span><br><span class="line">                <span class="tag">&lt;<span class="name">outputFile</span>&gt;</span>tree.txt<span class="tag">&lt;/<span class="name">outputFile</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;/<span class="name">configuration</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">execution</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">executions</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">plugin</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Apache Maven</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>JAVA</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>Maven配置文件setting.xml</title>
    <url>/2017/03/27/Maven%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6setting-xml/</url>
    <content><![CDATA[<h2 id="setting.xml">## setting.xml</h2>
<p>  <code>setting.xml</code>文件是Maven运行所需要的配置文件，作用于所有的Maven项目。<code>setting.xml</code>文件在Maven安装目录下面<code>$&#123;maven.home&#125;/conf/settings.xml</code>,作为Maven的全局配置，作用于所有用户。另外你可以单独指定自己的配置而不影响其他用户，在用户目录下面<code>$&#123;user.home&#125;/.m2/settings.xml</code>配置文件作为Maven的用户配置，该配置优先生效于Maven的全局配置，即Maven的用户配置内容会覆盖全局配置。</p>
<span id="more"></span>
<p>  <code>setting.xml</code>的文件结构如下： <figure class="highlight xml"><figcaption><span>setting.xml</span></figcaption><table><tr><td class="code"><pre><span class="line"><span class="meta">&lt;?xml version=<span class="string">&quot;1.0&quot;</span> encoding=<span class="string">&quot;UTF-8&quot;</span>?&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">settings</span> <span class="attr">xmlns</span>=<span class="string">&quot;http://maven.apache.org/SETTINGS/1.0.0&quot;</span> <span class="attr">xmlns:xsi</span>=<span class="string">&quot;http://www.w3.org/2001/XMLSchema-instance&quot;</span> <span class="attr">xsi:schemaLocation</span>=<span class="string">&quot;http://maven.apache.org/SETTINGS/1.0.0 http://maven.apache.org/xsd/settings-1.0.0.xsd&quot;</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">localRepository</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">interactiveMode</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">usePluginRegistry</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">offline</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">pluginGroups</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">pluginGroup</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">pluginGroups</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">proxies</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">proxie</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">proxies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">servers</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">servers</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">servers</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirror</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">profiles</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">profile</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">activeProfiles</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">activeProfile</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">activeProfiles</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">settings</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>实际使用中可以动态指定Maven的全局配置和用户本地配置
使用<code>mvn -s [file name]</code>指定用户本地配置
使用<code>mvn -gs [file name]</code>指定全局配置</p>
</blockquote>
<h2 id="localrepository">## localRepository</h2>
<p>  Maven配置的本地仓库路径，默认值为<code>$&#123;user.home&#125;/.m2/repository</code>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">localRepository</span>&gt;</span>$&#123;user.home&#125;/.m2/repository<span class="tag">&lt;/<span class="name">localRepository</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="interactivemode">## interactiveMode</h2>
<p>  Maven执行过程中是否接受用户输入，默认值为<code>true</code>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">interactiveMode</span>&gt;</span>true<span class="tag">&lt;/<span class="name">interactiveMode</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="usepluginregistry">## usePluginRegistry</h2>
<p>  Maven是否需要使用<code>plugin-registry.xml</code>文件来管理插件版本。如果需要让Maven使用文件<code>$&#123;user.home&#125;/.m2/plugin-registry.xml</code>来管理插件版本，则设为<code>true</code>。默认为false,并且和<code>setting.xml</code>文件一样可以设置全局配置和用户本地配置。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">usePluginRegistry</span>&gt;</span>false<span class="tag">&lt;/<span class="name">usePluginRegistry</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="offline">## offline</h2>
<p>  表示Maven是否支持在离线模式下运行。当由于网络设置原因或者安全因素，构建服务器不能连接远程仓库的时候，如果构建系统需要在离线模式下运行，则为<code>true</code>，默认为<code>false</code>。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">offline</span>&gt;</span>false<span class="tag">&lt;/<span class="name">offline</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="plugingroups">## pluginGroups</h2>
<p>  当插件的组织Id（groupId）没有显式提供时，供搜寻插件组织Id（groupId）的列表。该元素包含一个pluginGroup元素列表，每个子元素包含了一个组织Id（groupId）。当我们使用某个插件，并且没有在命令行为其提供组织Id（groupId）的时候，Maven就会使用该列表。默认情况下该列表包含了org.apache.maven.plugins和org.codehaus.mojo
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">pluginGroups</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">pluginGroup</span>&gt;</span>org.apache.maven.plugins<span class="tag">&lt;<span class="name">pluginGroup</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">pluginGroup</span>&gt;</span>org.codehaus.mojo<span class="tag">&lt;<span class="name">pluginGroup</span>/&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">pluginGroups</span>/&gt;</span></span><br></pre></td></tr></table></figure>
  因为有该配置内容，所以我们运行大部分Maven命令的时候一般都省略了组织Id（groupId）。如<code>mvn org.apache.maven.plugins:dependency:tree</code>可以简写成<code>mvn dependency:true</code>。</p>
<h2 id="proxies">## proxies</h2>
<p>  <code>proxies</code>节点可以给远程仓库的访问设置代理。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">proxies</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">proxy</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--代理的唯一定义符，用来区分不同的代理元素。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>myproxy<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--该代理是否是激活使用。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">active</span>&gt;</span>true<span class="tag">&lt;/<span class="name">active</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--代理的协议。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">protocol</span>&gt;</span>http<span class="tag">&lt;/<span class="name">protocol</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--代理的主机名。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">host</span>&gt;</span>proxy.somewhere.com<span class="tag">&lt;/<span class="name">host</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--代理的端口。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">port</span>&gt;</span>8080<span class="tag">&lt;/<span class="name">port</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--代理的用户名和密码，用户名和密码表示代理服务器认证的登录名和密码。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">username</span>&gt;</span>proxyuser<span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password</span>&gt;</span>somepassword<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--不该被代理的主机名列表。该列表的分隔符由代理服务器指定。—&gt;</span></span><br><span class="line"><span class="comment">        &lt;nonProxyHosts&gt;*.google.com|ibiblio.org&lt;/nonProxyHosts&gt;</span></span><br><span class="line"><span class="comment">    &lt;/proxy&gt;</span></span><br><span class="line"><span class="comment">&lt;/proxies&gt;</span></span><br></pre></td></tr></table></figure></p>
<h2 id="servers">## servers</h2>
<p>  当使用其他远程仓库的时候，通常我们会在POM文件中定义远程仓库的信息，但是一些设置如安全证书、用户名和密码不应该在<code>pom.xml</code>中一起分发，这种类型的信息应该在<code>setting.xml</code>下的<code>sercers</code>节点下配置，起到保护作用。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">servers</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!-- 服务器元素包含配置服务器时需要的信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">server</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!-- 这是server的id（注意不是用户登陆的id），该id distributionManagement中repository元素的id相匹配,Maven在连接一个库或者镜像的时候，通过id匹配要连接的服务器 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>server001<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--鉴权用户名。鉴权用户名表示服务器认证所需要的登录名。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">username</span>&gt;</span>my_login<span class="tag">&lt;/<span class="name">username</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--鉴权密码 。鉴权鉴权密码表示服务器认证所需要的密码。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">password</span>&gt;</span>my_password<span class="tag">&lt;/<span class="name">password</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--鉴权时使用的私钥位置。和前两个元素类似，私钥位置和私钥密码指定了一个私钥的路径（默认是$&#123;user.home&#125;/.ssh/id_dsa）。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">privateKey</span>&gt;</span>$&#123;usr.home&#125;/.ssh/id_dsa<span class="tag">&lt;/<span class="name">privateKey</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--鉴权时使用的私钥密码。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">passphrase</span>&gt;</span>some_passphrase<span class="tag">&lt;/<span class="name">passphrase</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--文件被创建时的权限。如果在部署的时候会创建一个仓库文件或者目录，这时候就可以使用权限（permission）。这两个元素合法的值是一个三位数字，其对应了unix文件系统的权限，如664，或者775。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">filePermissions</span>&gt;</span>664<span class="tag">&lt;/<span class="name">filePermissions</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--目录被创建时的权限。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">directoryPermissions</span>&gt;</span>775<span class="tag">&lt;/<span class="name">directoryPermissions</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">server</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">servers</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h2 id="mirrors">## mirrors</h2>
<p>  Maven会默认使用Apache
Maven官方的远程<code>central</code>仓库<code>http://repo.maven.apache.org/maven2/</code>,但有时候考虑到互联网访问的安全性和访问速度等问题，所以会建立一些对远程仓库的镜像仓库，当设置了远程镜像仓库的时候，Maven会引用镜像仓库，而不直接使用远程仓库。
  <code>mirrors</code>节点可以配置远程仓库的镜像： <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">mirrors</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--给定仓库的下载镜像。 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">mirror</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--该镜像的唯一标识符。id用来区分不同的mirror元素。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>planetmirror.com<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--镜像名称 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>PlanetMirror Australia<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--该镜像的URL。构建系统会优先考虑使用该URL，而非使用默认的服务器URL。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://downloads.planetmirror.com/pub/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--被镜像的服务器的id。例如，如果我们要设置了一个Maven中央仓库（http://repo.maven.apache.org/maven2/）的镜像，就需要将该元素设置成central。这必须和中央仓库的id central完全一致。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">mirrorOf</span>&gt;</span>central<span class="tag">&lt;/<span class="name">mirrorOf</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">mirror</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">mirrors</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<blockquote>
<p>对于<code>mirrorOf</code>参数还有更多写法：
<code>*</code>表示任意远程库；
<code>external:*</code>表示任何不在Localhost和文件系统中的远程库；<code>r1,r2</code>表示r1库或者r2库；
<code>*,!r1</code>表示除了r1库之外的任何远程库。</p>
</blockquote>
<h2 id="profiles">## profiles</h2>
<p>  <code>profiles</code>节点配置可以根据环境参数来调整构建配置的列表。由于<code>setting.xml</code>配置作用于整个Maven构建系统，即适用于所有Maven项目，而非单独的项目对象，所以<code>settings.xml</code>中的<code>profile</code>元素是<code>pom.xml</code>中<code>profile</code>元素的裁剪版本。它仅包含了<code>id</code>，<code>activation</code>，
<code>repositories</code>， <code>pluginRepositories</code>和
<code>properties</code>元素。
  如果一个<code>settings.xml</code>中的<code>profile</code>被激活，它的值会覆盖任何其它定义在POM中或者<code>profile.xml</code>中的带有相同id的<code>profile</code>。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">profiles</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">profile</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">activation</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">repository</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">pluginRepositories</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">pluginRepository</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">pluginRepositories</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">properties</span>/&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">profile</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">profiles</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="id">id</h3>
<p>  id表示当前<code>profile</code>的唯一标识符。 <figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">id</span>&gt;</span>dev-test<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="activation">activation</h3>
<p>  设定<code>profile</code>的触发逻辑,作为启动当前<code>profile</code>的钥匙。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">activation</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--profile默认是否激活的标识--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">activeByDefault</span>&gt;</span>false<span class="tag">&lt;/<span class="name">activeByDefault</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当匹配的jdk被检测到，profile被激活。例如，1.4激活JDK1.4，1.4.0_2，而!1.4激活所有版本不是以1.4开头的JDK。--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">jdk</span>&gt;</span>1.5<span class="tag">&lt;/<span class="name">jdk</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--当匹配的操作系统属性被检测到，profile被激活。os元素可以定义一些操作系统相关的属性。--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">os</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的操作系统的名字 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Windows XP<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的操作系统所属家族(如 &#x27;windows&#x27;)  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">family</span>&gt;</span>Windows<span class="tag">&lt;/<span class="name">family</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的操作系统体系结构  --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">arch</span>&gt;</span>x86<span class="tag">&lt;/<span class="name">arch</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的操作系统版本--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">version</span>&gt;</span>5.1.2600<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">os</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--如果Maven检测到某一个属性（其值可以在POM中通过$&#123;name&#125;引用），其拥有对应的name = 值，Profile就会被激活。如果值字段是空的，那么存在属性名称字段就会激活profile，否则按区分大小写方式匹配属性值字段--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">property</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的属性的名称--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>mavenVersion<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--激活profile的属性的值 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">value</span>&gt;</span>2.0.3<span class="tag">&lt;/<span class="name">value</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">property</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--提供一个文件名，通过检测该文件的存在或不存在来激活profile。missing检查文件是否存在，如果不存在则激活profile。另一方面，exists则会检查文件是否存在，如果存在则激活profile。--&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">file</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--如果指定的文件存在，则激活profile。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">exists</span>&gt;</span>$&#123;basedir&#125;/file2.properties<span class="tag">&lt;/<span class="name">exists</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--如果指定的文件不存在，则激活profile。--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">missing</span>&gt;</span>$&#123;basedir&#125;/file1.properties<span class="tag">&lt;/<span class="name">missing</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">file</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">activation</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
<h3 id="properties">properties</h3>
<p>  对应<code>profile</code>的扩展属性列表，用来存放一些值，这些值可以在POM中的任何地方使用标记<code>$&#123;X&#125;</code>来使用。
  在设置的属性值中，可以通过以下5种方式获取一些变量： 1.
<code>env.X</code>:
在一个变量前加上<code>env.</code>的前缀，会返回一个Shell环境变量。例如,<code>env.PATH</code>指代了<code>$path</code>环境变量（在Windows上是<code>%PATH%</code>）。
2. <code>project.x</code>：指代了POM中对应的元素值。例如:
<code>&lt;project&gt;&lt;version&gt;1.0&lt;/version&gt;&lt;/project&gt;</code>通过<code>$&#123;project.version&#125;</code>获得<code>version</code>的值。
3. <code>settings.x</code>:
指代了<code>settings.xml</code>中对应元素的值。例如：<code>&lt;settings&gt;&lt;offline&gt;false&lt;/offline&gt;&lt;/settings&gt;</code>通过
<code>$&#123;settings.offline&#125;</code>获得<code>offline</code>的值。 4.
<code>Java System Properties</code>:
所有可通过<code>java.lang.System.getProperties()</code>访问的属性都能在POM中使用该形式访问，例如
<code>$&#123;java.home&#125;</code>。 5. <code>x</code>:
在<code>&lt;properties/&gt;</code>元素中，或者外部文件中设置，以<code>$&#123;x&#125;</code>的形式使用。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">properties</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">user.install</span>&gt;</span>$&#123;java.home&#125;/our-project<span class="tag">&lt;/<span class="name">user.install</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">properties</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="repositories">repositories</h3>
<p>  <code>repositories</code>节点是Maven配置仓库的节点，它是Maven用来填充构建系统本地仓库所使用的一个远程仓库列表。仓库是Maven构件（<code>artifact</code>）的存储位置，相当于一个构件的集合。
  Maven中构件被表示为带有指定位置信息的依赖（<code>dependency</code>）和插件（<code>plugins</code>）。依赖是Maven中常用的构件，通常被用来为实际项目中加载一些第三方的类库和包。Maven中的依赖库通过<code>&lt;repositories&gt;</code>节点设置。
  Maven的仓库分为本地仓库和远程仓库，本地仓库在Maven安装的时候指定的一个路径地址，通常位于用户目录下面<code>$&#123;user.home&#125;/.m2/repository</code>，本地仓库的构件通常都是由Maven从远程仓库下载到本地仓库的；而远程仓库都是由第三方创建供开发者使用的，如Apache
Maven官方的<code>Maven central库</code>。
  项目构建和build的时候，Maven会先从本地仓库搜索需要使用到的构件，如果不存在则配置好的远程仓库列表中逐一查找。在远程仓库中找到构件并下载到本地仓库后供Maven使用，否则会抛出编译异常。</p>
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">repositories</span>&gt;</span></span><br><span class="line">    <span class="comment">&lt;!--包含需要连接到远程仓库的信息 --&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">repository</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--远程仓库唯一标识--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">id</span>&gt;</span>codehausSnapshots<span class="tag">&lt;/<span class="name">id</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--远程仓库名称 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">name</span>&gt;</span>Codehaus Snapshots<span class="tag">&lt;/<span class="name">name</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--如何处理远程仓库里发布版本的下载--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">releases</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--true或者false表示该仓库是否为下载某种类型构件（发布版，快照版）开启。  --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>&gt;</span>false<span class="tag">&lt;/<span class="name">enabled</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--该元素指定更新发生的频率。Maven会比较本地POM和远程POM的时间戳。这里的选项是：always（一直），daily（默认，每日），interval：X（这里X是以分钟为单位的时间间隔），或者never（从不）。 --&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">updatePolicy</span>&gt;</span>always<span class="tag">&lt;/<span class="name">updatePolicy</span>&gt;</span></span><br><span class="line">            <span class="comment">&lt;!--当Maven验证构件校验文件失败时该怎么做-ignore（忽略），fail（失败），或者warn（警告）。--&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">checksumPolicy</span>&gt;</span>warn<span class="tag">&lt;/<span class="name">checksumPolicy</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">releases</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--如何处理远程仓库里快照版本的下载。有了releases和snapshots这两组配置，POM就可以在每个单独的仓库中，为每种类型的构件采取不同的策略。例如，可能有人会决定只为开发目的开启对快照版本下载的支持。参见repositories/repository/releases元素--&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">snapshots</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">enabled</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">updatePolicy</span>/&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">checksumPolicy</span>/&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">snapshots</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--远程仓库URL，按protocol://hostname/path形式 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">url</span>&gt;</span>http://snapshots.maven.codehaus.org/maven2<span class="tag">&lt;/<span class="name">url</span>&gt;</span></span><br><span class="line">        <span class="comment">&lt;!--用于定位和排序构件的仓库布局类型-可以是default（默认）或者legacy（遗留）。Maven 2为其仓库提供了一个默认的布局；然而，Maven 1.x有一种不同的布局。我们可以使用该元素指定布局是default（默认）还是legacy（遗留）。 --&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">layout</span>&gt;</span>default<span class="tag">&lt;/<span class="name">layout</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">repository</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">repositories</span>&gt;</span></span><br></pre></td></tr></table></figure>
<h3 id="pluginrepositories">pluginRepositories</h3>
<p>  Maven中的插件做为一种特殊类型的构件，所以插件仓库独立于其他依赖仓库。插件仓库通过<code>&lt;pluginRepositories&gt;</code>节点单独设置，由于依赖和插件都属于Maven中的构件，所以两者的配置基本相同。
## activeProfiles ---
  手动激活<code>profiles</code>的列表。该元素包含了一组<code>activeProfile</code>元素，每个<code>activeProfile</code>都含有一个<code>profile id</code>。任何在<code>activeProfile</code>中定义的<code>profile id</code>，不论环境设置如何，其对应的<code>profile</code>都会被激活。如果没有匹配的<code>profile</code>，则什么都不会发生。
<figure class="highlight xml"><table><tr><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">activeProfiles</span>&gt;</span>  </span><br><span class="line">    <span class="tag">&lt;<span class="name">activeProfile</span>&gt;</span>env-test<span class="tag">&lt;/<span class="name">activeProfile</span>&gt;</span>  </span><br><span class="line"><span class="tag">&lt;/<span class="name">activeProfiles</span>&gt;</span></span><br></pre></td></tr></table></figure></p>
]]></content>
      <categories>
        <category>Apache Maven</category>
      </categories>
      <tags>
        <tag>原创</tag>
        <tag>JAVA</tag>
        <tag>Maven</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中的距离计算</title>
    <url>/2017/04/28/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E8%B7%9D%E7%A6%BB%E8%AE%A1%E7%AE%97/</url>
    <content><![CDATA[<p>  在机器学习和数据挖掘中，我们通常用计算样本间的“距离”（Distance）来估算不同样本之间的相似性度量（Similarity
Measurement），样本间的距离计算算法的选用会直接关系到算法结果的正确与否，所以选择一个合适当前样本集的相似性度量方法格外重要。</p>
<span id="more"></span>
<h2 id="欧氏距离---欧几里得度量euclidean-metric">欧氏距离 -
欧几里得度量（euclidean metric）</h2>
<hr />
<p>  欧式距离是一个通常采用的距离定义，指在m维空间中两个点之间的真实距离，或者向量的自然长度（即该点到原点的距离）。在二维和三维空间中的欧氏距离就是两点之间的实际距离。
  计算二维空间上点(3,5)和点(2,1)两点间的欧氏距离 <span
class="math display">\[
d=\sqrt{(x1-x2)^2 + (y1 - y2)^2}\Rightarrow\sqrt{(3 - 2)^2 + (5 - 1)^2}
\]</span>   计算三维空间上点(1,3,5)和点(0,2,1)两点间的欧氏距离 <span
class="math display">\[
d=\sqrt{(x1-x2)^2+(y1-y-2)^2+(z1-z_2)^2}\Rightarrow\sqrt{(1-0)^2+(3-2)^2+(5-1)^2}
\]</span>
  计算N维空间上点A(a1,a2,a3,...,an)和点B(b1,b2,b3,…,bn)两点间的欧氏距离
<span class="math display">\[
d=\sqrt{\sum_{i=1}^n(A_i - B_i)^2}
\]</span>
  NumPy生产实例：计算三维空间中点A(5,6,7)到其他三个相同维点的欧氏距离.</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 创建三维空间中的三个目标点</span></span><br><span class="line">matrix = array([[<span class="number">1</span>,<span class="number">5</span>,<span class="number">2</span>], [<span class="number">2</span>,<span class="number">1</span>,<span class="number">3</span>], [<span class="number">0</span>,<span class="number">4</span>,<span class="number">1</span>]])</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{matrix=}
\begin{bmatrix}
1 &amp; 5 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
0 &amp; 4 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取目标点数量</span></span><br><span class="line">matrixSize = matrix.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 复制点A数量，返回一个和matrix相同规格的矩阵</span></span><br><span class="line">tempMatrix = tile([<span class="number">5</span>,<span class="number">6</span>,<span class="number">7</span>], (matrixSize, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{tempMatrix=}
\begin{bmatrix}
5 &amp; 6 &amp; 7 \\
5 &amp; 6 &amp; 7 \\
5 &amp; 6 &amp; 7 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 根据欧氏距离公式计算做减法</span></span><br><span class="line">diffMatrix = tempMatrix - matrix</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
\mathtt{diffMatrix}
&amp; =
\begin{bmatrix}
5 &amp; 6 &amp; 7 \\
5 &amp; 6 &amp; 7 \\
5 &amp; 6 &amp; 7 \\
\end{bmatrix}
-
\begin{bmatrix}
1 &amp; 5 &amp; 2 \\
2 &amp; 1 &amp; 3 \\
0 &amp; 4 &amp; 1 \\
\end{bmatrix} \\
&amp; =
\begin{bmatrix}
5-1 &amp; 6-5 &amp; 7-2 \\
5-2 &amp; 6-1 &amp; 7-3 \\
5-0 &amp; 6-4 &amp; 7-1 \\
\end{bmatrix} \\
&amp; =
\begin{bmatrix}
4 &amp; 1 &amp; 5 \\
3 &amp; 5 &amp; 4 \\
5 &amp; 2 &amp; 6 \\
\end{bmatrix}
\end{align}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sqDiffMatrix = diffMatrix ** <span class="number">2</span></span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
\mathtt{sqDiffMatrix}
&amp; =
\begin{bmatrix}
4 &amp; 1 &amp; 5 \\
3 &amp; 5 &amp; 4 \\
5 &amp; 2 &amp; 6 \\
\end{bmatrix}^2 \\
&amp; =
\begin{bmatrix}
4^2 &amp; 1^2 &amp; 5^2 \\
3^2 &amp; 5^2 &amp; 4^2 \\
5^2 &amp; 2^2 &amp; 6^2 \\
\end{bmatrix} \\
&amp; =
\begin{bmatrix}
16 &amp; 1 &amp; 25 \\
9 &amp; 25 &amp; 16 \\
25 &amp; 4 &amp; 36 \\
\end{bmatrix}
\end{align}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">sqDistances = sqDiffMatrix.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
\mathtt{sqDistances}
&amp; =
\begin{bmatrix}
16 + 1 + 25 \\
9 + 25 + 16 \\
25 + 4 + 36 \\
\end{bmatrix} \\
&amp; =
\begin{bmatrix}
42 \\
50 \\
65 \\
\end{bmatrix}
\end{align}
\]</span> <figure class="highlight python"><table><tr><td class="code"><pre><span class="line">distances = sqDistances ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure> <span class="math display">\[
\begin{align}
\mathtt{distances}
&amp; =
\sqrt{\begin{bmatrix}
42 \\
50 \\
65 \\
\end{bmatrix}} \\
&amp; =
\begin{bmatrix}
\sqrt42 \\
\sqrt50 \\
\sqrt65 \\
\end{bmatrix} \\
&amp; =
\begin{bmatrix}
6.4807407 \\
7.07106781 \\
8.06225775 \\
\end{bmatrix}
\end{align}
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
      </tags>
  </entry>
  <entry>
    <title>k-近邻算法（kNN）</title>
    <url>/2017/04/30/k-%E8%BF%91%E9%82%BB%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<h2 id="算法原理">算法原理</h2>
<hr />
<p>  k-近邻算法（kNN）采用测量样本集中不同特征值之间的距离方法进行样本分类。</p>
<p>  使用k-近邻算法做分类判断，我们必须有一个<code>算法训练样本集</code>，样本集是一些已知数据分类的样本集合。当我们要使用k-近邻算法求一个数据的分类时，首先我们将算法训练样本集和未知分类的一条数据输入到k-近邻算法，然后算法通过估算未知分类数据和所有算法训练样本集中数据的特征相似度（一般使用欧氏距离），最后算法找出相似度最高的前k个样本数据，并在k个样本数据中将出现次数最多的样本数据分类做为未知分类数据的分类结果。</p>
<span id="more"></span>
<h2 id="使用前提">使用前提</h2>
<hr />
<ol type="1">
<li>使用k-近邻算法必须提供有分类明确的训练样本集数据；</li>
<li>k-近邻算法适用于数值型数据和标称型特征的数据；</li>
<li>需要计算未知分类数据到所有训练样本集的特征相似度，所以使用k-近邻算法必须考虑算法性能和样本集数据的存储问题；</li>
<li>k-近邻算法中k的取值对算法分类的结果起决定性作用，所以可能需要重复测试使用不同的k值评估算法的可信度。</li>
</ol>
<h2 id="数据归一化">数据归一化</h2>
<hr />
<p>  可以从欧氏距离的计算公式<span
class="math inline">\(d=\sqrt{\sum_{i=1}^n(A_i -
B_i)^2}\)</span>可以推断，数值大的特征值对样本相似度的计算结果影响会很大，所以在所有特征同等权重的情况下，为了得到准确的结果，我们需要对数据做归一化处理，使得特征值的取值范围限定在0～1或者-1～1之间。
<span class="math display">\[
newValue = \frac{oldValue-min} {max-min}
\]</span>
  上面的归一化数据公式可以将任意取值范围的特征值转化为0～1区间内的值。</p>
<h2 id="算法实现">算法实现</h2>
<hr />
<h3 id="python">Python</h3>
<p>  k-近邻算法中会使用到线性代数的知识，所以我们使用<code>NumPy</code>函数库来代替传统使用循环的方式遍历矩阵计算。</p>
<p>  构造一个算法训练样本集文件<code>data.txt</code>，文件内容为：</p>
<figure class="highlight apache"><table><tr><td class="code"><pre><span class="line"><span class="attribute">0</span>.<span class="number">8</span>	<span class="number">400</span>	<span class="number">0</span>.<span class="number">5</span>	<span class="number">1</span></span><br><span class="line"><span class="attribute">12</span>	<span class="number">134000</span>	<span class="number">0</span>.<span class="number">9</span>	<span class="number">3</span></span><br><span class="line"><span class="attribute">0</span>	<span class="number">20000</span>	<span class="number">1</span>.<span class="number">1</span>	<span class="number">2</span></span><br><span class="line"><span class="attribute">67</span>	<span class="number">32000</span>	<span class="number">0</span>.<span class="number">1</span>	<span class="number">2</span></span><br></pre></td></tr></table></figure>
<p>  样本集文件数据按照<code>\t</code>为分隔符，一行文本数据为一个样本内容，样本内容包括3个特征值和最后一个分类结果字段。</p>
<p>  通过构造k-近邻算法计算未知分类数据<code>[0.1 200 1.0]</code>的分类结果。</p>
<p>  开始构建k-近邻算法：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 创建样本集数据矩阵和对应分类列表</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 打开样本集文件</span></span><br><span class="line">fr = <span class="built_in">open</span>(<span class="string">&quot;data.txt&quot;</span>)</span><br><span class="line"><span class="comment"># 读取样本集文件内容</span></span><br><span class="line">arrayOlines = fr.readlines()</span><br><span class="line"><span class="comment"># 获取样本集数量</span></span><br><span class="line">numberOfLines = <span class="built_in">len</span>(arrayOlines)</span><br><span class="line"><span class="comment"># 构造样本矩阵</span></span><br><span class="line">dataMat = zeros((numberOfLines, <span class="number">3</span>))</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{dataMat=}
\begin{bmatrix}
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
0 &amp; 0 &amp; 0 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 样本对应的分类列表</span></span><br><span class="line">classLabelVector = []</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> line <span class="keyword">in</span> arrayOlines:</span><br><span class="line">    line = line.strip()</span><br><span class="line">    listFromLine = line.split(<span class="string">&#x27;\t&#x27;</span>)</span><br><span class="line">    <span class="comment"># 将样本内容填充到样本矩阵</span></span><br><span class="line">    returnMat[index:] = listFromLine[<span class="number">0</span>:<span class="number">3</span>]</span><br><span class="line">    <span class="comment"># 用最后一个样本分类字段构造样本分类列表</span></span><br><span class="line">    classLabelVector.append( <span class="built_in">int</span>(listFromLine[-<span class="number">1</span>]) )</span><br><span class="line">    index += <span class="number">1</span></span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{dataMat=}
\begin{bmatrix}
0.8 &amp; 400 &amp; 0.5 \\
12 &amp; 134000 &amp; 0.9 \\
0 &amp; 20000 &amp; 1.1 \\
67 &amp; 32000 &amp; 0.1 \\
\end{bmatrix}
\]</span></p>
<p><span class="math display">\[
\mathtt{classLabelVector=}
\begin{bmatrix}
1 \\
3 \\
2 \\
2 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 特征归一化</span></span><br><span class="line"><span class="comment"># 创建归一化操作需要的数据规格，包括样本集数据和待计算样本</span></span><br><span class="line">normData = zeros((dataMat.shape[<span class="number">0</span>] + <span class="number">1</span>, dataMat.shape[<span class="number">1</span>]))</span><br><span class="line">index = <span class="number">0</span></span><br><span class="line"><span class="keyword">for</span> matPart <span class="keyword">in</span> dataMat:</span><br><span class="line">    normData[index:] = matPart</span><br><span class="line">    index += <span class="number">1</span></span><br><span class="line">normData[index:] = array([<span class="number">0.1</span>, <span class="number">200</span>, <span class="number">1.0</span>])</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{normData=}
\begin{bmatrix}
0.8 &amp; 400 &amp; 0.5 \\
12 &amp; 134000 &amp; 0.9 \\
0 &amp; 20000 &amp; 1.1 \\
67 &amp; 32000 &amp; 0.1 \\
0.1 &amp; 200 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取每个特征的最小值</span></span><br><span class="line">minVals = normData.<span class="built_in">min</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{minVals=}
\begin{bmatrix}
0 &amp; 200 &amp; 0.1 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 获取每个特征的最大值</span></span><br><span class="line">maxVals = dataSet.<span class="built_in">max</span>(<span class="number">0</span>)</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{maxVals=}
\begin{bmatrix}
67 &amp; 134000 &amp; 1.1 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">m = normData.shape[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 由前面提供的归一化数据公式进行数据归一化</span></span><br><span class="line">normMat = (normData - tile(minVals, (m, <span class="number">1</span>))) / tile((maxVals - minVals), (m, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\begin{align}
\mathtt{normMat} = \frac{oldValue-min}{max-min}
&amp; = \frac{
\begin{bmatrix}
0.8 &amp; 400 &amp; 0.5 \\
12 &amp; 134000 &amp; 0.9 \\
0 &amp; 20000 &amp; 1.1 \\
67 &amp; 32000 &amp; 0.1 \\
0.1 &amp; 200 &amp; 1 \\
\end{bmatrix}
-
\begin{bmatrix}
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
\end{bmatrix}
}{
\begin{bmatrix}
67 &amp; 134000 &amp; 1.1 \\
67 &amp; 134000 &amp; 1.1 \\
67 &amp; 134000 &amp; 1.1 \\
67 &amp; 134000 &amp; 1.1 \\
67 &amp; 134000 &amp; 1.1 \\
\end{bmatrix}
-
\begin{bmatrix}
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
0 &amp; 200 &amp; 0.1 \\
\end{bmatrix}
}
\\
&amp; =
\begin{bmatrix}
\frac{0.8-0}{67-0} &amp; \frac{400-200}{134000-200} &amp;
\frac{0.5-0.1}{1.1-0.1} \\
\frac{12-0}{67-0} &amp; \frac{134000-200}{134000-200} &amp;
\frac{0.9-0.1}{1.1-0.1} \\
\frac{0-0}{67-0} &amp; \frac{20000-200}{134000-200} &amp;
\frac{1.1-0.1}{1.1-0.1} \\
\frac{67-0}{67-0} &amp; \frac{32000-200}{134000-200} &amp;
\frac{0.1-0.1}{1.1-0.1} \\
\frac{0.1-0}{67-0} &amp; \frac{200-200}{134000-200} &amp;
\frac{1-0.1}{1.1-0.1} \\
\end{bmatrix}
\\
&amp; =
\begin{bmatrix}
0.0119403 &amp; 0.00149477 &amp; 0.4 \\
0.17910448 &amp; 1. &amp; 0.8 \\
0 &amp; 0.14798206 &amp; 1. \\
1 &amp; 0.23766816 &amp; 0. \\
0.00149254 &amp; 0. &amp; 0.9 \\
\end{bmatrix}
\end{align}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 待计算分类的样本</span></span><br><span class="line">item = normMat[<span class="built_in">len</span>(normMat) - <span class="number">1</span>,:]</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{item=}
\begin{bmatrix}
0.00149254 &amp; 0. &amp; 0.9 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 算法训练样本集</span></span><br><span class="line">dataSet = normMat[<span class="number">0</span>:<span class="built_in">len</span>(normMat) - <span class="number">1</span>,:]</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{dataSet=}
\begin{bmatrix}
0.0119403 &amp; 0.00149477 &amp; 0.4 \\
0.17910448 &amp; 1. &amp; 0.8 \\
0 &amp; 0.14798206 &amp; 1. \\
1 &amp; 0.23766816 &amp; 0. \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算样本集的欧氏距离，详细流程阅读《机器学习中的距离计算》</span></span><br><span class="line">diffMat = tile(item, (dataSet.shape[<span class="number">0</span>], <span class="number">1</span>)) - dataSet</span><br><span class="line">sqDiffMat = diffMat ** <span class="number">2</span></span><br><span class="line">sqDistances = sqDiffMat.<span class="built_in">sum</span>(axis=<span class="number">1</span>)</span><br><span class="line">distances = sqDistances ** <span class="number">0.5</span></span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{distances=}
\begin{bmatrix}
0.50011138 \\
1.02056161 \\
0.17860828 \\
1.36510194 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 对计算完的距离列表排序，输出记录距离原始位置的列表，因为要找到对应的分类</span></span><br><span class="line">sortedDistIndicies = distances.argsort()</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
\mathtt{sortedDistIndicies=}
\begin{bmatrix}
0.50011138_0 \\
1.02056161_1 \\
0.17860828_2 \\
1.36510194_3 \\
\end{bmatrix}
=^{sort}
\begin{bmatrix}
0.17860828_2 \\
0.50011138_0 \\
1.02056161_1 \\
1.36510194_3 \\
\end{bmatrix}
=
\begin{bmatrix}
2 \\
0 \\
1 \\
3 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 统计样本集中前k个样本集分类出现的次数</span></span><br><span class="line">classCount = &#123;&#125;</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(k):</span><br><span class="line">    voteIlabel = classLabelVector[sortedDistIndicies[i]]</span><br><span class="line">    classCount[voteIlabel] = classCount.get(voteIlabel, <span class="number">0</span>) + <span class="number">1</span></span><br><span class="line"><span class="comment"># 按照分类出现次数由高到低排序</span></span><br><span class="line">sortedClassCount = <span class="built_in">sorted</span>(classCount.iteritems(), key=operator.itemgetter(<span class="number">1</span>),reverse=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<blockquote>
<p>本案例只是作为熟悉使用k-近邻算法，因为样本集个数和质量问题并没有得出最终的算法结果，如果要得出正确的结果，需要添加更多的样本集数量重新验证本算法。</p>
</blockquote>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>kNN</tag>
      </tags>
  </entry>
  <entry>
    <title>决策树（ID3）</title>
    <url>/2017/05/02/%E5%86%B3%E7%AD%96%E6%A0%91%EF%BC%88ID3%EF%BC%89/</url>
    <content><![CDATA[<h2 id="算法原理">算法原理</h2>
<hr />
<p>  在机器学习中，有多种构造决策树的方法，本文只讨论ID3的决策树。</p>
<p>  决策树顾名思义就是使用样本集数据构造一颗树，一棵树会有很多枝干节点和叶子节点。决策树算法会把最终结果放在叶子节点，所以要知道算法结果，我们必须从根节点开始一节一节通过树枝干节点找到结果所在的叶子节点。</p>
<span id="more"></span>
<p>  一个树的数据模型应该是结构非常清晰并且数据形式非常容易理解的。构造决策树算法中枝干部分会由数据的特征值来创建。在算法计算中，我们通过未知分类数据的某一个特征的特征值从由决策树构建的树模型中找到对应的枝干，然后在用下一个特征的特征值找到该枝干的子枝干部分，这样一级一级找下去，当所有的特征都用完了的时候，我们就找到了叶子节点的位置，最后得出结论。</p>
<p>  说的更形象一点，决策树类似于我们做开发时候的条件语句嵌套：</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">如果 a=<span class="number">1</span>:</span><br><span class="line">    如果 b=<span class="number">1</span>:</span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ...</span><br><span class="line"><span class="keyword">else</span>:</span><br><span class="line">    如果 c=<span class="number">1</span>:</span><br><span class="line">        ...</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        ...</span><br></pre></td></tr></table></figure>
<p>这样一只嵌套下去，然后得到一个最终的结果。</p>
<p>  决策树算法可以将算法训练结果即树模型存储起来避免重复构建决策树。</p>
<h2 id="算法条件">算法条件</h2>
<hr />
<ol type="1">
<li>ID3算法最适合处理标称型的数据，无法直接处理数值型数据，如果要处理数值型数据，我们需要通过量化的方法将数值型数据转化为标称型数据；</li>
<li>特征划分如果过多，ID3算法会面临其他问题；</li>
</ol>
<h2 id="数据划分">数据划分</h2>
<hr />
<p>  前面算法原理中讲到决策树的树模型，在算法构建决策树模型的时候，我们第一应该考虑的问题是到底应该由数据集的哪个特征来先创建决策树模型的枝干会更好一点？所以在决策树算法中需要考虑怎么对数据做划分会更好。</p>
<p>  划分数据的原则是将本来无序的数据变得更加有序，我们使用决策树算法来处理的数据一般都是一些杂乱无章的数据，无序数据的特征互不相干且数据不易理解，对该类型的数据划分我们这里选择使用<code>信息论</code>来量化<code>度量信息</code>。在数据划分前后信息发生的变化叫做<code>信息增益</code>，通过计算每个特征值划分数据集获得的信息增益并取信息增益最高的特征就是最好的数据划分特征。</p>
<p>  计算信息增益的度量方式是<code>香农熵</code>或简称<code>熵</code>，熵被定义为信息的期望值。信息的定义公式：
<span class="math display">\[
l(x_i)=-log_2p(x_i)
\]</span> 在决策树算法中，<span
class="math inline">\(x_i\)</span>为类别，<span
class="math inline">\(p(x_i)\)</span>为在样本数据集中选择该分类的概率，即<span
class="math inline">\(x_i\)</span>类别的样本数量除以样本集大小。为了计算熵，我们需要计算所有类别所有可能值包含的信息期望值，计算熵的公式：
<span class="math display">\[
H=-\sum_{i=1}^np(x_i)log_2p(x_i)
\]</span>
数据的熵值越大说明混合的数据越多，也就是说数据集的熵越大，则表示该数据集越无序。</p>
<h2 id="算法流程">算法流程</h2>
<hr />
<ol type="1">
<li>计算当前样本数据集的熵；</li>
<li>遍历当前样本集的特征，然后按照每个特征的特征值将数据集拆分成若干子集；</li>
<li>计算每个子集的熵，使用子集的熵乘以该子集的概率（子集尺寸除以当前数据集的尺寸）然后做相加操作即为按照该特征划分数据的信息增益；</li>
<li>选取一个信息增益最大的特征作为划分数据特征；</li>
<li>按照第4步获取特征的特征值对当前样本集做数据划分；</li>
<li>使用第5步获取的样本子集重新从第1步开始操作，直到新划分的子集没有特征可划分或样本集中只有单一分类即最终的叶子节点。</li>
</ol>
<h2 id="算法实现">算法实现</h2>
<hr />
<h3 id="python">Python</h3>
<p>  实验使用《机器学习实战》一书中的<code>海洋生物数据</code>作为数据集。</p>
<table>
<thead>
<tr class="header">
<th style="text-align: center;">不浮出水面十分可以生存</th>
<th style="text-align: center;">是否有脚蹼</th>
<th style="text-align: center;">属于鱼类</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
</tr>
<tr class="even">
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">是</td>
</tr>
<tr class="odd">
<td style="text-align: center;">是</td>
<td style="text-align: center;">否</td>
<td style="text-align: center;">否</td>
</tr>
<tr class="even">
<td style="text-align: center;">否</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">否</td>
</tr>
<tr class="odd">
<td style="text-align: center;">否</td>
<td style="text-align: center;">是</td>
<td style="text-align: center;">否</td>
</tr>
</tbody>
</table>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> math <span class="keyword">import</span> log</span><br><span class="line"><span class="keyword">import</span> operator</span><br><span class="line"><span class="comment"># 创建算法训练样本集和特征名称列表</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createDataSet</span>():</span><br><span class="line">    dataSet = [[<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>], [<span class="number">1</span>, <span class="number">1</span>, <span class="string">&#x27;yes&#x27;</span>], [<span class="number">1</span>, <span class="number">0</span>, <span class="string">&#x27;no&#x27;</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>], [<span class="number">0</span>, <span class="number">1</span>, <span class="string">&#x27;no&#x27;</span>]]</span><br><span class="line">    labels = [<span class="string">&#x27;no surfacing&#x27;</span>, <span class="string">&#x27;flippers&#x27;</span>]</span><br><span class="line">    <span class="keyword">return</span> dataSet, labels</span><br><span class="line"><span class="comment"># 计算数据集的熵</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcShannonEnt</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 数据集中样本数量</span></span><br><span class="line">    numEntries = <span class="built_in">len</span>(dataSet)</span><br><span class="line">    <span class="comment"># 数据集中每种类别的数量</span></span><br><span class="line">    labelCounts = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        currentLabel = featVec[-<span class="number">1</span>]</span><br><span class="line">        <span class="keyword">if</span> currentLabel <span class="keyword">not</span> <span class="keyword">in</span> labelCounts.keys():</span><br><span class="line">            labelCounts[currentLabel] = <span class="number">0</span></span><br><span class="line">        labelCounts[currentLabel] += <span class="number">1</span></span><br><span class="line">    shannonEnt = <span class="number">0.0</span></span><br><span class="line">    <span class="comment"># 根据香农熵公式计算数据集的熵</span></span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> labelCounts:</span><br><span class="line">        prob = <span class="built_in">float</span>(labelCounts[key]) / numEntries</span><br><span class="line">        shannonEnt -= prob * log(prob, <span class="number">2</span>)</span><br><span class="line">    <span class="keyword">return</span> shannonEnt</span><br><span class="line"><span class="comment"># 划分数据并返回输入数据集中特征axis的值为value的数据子集</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">splitDataSet</span>(<span class="params">dataSet, axis, value</span>):</span><br><span class="line">    retDataSet = []</span><br><span class="line">    <span class="keyword">for</span> featVec <span class="keyword">in</span> dataSet:</span><br><span class="line">        <span class="keyword">if</span> featVec[axis] == value:</span><br><span class="line">            reducedFeatVec = featVec[:axis]</span><br><span class="line">            reducedFeatVec.extend(featVec[axis+<span class="number">1</span>:])</span><br><span class="line">            retDataSet.append(reducedFeatVec)</span><br><span class="line">    <span class="keyword">return</span> retDataSet</span><br><span class="line"><span class="comment"># 从当前数据集中选择最好的划分数据特征</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chooseBestFeatureToSplit</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 特征数量</span></span><br><span class="line">    numFeatures = <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) - <span class="number">1</span></span><br><span class="line">    <span class="comment"># 当前数据集的熵</span></span><br><span class="line">    baseEntropy = calcShannonEnt(dataSet)</span><br><span class="line">    bestInfoGain = <span class="number">0.0</span></span><br><span class="line">    bestFeature = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 遍历所有特征，分别计算按该特征划分数据后的熵，取熵值最小的特征作为数据划分特征，即熵越小，数据集越有序，信息增益越大</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numFeatures):</span><br><span class="line">        <span class="comment"># 特征值列表</span></span><br><span class="line">        featList =[example[i] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">        <span class="comment"># 特征值排重</span></span><br><span class="line">        uniqueVals = <span class="built_in">set</span>(featList)</span><br><span class="line">        newEntropy = <span class="number">0.0</span></span><br><span class="line">        <span class="comment"># 遍历所有特征值，并做预划分，返回计算该特征划分后在总数据集中的熵</span></span><br><span class="line">        <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">            subDataSet = splitDataSet(dataSet, i, value)</span><br><span class="line">            <span class="comment"># 计算特征取value的概率，即取该特征值在数据集中的次数除以数据集的实例总数</span></span><br><span class="line">            prob = <span class="built_in">len</span>(subDataSet) / <span class="built_in">float</span>(<span class="built_in">len</span>(dataSet))</span><br><span class="line">            newEntropy += prob * calcShannonEnt(subDataSet)</span><br><span class="line">        infoGain = baseEntropy - newEntropy</span><br><span class="line">        <span class="keyword">if</span> (infoGain &gt; bestInfoGain):</span><br><span class="line">            bestInfoGain = infoGain</span><br><span class="line">            bestFeature = i</span><br><span class="line">    <span class="keyword">return</span> bestFeature</span><br><span class="line"><span class="comment"># 生成叶子节点，如果已经没有特征做数据划分时，取该数据集中出现次数最多的类别作为待分类类别的结果</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">majorityCnt</span>(<span class="params">classList</span>):</span><br><span class="line">    classCount = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> vote <span class="keyword">in</span> classList:</span><br><span class="line">        <span class="keyword">if</span> vote <span class="keyword">not</span> <span class="keyword">in</span> classCount.keys():</span><br><span class="line">            classCount[vote] = <span class="number">0</span></span><br><span class="line">        classCount[vote] += <span class="number">1</span></span><br><span class="line">    sortedClassCount = <span class="built_in">sorted</span>(classCount.iteritems(), key=operator.attrgetter(<span class="number">1</span>), reverse=<span class="literal">True</span>)</span><br><span class="line">    <span class="keyword">return</span> sortedClassCount[<span class="number">0</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 创建决策树模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet, labels</span>):</span><br><span class="line">    classList = [example[-<span class="number">1</span>] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    <span class="comment"># 如果数据集中样本类别唯一，则不用做数据划分，直接返回类别作为叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> classList.count(classList[<span class="number">0</span>]) == <span class="built_in">len</span>(classList):</span><br><span class="line">        <span class="keyword">return</span> classList[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 如果当前数据集中的样本没有可做数据划分的特征，则计算样本集中出现频率最高的类别作为叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(dataSet[<span class="number">0</span>]) == <span class="number">1</span>:</span><br><span class="line">        <span class="keyword">return</span> majorityCnt(classList)</span><br><span class="line">    bestFeat = chooseBestFeatureToSplit(dataSet)</span><br><span class="line">    bestFeatLabel = labels[bestFeat]</span><br><span class="line">    myTree = &#123;bestFeatLabel:&#123;&#125;&#125;</span><br><span class="line">    <span class="keyword">del</span>(labels[bestFeat])</span><br><span class="line">    featValues = [example[bestFeat] <span class="keyword">for</span> example <span class="keyword">in</span> dataSet]</span><br><span class="line">    uniqueVals = <span class="built_in">set</span>(featValues)</span><br><span class="line">    <span class="keyword">for</span> value <span class="keyword">in</span> uniqueVals:</span><br><span class="line">        subLabels = labels[:]</span><br><span class="line">        myTree[bestFeatLabel][value] = createTree(splitDataSet(dataSet, bestFeat, value), subLabels)</span><br><span class="line">    <span class="keyword">return</span> myTree</span><br><span class="line"><span class="comment"># 决策树模型储存</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">storeTree</span>(<span class="params">inputTree, filename</span>):</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fw = <span class="built_in">open</span>(filename, <span class="string">&#x27;w&#x27;</span>)</span><br><span class="line">    pickle.dump(inputTree, fw)</span><br><span class="line">    fw.close()</span><br><span class="line"><span class="comment"># 决策树模型导入</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">grabTree</span>(<span class="params">filename</span>):</span><br><span class="line">    <span class="keyword">import</span> pickle</span><br><span class="line">    fr = <span class="built_in">open</span>(filename)</span><br><span class="line">    <span class="keyword">return</span> pickle.load(fr)</span><br><span class="line"><span class="comment"># 使用决策树做分类判定</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classify</span>(<span class="params">inputTree, labels, testVec</span>):</span><br><span class="line">    firstStr = inputTree.keys()[<span class="number">0</span>]</span><br><span class="line">    <span class="built_in">print</span> firstStr, inputTree, labels</span><br><span class="line">    secondDict = inputTree[firstStr]</span><br><span class="line">    featIndex = labels.index(firstStr)</span><br><span class="line">    <span class="keyword">for</span> key <span class="keyword">in</span> secondDict.keys():</span><br><span class="line">        <span class="keyword">if</span> testVec[featIndex] == key:</span><br><span class="line">            <span class="keyword">if</span> <span class="built_in">type</span>(secondDict[key]).__name__ == <span class="string">&#x27;dict&#x27;</span>:</span><br><span class="line">                classLabel = classify(secondDict[key], labels, testVec)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                classLabel = secondDict[key]</span><br><span class="line">    <span class="keyword">return</span> classLabel</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>决策树</tag>
      </tags>
  </entry>
  <entry>
    <title>朴素贝叶斯</title>
    <url>/2017/05/03/%E6%9C%B4%E7%B4%A0%E8%B4%9D%E5%8F%B6%E6%96%AF/</url>
    <content><![CDATA[<p>  朴素贝叶斯算法是基于概率论的分类方法，在机器学习算法做分类判定的时候，有时我们并不需要算法给出一个明确的分类答案，因为分类器会产生错误结果，我们更偏向于获得分类器判定的一个最优的类别猜测结果，并用这个猜测的概率值来评估分类结果的可信度。</p>
<span id="more"></span>
<h2 id="算法原理">算法原理</h2>
<hr />
<p>  贝叶斯决策理论是朴素贝叶斯的核心内容，贝叶斯决策理论是选择具有最高概率的决策，通俗点讲就是事物a属于<span
class="math inline">\(c_1\)</span>的概率如果大于事物a属于<span
class="math inline">\(c_2\)</span>的概率，那么我们就判定事物a为<span
class="math inline">\(c_1\)</span>,相反则属于<span
class="math inline">\(c_2\)</span>，即公式 <span class="math display">\[
C=p(a|c_1) &gt; p(a|c_2) \Rightarrow c_1
\]</span></p>
<p><span class="math display">\[
C=p(a|c_1) &lt; p(a|c_2) \Rightarrow c_2
\]</span></p>
<p><span
class="math inline">\(p(a|c_1)\)</span>为条件概率，是限定条件为<span
class="math inline">\(c_1\)</span>的情况下，<span
class="math inline">\(a\)</span>的概率。贝叶斯准则是有效计算条件概率的方法：
<span class="math display">\[
p(c|x) = \frac{p(x|c)p(c)}{p(x)}
\]</span> 即在限定条件为<span class="math inline">\(x\)</span>，<span
class="math inline">\(c\)</span>的概率为限定条件为<span
class="math inline">\(c\)</span>，<span
class="math inline">\(x\)</span>的概率和<span
class="math inline">\(c\)</span>的概率的积除以<span
class="math inline">\(x\)</span>的概率。</p>
<p>  朴素贝叶斯算法经常被用于文档分类的判定。在算法实现中，我们将算法训练样本集转换成词向量格式。在一个文档样本中，根据所有样本集中词或句子的集合，来用1和0表示词或句子是否出现作为文档样本的一个特征，这样可以将样本集中的每个文档样本都被表示为向量的方式：
<span class="math display">\[
vector=[0, 1, 1, 0, 1, 0, \cdots, 0]
\]</span>
该方式叫做<code>词集模型</code>；如果一个词或句子在样本中出现不止一次，为了捕获这种不能表达的某种样本特征信息，在构建样本向量时，使用0表示词或句子没有出现，而大于0的数值表示该词或句子在样本文档中出现的次数
<span class="math display">\[
vector=[0, 1, 0, 2, 5, \cdots, 1]
\]</span> 这种构建样本文档向量的方式叫做<code>词袋模型</code>。</p>
<p>  根据贝叶斯准则公式，推导出计算样本文档类别概率的公式： <span
class="math display">\[
p(c_i|w) = \frac{p(w|c_i)p(c_i)}{p(w)}
\]</span> <span
class="math inline">\(p(c_i)\)</span>表示类别概率，通过类别<span
class="math inline">\(c_i\)</span>中样本文档数除以总的样本数量计算。<span
class="math inline">\(p(w|c_i)\)</span>表示在限定类别为<span
class="math inline">\(c_i\)</span>的条件下，样本文档<span
class="math inline">\(w\)</span>的概率，由于我们已经将文档<span
class="math inline">\(w\)</span>转换为向量的格式，所以<span
class="math inline">\(p(w|c_i)\)</span>把<span
class="math inline">\(w\)</span>展开为一个个独立的特征可以写成<span
class="math inline">\(p(w_0,w_1,w_2,\cdots,w_n)\)</span>，接下来我们假设文档向量中的所有词都相互独立，该假设也称作<code>条件独立性假设</code>，朴素贝叶斯算法中<code>朴素</code>一词也来源于算法中简单朴素的这些假设。现在我们计算文档类别概率的公式可以修改为：
<span class="math display">\[
\begin{align}
p(c_i|w)
&amp;= \frac{p(w_0|c_i)p(w_1|c_i)p(w_2|c_i) \cdots
p(w_n|c_i)p(c_i)}{p(w)} \\
&amp;= \frac{\prod_{i=1,j=1}^np(w_j|c_i)p(c_i)}{p(w)} \\
\end{align}
\]</span>   前面我们已经知道了<span
class="math inline">\(p(c_i)\)</span>的计算方式，<span
class="math inline">\(p(w_n|c_i)\)</span>的计算方法类似，在限定类别为<span
class="math inline">\(c_i\)</span>的条件下，计算特征<span
class="math inline">\(w_n\)</span>的出现的次数除以所有特征出现的总次数。由于在朴素贝叶斯算法中分母<span
class="math inline">\(p(w)\)</span>的值都相同，所以我们只需要计算公式中分子的内容。</p>
<h2 id="算法修正">算法修正</h2>
<hr />
<p>  根据上面推导后得来的最终概率公式可以得知，如果分子中任意一个概率为0时，则因为相乘的关系，整个分子值都为0。显然这是不正确的，所以我为了避免这种特殊情况的发生，在计算概率<span
class="math inline">\(p(w_n|c_i)\)</span>时，特征<span
class="math inline">\(w_n\)</span>的出现的次数从1开始统计，并将分母所有特征出现的总次数起始值设定为2。</p>
<p>  由于概率的值都是很小的数，所以在计算乘积时最后的结果会下溢出或得到不正确的答案。合理规避这个问题的方式就是对最终的乘积取自然对数，同时采用自然对数的处理不会对结果产生任何损失。在代数中对数公式有
<span class="math display">\[
ln(a*b) = ln(a)+ln(b)
\]</span> 所以朴素贝叶斯算法中的概率公式可以改写为 <span
class="math display">\[
\begin{align}
p(c_i|w)
&amp;= \frac{ln(p(w_0|c_i))+ln(p(w_1|c_i))+ \cdots +
ln(p(w_n|c_i))+ln(p(c_i))}{p(w)} \\
&amp;= \frac{\sum_{i=1,j=1}^nln(p(w_j|c_i))+ln(p(c_i))}{p(w)} \\
\end{align}
\]</span></p>
<h2 id="算法条件">算法条件</h2>
<hr />
<ol type="1">
<li>朴素贝叶斯算法适用于标称型数据或数值型数据；</li>
<li>算法结果对输入数据比较敏感，所以可能需要花费更多的时间在对算法输入数据的处理中；</li>
</ol>
<h2 id="算法实现">算法实现</h2>
<hr />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadDataSet</span>():</span><br><span class="line">    postingList=[[<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;has&#x27;</span>, <span class="string">&#x27;flea&#x27;</span>, <span class="string">&#x27;problems&#x27;</span>, <span class="string">&#x27;help&#x27;</span>, <span class="string">&#x27;please&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;maybe&#x27;</span>, <span class="string">&#x27;not&#x27;</span>, <span class="string">&#x27;take&#x27;</span>, <span class="string">&#x27;him&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;park&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>, <span class="string">&#x27;is&#x27;</span>, <span class="string">&#x27;so&#x27;</span>, <span class="string">&#x27;cute&#x27;</span>, <span class="string">&#x27;I&#x27;</span>, <span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;posting&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;garbage&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;mr&#x27;</span>, <span class="string">&#x27;licks&#x27;</span>, <span class="string">&#x27;ate&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;steak&#x27;</span>, <span class="string">&#x27;how&#x27;</span>, <span class="string">&#x27;to&#x27;</span>, <span class="string">&#x27;stop&#x27;</span>, <span class="string">&#x27;him&#x27;</span>],</span><br><span class="line">                 [<span class="string">&#x27;quit&#x27;</span>, <span class="string">&#x27;buying&#x27;</span>, <span class="string">&#x27;worthless&#x27;</span>, <span class="string">&#x27;dog&#x27;</span>, <span class="string">&#x27;food&#x27;</span>, <span class="string">&#x27;stupid&#x27;</span>]]</span><br><span class="line">    classVec = [<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>,<span class="number">0</span>,<span class="number">1</span>]    <span class="comment">#1 is abusive, 0 not</span></span><br><span class="line">    <span class="keyword">return</span> postingList,classVec</span><br><span class="line">                 </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createVocabList</span>(<span class="params">dataSet</span>):</span><br><span class="line">    vocabSet = <span class="built_in">set</span>([])  <span class="comment">#create empty set</span></span><br><span class="line">    <span class="keyword">for</span> document <span class="keyword">in</span> dataSet:</span><br><span class="line">        vocabSet = vocabSet | <span class="built_in">set</span>(document) <span class="comment">#union of the two sets</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">list</span>(vocabSet)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">setOfWords2Vec</span>(<span class="params">vocabList, inputSet</span>):</span><br><span class="line">    returnVec = [<span class="number">0</span>]*<span class="built_in">len</span>(vocabList)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] = <span class="number">1</span></span><br><span class="line">        <span class="keyword">else</span>: <span class="built_in">print</span> <span class="string">&quot;the word: %s is not in my Vocabulary!&quot;</span> % word</span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">trainNB0</span>(<span class="params">trainMatrix,trainCategory</span>):</span><br><span class="line">    numTrainDocs = <span class="built_in">len</span>(trainMatrix)</span><br><span class="line">    numWords = <span class="built_in">len</span>(trainMatrix[<span class="number">0</span>])</span><br><span class="line">    pAbusive = <span class="built_in">sum</span>(trainCategory)/<span class="built_in">float</span>(numTrainDocs)</span><br><span class="line">    p0Num = ones(numWords); p1Num = ones(numWords)      <span class="comment">#change to ones() </span></span><br><span class="line">    p0Denom = <span class="number">2.0</span>; p1Denom = <span class="number">2.0</span>                        <span class="comment">#change to 2.0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numTrainDocs):</span><br><span class="line">        <span class="keyword">if</span> trainCategory[i] == <span class="number">1</span>:</span><br><span class="line">            p1Num += trainMatrix[i]</span><br><span class="line">            p1Denom += <span class="built_in">sum</span>(trainMatrix[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            p0Num += trainMatrix[i]</span><br><span class="line">            p0Denom += <span class="built_in">sum</span>(trainMatrix[i])</span><br><span class="line">    p1Vect = log(p1Num/p1Denom)          <span class="comment">#change to log()</span></span><br><span class="line">    p0Vect = log(p0Num/p0Denom)          <span class="comment">#change to log()</span></span><br><span class="line">    <span class="keyword">return</span> p0Vect,p1Vect,pAbusive</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">classifyNB</span>(<span class="params">vec2Classify, p0Vec, p1Vec, pClass1</span>):</span><br><span class="line">    p1 = <span class="built_in">sum</span>(vec2Classify * p1Vec) + log(pClass1)    <span class="comment">#element-wise mult</span></span><br><span class="line">    p0 = <span class="built_in">sum</span>(vec2Classify * p0Vec) + log(<span class="number">1.0</span> - pClass1)</span><br><span class="line">    <span class="keyword">if</span> p1 &gt; p0:</span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">bagOfWords2VecMN</span>(<span class="params">vocabList, inputSet</span>):</span><br><span class="line">    returnVec = [<span class="number">0</span>]*<span class="built_in">len</span>(vocabList)</span><br><span class="line">    <span class="keyword">for</span> word <span class="keyword">in</span> inputSet:</span><br><span class="line">        <span class="keyword">if</span> word <span class="keyword">in</span> vocabList:</span><br><span class="line">            returnVec[vocabList.index(word)] += <span class="number">1</span></span><br><span class="line">    <span class="keyword">return</span> returnVec</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testingNB</span>():</span><br><span class="line">    listOPosts,listClasses = loadDataSet()</span><br><span class="line">    myVocabList = createVocabList(listOPosts)</span><br><span class="line">    trainMat=[]</span><br><span class="line">    <span class="keyword">for</span> postinDoc <span class="keyword">in</span> listOPosts:</span><br><span class="line">        trainMat.append(setOfWords2Vec(myVocabList, postinDoc))</span><br><span class="line">    p0V,p1V,pAb = trainNB0(array(trainMat),array(listClasses))</span><br><span class="line">    testEntry = [<span class="string">&#x27;love&#x27;</span>, <span class="string">&#x27;my&#x27;</span>, <span class="string">&#x27;dalmation&#x27;</span>]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="built_in">print</span> testEntry,<span class="string">&#x27;classified as: &#x27;</span>,classifyNB(thisDoc,p0V,p1V,pAb)</span><br><span class="line">    testEntry = [<span class="string">&#x27;stupid&#x27;</span>, <span class="string">&#x27;garbage&#x27;</span>]</span><br><span class="line">    thisDoc = array(setOfWords2Vec(myVocabList, testEntry))</span><br><span class="line">    <span class="built_in">print</span> testEntry,<span class="string">&#x27;classified as: &#x27;</span>,classifyNB(thisDoc,p0V,p1V,pAb)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>朴素贝叶斯</tag>
      </tags>
  </entry>
  <entry>
    <title>Logistic回归</title>
    <url>/2017/05/04/Logistic%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<p>  Logistic回归算法是一个求最优解的算法，算法的目标是训练一个非线性函数用于分类判定。</p>
<p>  回归的定义是把平面上的一系列点用一条线对这些点进行拟合，这个拟合的过程叫做<code>回归</code>，这条线就做<code>最佳拟合线</code>。拟合的定义是把平面上一系列点用一条线连接起来。利用Logistic回归算法进行分类是根据现有数据对分类边界建立回归公式，且算法需要找到一个最佳拟合参数用来分类判定，所以Logistic回归算法在算法训练过程中，主要就是为了找到最佳的分类回归系数。</p>
<span id="more"></span>
<h2 id="算法原理">算法原理</h2>
<hr />
  为了实现算法分类判定，我们需要有一个函数能接受所有的样本特征输入，然后预测出样本类别，在二分类判定中，我们要求该函数输出0或1，这种函数被称作<code>海维塞德阶跃函数</code>或<code>单位阶跃函数</code>，<code>Sigmoid</code>函数满足我们的要求，Sigmoid函数公式为：
<span class="math display">\[
\sigma(z) = \frac1{1+e^{-z}}
\]</span>
<center>
<img src="/2017/05/04/Logistic%E5%9B%9E%E5%BD%92/sigmoid.jpg" class="" title="可以看到将横坐标尺度放大时，Sigmoid函数很像一个阶跃函数">
</center>
<p>  所以为了实现Logistic回归分类器，我们可以在每一个特征上乘以一个回归系数，然后把所有结果相加并带入Sigmoid函数中得到一个0～1之间的数值，任何大于0.5的数据被分为1类，小于0.5则属于0类，即Sigmoid的输入公式为
<span class="math display">\[
z=w_0 + w_1x_1 + w_2x_2 + \cdots + w_ix_i
\]</span> 这里将样本特征<span
class="math inline">\(x\)</span>个数定义为<span
class="math inline">\(i\)</span>，为了方便计算，将特征<span
class="math inline">\(x_0\)</span>的值设置为1，则上述公式可以表示为
<span class="math display">\[
\begin{align}
z
&amp;= w_0 + w_1x_1 + w_2x_2 + \cdots + w_ix_i \\
&amp;= w_0x_0 + w_1x_1 + w_2x_2 + \cdots + w_ix_i \\
&amp;= w^Tx
\end{align}
\]</span> 因此可以推导出Logistic回归算法中的预测函数 <span
class="math display">\[
h(x_i) = \sigma(w^Tx) = \frac1{1+e^{-w^Tx}}
\]</span>   上面确定了分类器的函数形式，但是里面有个回归系数<span
class="math inline">\(w\)</span>，现在我们需要基于最优化方法来确定最佳回归系数来对样本数据做最佳拟合。</p>
<h2 id="最大似然估计">最大似然估计</h2>
<hr />
<p>  在计算最佳回归系数的时候会用到<code>最大似然估计</code>方法，所以这里先介绍这个概念。</p>
<p>  现在已经拿到了很多个样本，这些样本值已经实现，最大似然估计就是去找到那个参数估计值，使得前面已经实现的样本值发生概率最大。因为你手头上的样本已经实现了，其发生概率最大才符合逻辑。通俗一点的解释就是利用已知的样本结果，反推最有可能（最大概率）导致这样结果的参数值。</p>
<p>  比如一个麻袋里有白球与黑球，但是我不知道它们之间的比例，那我就有放回的抽取10次，结果我发现我抽到了8次黑球2次白球，我要求最有可能的黑白球之间的比例时，就采取最大似然估计法：我假设我抽到黑球的概率为<span
class="math inline">\(p\)</span>,那得出8次黑球2次白球这个结果的概率为：<span
class="math inline">\(P=p^8(1-p)^2\)</span>，现在我想要得出p是多少，使得P最大的p就是我要求的结果。</p>
<p>  同理，在Logistic回归中，对单个样本分类为0或1的概率表示为 <span
class="math display">\[
p(y_1=1|x_1) = \sigma(z_1)
\]</span></p>
<p><span class="math display">\[
p(y_1=0|x_1) = 1-\sigma(z_1)
\]</span></p>
<p>用一个公式表示产生该样本的概率为 <span class="math display">\[
p(y_1|x_1) =\sigma(z_1)^{y_1}(1-\sigma(z_1))^{1-y_1}
\]</span> 因为<span
class="math inline">\(y_1\)</span>表示0或1两个分类结果，所以<span
class="math inline">\(y_1\)</span>和<span
class="math inline">\(1-y_1\)</span>表示指定产生概率只有产生和没产生两种。根据上面描述的最大似然估计和单样本产生概率公式，可以得出生成当前样本集的最大似然估计函数，定义样本数量为<span
class="math inline">\(n\)</span> <span class="math display">\[
\begin{align}
L(z_i)
&amp;= p(y_1|x_1)p(y_2|x_2)p(y_3|x_3) \cdots p(y_n|x_n) \\
&amp;= \prod_{i=1}^np(y_i|x_i) \\
&amp;= \prod_{i=1}^n(\sigma(z_i))^{y_i}(1-\sigma(z_i))^{1-y_i}
\end{align}
\]</span> 为了方便计算，对<span
class="math inline">\(L(z_i)\)</span>取对数，这样连乘积变成了线性加总，且不会改变极值的位置（前面朴素贝叶斯算法中也有用到）
<span class="math display">\[
\begin{align}
l(z_i)
&amp;= logL(z_i) \\
&amp;=log(\sigma(z_i)^{y_i}(1-\sigma(z_i))^{1-y_i}) \\
&amp;= \sum_{i=1}^n(y_ilog(\sigma(z_i))+(1-y_i)log(1-\sigma(z_i)))
\end{align}
\]</span>   现在我们知道通过计算最大似然估计函数<span
class="math inline">\(l(z_i)\)</span>就表示回归算法会更接近于当前样本的实际分类状态，根据公式中输入参数<span
class="math inline">\(z_i\)</span>的计算公式 <span
class="math display">\[
z=w^Tx
\]</span> 所以我们重新更新最大似然估计函数<span
class="math inline">\(l(z_i)\)</span>为<span
class="math inline">\(l(w_i)\)</span> <span class="math display">\[
\begin{align}
l(w_i)
&amp;=l(z_i)  \\
&amp;= l(w_i^Tx_i) \\
&amp;=
\sum_{i=1}^n(y_ilog(\sigma(w_i^Tx_i))+(1-y_i)log(1-\sigma(w_i^Tx_i)))
\end{align}
\]</span> 可以知道，在输入<span
class="math inline">\(x\)</span>（样本集样本）不变情况下，我们需要改变<span
class="math inline">\(w\)</span>的取值使得<span
class="math inline">\(l(w_i)\)</span>达到我们要求的最大，所以又回到训练最佳回归系数的问题。</p>
<h2 id="梯度上升算法">梯度上升算法</h2>
<hr />
<p>  梯度上升算法是计算极值的一个有效方法，因为我们需要计算最大似然估计函数<span
class="math inline">\(l(w_i)\)</span>的最大值，所以我们采用沿着<span
class="math inline">\(l(w_i)\)</span>的梯度上升方向迭代，直到达到某个停止条件或设定的迭代次数，然后影响<span
class="math inline">\(l(w_i)\)</span>取值的<span
class="math inline">\(w_i\)</span>即是我们要求的最佳回归系数。下面先介绍梯度的概念。</p>
<p>  梯度是一个立体概念，通俗点讲就好比有一些层峦叠嶂的山，而你要从山脚走到山顶，常规的走法就是你会先选择往比当前位置海拔更高一点的方向走，最后一直走到山顶结束，这就是梯度上升（当然还有梯度下降）。现在可以在脑海中构造梯度的图形，因为<span
class="math inline">\(w_i\)</span>取值的迭代变化，所以会产生很多大小不同的<span
class="math inline">\(l(w_i)\)</span>，把这些<span
class="math inline">\(l(w_i)\)</span>看成在立体坐标系中一系列点，把这些点连接起来之后就会生成一个梯度图像，这时候找到最大的<span
class="math inline">\(l(w_i)\)</span>取值就和上山是一个问题。</p>
<p>  梯度上升算法到达每个点后都会重新估计移动的方向，并沿新的梯度方向移动，这样循环移动直到满足停止条件。</p>
<center>
<img src="/2017/05/04/Logistic%E5%9B%9E%E5%BD%92/tidu.png" class="" title="梯度概念">
</center >
<p>  梯度上升算法的迭代公式为 <span class="math display">\[
w:=w+\alpha \nabla_wf(w)
\]</span> 公式中<span
class="math inline">\(w\)</span>即最佳回归系数，<span
class="math inline">\(\alpha\)</span>表示为上升算法中的移动步长即移动量的大小。在数学中，函数<span
class="math inline">\(f(x,y)\)</span>的梯度表示为 <span
class="math display">\[
\nabla f(x, y) =
\begin{pmatrix}
     \frac {\partial f(x, y)}{\partial x} \\
     \frac {\partial f(x, y)}{\partial y}
\end{pmatrix}
\]</span> 即沿<span class="math inline">\(x\)</span>的方向移动<span
class="math inline">\(\frac {\partial f(x, y)}{\partial
x}\)</span>，沿<span class="math inline">\(y\)</span>的方向移动<span
class="math inline">\(\frac {\partial f(x, y)}{\partial
y}\)</span>。所以梯度上升算法的迭代公式推导为 <span
class="math display">\[
w:=w+\alpha \frac {\partial f(w)}{\partial w}
\]</span> 在Logistic回归中，<span
class="math inline">\(f(w)\)</span>函数为上面的最大似然估计函数<span
class="math inline">\(l(w_i)\)</span> <span class="math display">\[
l(w_i) =
\sum_{i=1}^n(y_ilog(\sigma(w_i^Tx_i))+(1-y_i)log(1-\sigma(w_i^Tx_i)))
\]</span> 所以公式推导为 <span class="math display">\[
\begin{align}
\frac {\partial f(w_i)}{\partial w_i}
&amp;=\frac {\partial}{\partial w_i} l(w_i)\\
&amp;=\sum_{i=1}^n(y_i \frac1{\sigma(w_i^Tx_i)}\frac {\partial}{\partial
w_i}\sigma(w_i^Tx_i)-(1-y_i)\frac 1{1-\sigma(w_i^Tx_i)} \frac
\partial{\partial w_i}\sigma(w_i^Tx_i)) \\
&amp;=\sum_{i=1}^n(y_i \frac1{\sigma(w_i^Tx_i)}-(1-y_i)\frac
1{1-\sigma(w_i^Tx_i)})\frac \partial{\partial w_i}\sigma(w_i^Tx_i) \\
&amp;=\sum_{i=1}^n(y_i \frac1{\sigma(w_i^Tx_i)}-(1-y_i)\frac
1{1-\sigma(w_i^Tx_i)}) \sigma(w_i^Tx_i)(1-\sigma(w_i^Tx_i))\frac
\partial{\partial w_i} w_i^Tx_i\\
&amp;=\sum_{i=1}^n(y_i(1-\sigma(w_i^Tx_i))-(1-y_i)\sigma(w_i^Tx_i))x_i
\\
&amp;=\sum_{i=1}^n(y_i-\sigma(w_i^Tx_i))x_i
\end{align}
\]</span> 即将输入值<span
class="math inline">\(x_i\)</span>看作常量的情况下对<span
class="math inline">\(w_i\)</span>求偏导。所以算法迭代公式更新为 <span
class="math display">\[
\begin{align}
w: &amp;=w+\alpha \frac {\partial f(w)}{\partial w} \\
&amp;=w + \alpha \sum_{i=1}^n(y_i-\sigma(w_i^Tx_i))x_i
\end{align}
\]</span></p>
<h2 id="梯度上升算法的实现">梯度上升算法的实现</h2>
<hr />
<h3 id="python">Python</h3>
<p>  算法实现中会使用到矩阵运算，所以先导入<code>NumPy</code>函数库</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br></pre></td></tr></table></figure>
<p>  首先我们需要构造一个样本集数据的列表和一个和样本集样本对应的分类列表
<span class="math display">\[
dataSet =
\begin{pmatrix}
1 &amp; 2 &amp; 3 \\
\cdots &amp; \cdots &amp; \cdots \\
1 &amp; 4 &amp; 1 \\
\end{pmatrix},
dataLabel = \begin{pmatrix}
1,\cdots,0
\end{pmatrix}
\]</span> 为了方便计算，并且构造的数据符合预测函数<span
class="math inline">\(\sigma(w^Tx)\)</span>需要的输入要求，所以样本集中开始的特征值始终为1，即<span
class="math inline">\(w_0=1\)</span>。</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line">dataSet = array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], ...,[<span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>]])</span><br><span class="line">dataLabel = [<span class="number">1</span>, ..., <span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>  接下来我们做算法训练求最佳回归系数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 将样本集数据dataSet转换为NumPy中的矩阵格式</span></span><br><span class="line">dataMat = mat(dataSet)</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
dataMat =
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
\cdots &amp; \cdots &amp; \cdots \\
1 &amp; 4 &amp; 1 \\
\end{bmatrix}
\]</span></p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 样本集矩阵的规格</span></span><br><span class="line">m, n = shape(dataMat)</span><br><span class="line"><span class="comment"># 设置在梯度迭代中的移动步长，即每次迭代的移动距离</span></span><br><span class="line">alpha = <span class="number">0.001</span></span><br><span class="line"><span class="comment"># 设置最大迭代次数</span></span><br><span class="line">maxCycles = <span class="number">500</span></span><br><span class="line"><span class="comment"># 创建一个初始的回归系数，默认为1，回归系数的尺寸和样本集中样本的特征数量相同</span></span><br><span class="line">weights = ones((n, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>
<p><span class="math display">\[
weights=\begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}
\]</span></p>
<p>  接下来我们实现梯度上升的迭代求出最佳回归系数</p>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(maxCycles):</span><br><span class="line">    h = <span class="number">1.0</span>/(<span class="number">1</span>+exp(-dataMat*weights))</span><br><span class="line">    weights = weights + alpha * (mat(dataLabel).transpose() - h) * dataMat.transpose()</span><br></pre></td></tr></table></figure>
<p>其中<code>1.0/(1+exp(-dataMat*weights))</code>是迭代过程中，使用迭代当前的回归系数和样本特征值输入到预测函数<span
class="math inline">\(\frac1{1+e^{-w^Tx}}\)</span>做结果预测，且<span
class="math inline">\(w^Tx=w_0 + w_1x_1 + w_2x_2 + \cdots +
w_ix_i\)</span>，计算<span
class="math inline">\(w^Tx\)</span>使用矩阵计算很容易实现，过程如下
<span class="math display">\[
\begin{align}
dataMat \times weights
&amp;=
\begin{bmatrix}
1 &amp; 2 &amp; 3 \\
\cdots &amp; \cdots &amp; \cdots \\
1 &amp; 4 &amp; 1 \\
\end{bmatrix}
\times
\begin{bmatrix}
1 \\
1 \\
1
\end{bmatrix}
\\
&amp;=
\begin{bmatrix}
1\times1+2\times1+3\times1 \\
\cdots  \\
1\times1+4\times1+1\times1 \\
\end{bmatrix}
\\
\end{align}
\]</span>
其中<code>weights + alpha * (mat(dataLabel).transpose() - h) * dataMat.transpose()</code>则完全是根据梯度迭代公式计算
<span class="math display">\[
w: = w + \alpha (y_i-\sigma(w_i^Tx_i))x_i^T
\]</span>
迭代完成之后<code>weights</code>的值即为我们所求的最佳回归系数。</p>
<h2 id="算法收敛">算法收敛</h2>
<hr />
<p>  收敛是判断一个优化算法好坏的方法，就是说该算法的参数是否达到了稳定值。通俗的讲就是在做最优化算法的时候，算法要找到一个最优解需要一个过程，在Logistic回归算法计算最佳回归系数的时候，回归系数会由一个最差的回归系数慢慢变成一个最佳回归系数，并且由于一般情况下数据集中的样本并不是线性可分的，在算法训练过程中回归系数的值还会有数据的波动或高频波动产生，但是回归系数的值在迭代更新一定次数后会趋于一个稳定值，尽管还会有稍许数据波动产生也是可以接受范围，这个时候我们就说算法已经收敛，这个趋于稳定的值就是我们所说的最佳回归系数。</p>
<p>  在算法训练后观察优化算法收敛的状态可以让我们找到如何优化和完善算法的方向和评估算法的好坏。为了可以直观的看到算法收敛，我们需要在坐标系中，将<span
class="math inline">\(x\)</span>轴作为系数更新次数，<span
class="math inline">\(y\)</span>轴表示为某个特征系数的值，就会绘制出一条算法收敛示意图。</p>
<p>  知道了收敛是判断一个优化算法的好坏，因此我们在做优化和改善算法的时候，我们的目标就是使得优化算法可以更好的收敛，即我们需要使收敛速度更快和数据波动或高频波动更少。</p>
<p>  收敛速度的可控因素是算法训练中<span
class="math inline">\(\alpha\)</span>的值，即控制梯度上升中每次移动的步长。最好的方法是在梯度上升中使得回归系数的每次迭代更新中<span
class="math inline">\(\alpha\)</span>的值随着迭代次数的增加不断下降，即将梯度上升中的移动速度慢慢放缓。因为刚开始的迭代中系数的波动都比较大且不是我们需要计算的最佳回归系数状态，所以可以加快通过这个波动的速度。不过值得注意的是，需要保证<span
class="math inline">\(\alpha\)</span>的值永远不会减小到0，也就是需要保证在每次迭代更新后的新数据任然具有一定的影响。</p>
<h2 id="随机梯度上升算法">随机梯度上升算法</h2>
<hr />
<p>  梯度上升算法中，在更新回归系数的迭代过程中，因为矩阵相乘的关系每次迭代都会遍历整个数据集，如果定义训练数据集中有<span
class="math inline">\(m\)</span>个样本，一个数据样本中有<span
class="math inline">\(n\)</span>个特征，算法训练中被迭代了<span
class="math inline">\(t\)</span>次，那么梯度上升算法的运算量为 <span
class="math display">\[
c = n \times m \times t
\]</span>
如果样本集中样本数量非常大的时候，梯度上升算法的运算复杂度就会很高，并且直接影响算法训练的效率。</p>
<p>  基于上述原因，所以我们引入随机梯度上升算法，随机梯度上升算法是梯度上升算法的优化版本。随机梯度上升算法和梯度上升算法的不同在于梯度上升算法是每次迭代都将样本集中所有样本用于更新回归系数计算，而随机梯度上升算法是每次迭代都只使用样本集中的一条没有参与计算的新样本进行计算，是增量式的更新，这是一个<code>在线学习</code>的算法，而梯度上升算法是一个<code>批处理</code>的算法。正是随机梯度上升算法这个不同，大大降低了算法训练过程的计算复杂度和训练效率。</p>
<h2 id="随机梯度上升算法的实现">随机梯度上升算法的实现</h2>
<hr />
<h3 id="python-1">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 构造样本集，这里需使用NumPy数组</span></span><br><span class="line">dataSet = array([[<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>], ...,[<span class="number">1</span>, <span class="number">4</span>, <span class="number">1</span>]])</span><br><span class="line"><span class="comment"># 样本集对应的样本类别</span></span><br><span class="line">dataLabel = [<span class="number">1</span>, ..., <span class="number">0</span>]</span><br><span class="line"><span class="comment"># 样本集数据的规格</span></span><br><span class="line">m, n = shape(dataSet)</span><br><span class="line"><span class="comment"># 创建一个初始的回归系数，默认为1，回归系数的尺寸和样本集中样本的特征数量相同</span></span><br><span class="line">weights = ones((n, <span class="number">1</span>))</span><br><span class="line"><span class="comment"># 设置循环迭代的次数</span></span><br><span class="line">maxCycles = <span class="number">200</span></span><br><span class="line"><span class="keyword">for</span> k <span class="keyword">in</span> <span class="built_in">range</span>(maxCycles):</span><br><span class="line">    dataIndex = <span class="built_in">range</span>(m)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        <span class="comment"># 每次迭代的移动步进距离，逐渐减小且不可能等于0</span></span><br><span class="line">        alpha = <span class="number">4</span>/(<span class="number">1.0</span>+k+i)+<span class="number">0.01</span></span><br><span class="line">        randIndex = <span class="built_in">int</span>(random.uniform(<span class="number">0</span>, <span class="built_in">len</span>(dataIndex)))</span><br><span class="line">        <span class="comment"># 这里没有使用矩阵乘法，所有需要用sum函数计算sigmoid的输入值</span></span><br><span class="line">        h = <span class="number">1.0</span> / (<span class="number">1</span> + exp(-<span class="built_in">sum</span>(dataSet[randIndex]*weights)))</span><br><span class="line">        weights = weights + alpha * (classLabel[randIndex] - h) * dataSet[randIndex]</span><br><span class="line">        <span class="keyword">del</span>(dataIndex[randIndex])</span><br></pre></td></tr></table></figure>
<p>算法实现中<code>alpha = 4/(1.0+k+i)+0.01</code>可以根据实际样本集和训练情况做修改，<code>+0.01</code>为保证<code>alpha</code>不会等于0。在算法训练中采用增量更新，每次随机获取数据集中的一个样本输入并删除，保证不会重复输入相同的样本。</p>
<h2 id="决策边界">决策边界</h2>
<hr />
<p>  Logistic回归算法在二分类的分类预测中，因为算法的过程是对已知分类的样本集做拟合的过程，所以最终可以生成一条线叫做最佳拟合线，也叫决策边界，这条线将所有的样本内容一分为二，一部分属于分类1，则另一部分属于分类2。为了更直观的展示算法训练效果，那么如何确定和在坐标系中画出这条线呢？</p>
<p>  我们已经通过算法训练出了最佳回归系数，并且通过Sigmoid函数的曲线可以看出，预测函数的边界在0的位置，在坐标系中，横坐标0两边的部分分别表示两个不同的分类，所以设定边界函数为
<span class="math display">\[
0=w_0+w_1x_1 + w_2x_2 + \cdots + w_nx_n
\]</span> 由于<span class="math inline">\(x_0=0\)</span>，所以<span
class="math inline">\(0=w_0+w_1x_1+w_2x_2\)</span>，解出<span
class="math inline">\(x_2\)</span>和<span
class="math inline">\(x_1\)</span>的关系为 <span class="math display">\[
x_1 = \frac {-w_0-w_1 * x_2}{w_2}
\]</span> 在坐标系中，将一系列<span
class="math inline">\((x_1,x_2)\)</span>的点用线连接起来，这条线即算法在该样本集中的决策边界。</p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>回归</tag>
      </tags>
  </entry>
  <entry>
    <title>支持向量机 (SVM)</title>
    <url>/2017/05/09/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/</url>
    <content><![CDATA[<p>  支持向量机（SVM）号称最优秀的分类算法之一。SVM分类器可以得到低错误率的结果并能够对训练集之外的数据点作出很好的分类决策。</p>
<p>  如果了解过Logistic回归算法，那么对SVM算法的原理会很容易了解，其实他们是一个问题，都是去找一个决策边界函数将数据集中的所有样本分隔为两类（即二分类问题），然后计算该决策边界函数中参数的最优解。</p>
<span id="more"></span>
<center>
<img src="/2017/05/09/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/svm.png" class="" title="二分类问题分隔">
</center>
<p>  上面的示意图很好的展示了我们关注的二分类问题，图中所有的实心点和空心点共同构成了我们的数据集或称样本集，实心的点代表二分类中的一个分类，而空心点则代表了另一个分类，在Logistic回归中，两个分类用1和0的值来表示，那么上图中实心的点我们可以看作是属于1分类的点，空心的点则属于0分类的点。并且我们发现，我们可以找到一条直线将所有的实心点和空心点完全分隔到该条直线的上下两端，这样的数据集我们叫做<code>线性可分</code>数据。</p>
<p>  通过观察我们知道，有直线可以将上面属于两个分类的数据点完全区分开来，并且这样的直线还不止一条，可以看出直线<span
class="math inline">\(H_2\)</span>和<span
class="math inline">\(H_3\)</span>都可以对数据集做切分，并且这样的直线还可以找到很多条。但是这么多可以做分隔的直线中，哪条才是最好的数据集分隔直线？这就是SVM算法中我们需要考虑的问题。</p>
<p>  上图中直线<span
class="math inline">\(H_2\)</span>只是刚刚可以将数据集切分，但是如果离<span
class="math inline">\(H_2\)</span>最近的点往右移动一点距离<span
class="math inline">\(H_2\)</span>就不满足数据切分要求，但是直线<span
class="math inline">\(H_3\)</span>可以最大限度的将数据集切分为上下两个类别，我们暂且把<span
class="math inline">\(H_3\)</span>作为最好的数据集分隔线，该条线我们称作为<code>分隔超平面</code>，当前我们考虑的只是数据点在二维平面上，如果给定的数据点集是三维的，那么用来分隔数据的就是一个平面，如果更多维的时候呢？用来分隔数据集的分隔对象我们叫做<code>超平面</code>，也就是在分类问题中的分类决策边界。</p>
<p>  如果将<span
class="math inline">\(H_3\)</span>作为最好的超平面，和<span
class="math inline">\(H_2\)</span>比较可以看出，选取最好超平面的唯一要求就是离超平面最近的数据点到超平面的距离尽可能远，这里我们称这些离超平面最近的点为<code>支持向量</code>，点到超平面的距离为<code>间隔</code>，这样可以在我们训练数据有限的情况下使得分类器尽可能的健壮和有一定的容错能力。</p>
<p>  到这里，我们知道了SVM算法的目标，求给定数据集的最佳分隔线，且数据集离分割线最近的点到分隔线的间隔最大。</p>
<h2 id="算法原理">算法原理</h2>
<hr />
<p>  由于二维数据集是比较基础的数据样本集，并且也比较容易理解，所以我们由二维数据集的二分类判定来研究和阐述算法，最终的结果也同样适用于多维数据集。</p>
<p>  我们了解到SVM算法的算法目标就是找到一条将数据集分隔的最佳分隔超平面，分隔超平面的函数可以写成
<span class="math display">\[
w^Tx+b = 0
\]</span> 这里的函数和Logistic回归中带入到Sigmoid函数的变量一致，即
<span class="math display">\[
0=w_0+w_1x_1+w_2x_2 + \cdots + w_nx_n
\]</span> 在SVM的分隔超平面中，将<span
class="math inline">\(w_0\)</span>看作常量<span
class="math inline">\(b\)</span>，所以分隔超平面函数中的系数<span
class="math inline">\(w\)</span>和常量<span
class="math inline">\(b\)</span>就是构成最佳分割超平面函数的参数，也是SVM算法中需要训练得出的解。</p>
  我们现在知道了分隔超平面函数，那么找到距离分隔超平面距离最近的点A，根据最优化理论，使得点A到分隔超平面间隔最大，即该点到分隔面的法线或垂线的长度，表示为
<span class="math display">\[
d=\frac{|w^TA+b|}{\mid\mid w\mid\mid}
\]</span>
同样的，因为我们考虑的是二分类问题，所以在分隔超平面的一边找到点A，那么在超平面的另一边也存在点B，而且要分别使点A和点B距离分隔超平面的距离最大则该分隔超平面在点A和点B的中线位置，我们设点A距离分隔超平面的距离为1，则点B距离分隔超平面的距离也为1，将距离分隔超平面的距离为1的所有点用线连接起来会得到两条线，相当于将分隔超平面上下移动了1个单位距离，用函数表示这两条线为
<span class="math display">\[
w^TA_i+b=1\\
w^TB_i+b=-1
\]</span>
<center>
<img src="/2017/05/09/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/svm1.png" class="" title="二分类问题分隔">
</center>
<p>通过观察上图我们可以很容易理解上面我们关于最大距离的描述。并且我们发现，在SVM算法中表示两个分类的值和Logistic回归中不同，在Logistic回归中，使用1和0来表示两个不同的分类，而在SVM算法中，我们改用1和-1来表示，这样做的好处是可以更直观的描述距离问题和方便计算，这样数据集中的所有点都会满足一个条件我们叫约束条件
<span class="math display">\[
label (w^Tx+b) \ge 1
\]</span> <span
class="math inline">\(label\)</span>表示为数据点的标签1或-1。现在回来重新看看距离计算公式
<span class="math display">\[
d=\frac{|w^TA+b|}{\mid\mid w\mid\mid} = \frac{1}{\mid\mid w\mid\mid}
\]</span> 因为<span class="math inline">\(w\)</span>是一个向量，<span
class="math inline">\(||w||\)</span>表示为一个范数，即<span
class="math inline">\(w\)</span>向量的各个元素的平方和的开平方 <span
class="math display">\[
d=\frac{|w^TA+b|}{\mid\mid w\mid\mid} = \frac{1}{\sqrt {w^Tw}}
\]</span> 要求点到分隔超平面的距离<span
class="math inline">\(d\)</span>最大，就是求<span
class="math inline">\(w^Tw\)</span>的值最小，这样SVM算法的优化问题由
<span class="math display">\[
arg\quad max_{w,b}\left\lbrace min_n(label(w^Tx+b))\frac1{\mid\mid
w\mid\mid}\right \rbrace
\]</span> 转变为 <span class="math display">\[
min(\frac 12w^Tw) \\
s.t. \quad y(w^Tx+b) \ge 1
\]</span>
一个带约束条件的优化问题，这里我们乘以一个0.5的系数是为了方便后面的运算，当然前提并不会对算法结果有影响。求解上述问题，我们可以使用<code>拉格朗日乘子法</code>。</p>
<h2 id="拉格朗日乘子法">拉格朗日乘子法</h2>
<hr />
<p>  在数学中的最优化问题中，<code>拉格朗日乘数法</code>（以数学家约瑟夫·拉格朗日命名）是一种寻找多元函数在其变量受到一个或多个条件的约束时的极值的方法。这种方法可以将一个有<em>n</em>个变量与<em>k</em>个约束条件的最优化问题转换为一个解有<em>n</em>
+
<em>k</em>个变量的方程组的解的问题。这种方法中引入了一个或一组新的未知数，即<code>拉格朗日乘数</code>，又称<code>拉格朗日乘子</code>，或<code>拉氏乘子</code>，它们是在转换后的方程，即约束方程中作为梯度（gradient）的线性组合中各个向量的系数。</p>
  比如我们要求 <span class="math display">\[
max(f(x,y)) \\
s.t. \quad g(x,y) = c
\]</span> 对不同<span class="math inline">\(d_n\)</span>的值，不难想像出
<span class="math display">\[
f \left( x, y \right)=d_n
\]</span> 的等高线。而方程<span
class="math inline">\(g\)</span>的可行集所构成的线正好是 <span
class="math display">\[
g ( x, y ) = c
\]</span>
<center>
<img src="/2017/05/09/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/Lagrange_multiplier.png" class="" title="拉格朗日示意">
</center>
<p>  想像我们沿着<span class="math inline">\(g =
c\)</span>的可行集走；因为大部分情况下<span
class="math inline">\(f\)</span>的等高线和<span
class="math inline">\(g\)</span>的可行集线不会重合，但在有解的情况下，这两条线会相交。想像此时我们移动<span
class="math inline">\(g = c\)</span>上的点，因为<span
class="math inline">\(f\)</span>是连续的方程，我们因此能走到<span
class="math inline">\(f \left( x, y
\right)=d_n\)</span>更高或更低的等高线上，也就是说<span
class="math inline">\(d_n\)</span>可以变大或变小。只有当<span
class="math inline">\(g = c\)</span>和<span class="math inline">\(f
\left( x, y
\right)=d_n\)</span>相切，也就是说，此时，我们正同时沿着<span
class="math inline">\(g = c\)</span>和<span class="math inline">\(f
\left( x, y \right)=d_n\)</span>走，那么这个时候就会出现极值。</p>
<p>  对该优化问题求解我们引入新变量拉格朗日乘数<span
class="math inline">\(\alpha\)</span>，这是我们只需要下列拉格朗日函数的极值：
<span class="math display">\[
L(x,y,\alpha) = f(x,y) + \alpha (g(x,y)-c)
\]</span> 根据上述推断，当出现极值时<span
class="math inline">\(f\)</span>和<span
class="math inline">\(g\)</span>的切线在某点上平行，同时也意味着两者的梯度平行，那么有
<span class="math display">\[
\nabla \left[f(x,y) + \alpha(g(x,y)-c)\right] = 0 \\
s.t.\quad \alpha \neq 0
\]</span> 求出<span class="math inline">\(\alpha\)</span>的值后带入<span
class="math inline">\(g\)</span>和<span
class="math inline">\(f\)</span>中，转变为在无约束条件下的极值和对应极值点的求解，并且<span
class="math inline">\(L(x,y,\alpha)\)</span>在达到极值时与<span
class="math inline">\(f(x,y)\)</span>相等，因为<span
class="math inline">\(L(x,y,\alpha)\)</span>在达到极值时<span
class="math inline">\(g(x,y)-c\)</span>总等于0。</p>
<p>  具体例子中应用格朗拉日乘子法，求 <span class="math display">\[
f(x,y) = x^2y \\
s.t. \quad x^2+y^2=1
\]</span> 格朗拉日乘子法极值函数为 <span class="math display">\[
L(x,y,\alpha)=x^2y+\alpha(x^2+y^2-1)
\]</span> 分别对函数中变量求导 <span class="math display">\[
\frac {\partial L(x,y,\alpha)}{\partial x} \Rightarrow 2xy +2\alpha x=0
\\
\frac {\partial L(x,y,\alpha)}{\partial y} \Rightarrow x^2 +2\alpha y=0
\\
x^2+y^2-1=0
\]</span> 最小值就是上面方程组的解中的一个。</p>
<p>  解释了半天格朗拉日乘子法，那用格朗拉日乘子法怎么求解我们SVM算法中的优化问题
<span class="math display">\[
\frac 12min(w^Tw) \\
s.t. \quad y(w^Tx+b) \ge 1
\]</span>
然而没有我们想的那么顺利，格朗拉日乘子法并不适用我们的问题，因为格朗拉日乘子法中的约束条件时等式约束，我们的优化问题中约束条件时大于等于约束，没关系，我们使用另一个方法来求解我们的SVM算法中的优化问题，该方法是<code>KKT条件</code>，是一个广义化拉格朗日乘数，你可以理解成在拉格朗日乘数上拓展来的一个方法。</p>
<h2 id="kkt条件">KKT条件</h2>
<hr />
<p>  KKT条件全名<code>卡罗需-库恩-塔克条件</code>（Karush-Kuhn-Tucker
Conditions），是在满足一些有规则条件下，一个非线性规划问题能有最优解解法的一个必要和充分条件。这是一个广义化拉格朗日乘数的成果。</p>
<p>  KKT条件和拉格朗日乘数的概念相似，所以我们直接讲。求 <span
class="math display">\[
min\quad f(x)\\
s.t.\quad h(x) = 0\\
g(x) \le  0
\]</span> 函数<span
class="math inline">\(h\)</span>为等式约束条件，函数<span
class="math inline">\(g\)</span>为不等式约束。将优化问题转为KKT条件极值函数
<span class="math display">\[
L(x,\alpha,\beta) = f(x) + \sum_{i=1}^n\alpha_ig_i(x) +
\sum_{i=1}^n\beta_ih_i(x)
\]</span> 该KKT条件极值函数必须满足条件</p>
<ol type="1">
<li>L对各个x求导的结果为0</li>
<li><span class="math inline">\(\beta_i \neq 0\)</span></li>
<li><span class="math inline">\(\alpha_i \ge 0\)</span></li>
<li><span class="math inline">\(\alpha_ig_i(x) = 0\)</span></li>
<li><span class="math inline">\(g_i(x) \le 0\)</span></li>
<li><span class="math inline">\(h_i(x) = 0\)</span></li>
</ol>
<p>条件1和2在拉格朗日乘数中有解释，条件5和6为为优化问题的约束条件。满足条件3是因为我们要求<span
class="math inline">\(f(x)\)</span>的最小值，那么KKT条件极值函数中的三项都越小越好，因为等式约束已经最小为0，不等式约束条件<span
class="math inline">\(g_i(x)\le0\)</span>，那么根据最小要求只有<span
class="math inline">\(\alpha_i \ge0\)</span>时<span
class="math inline">\(\alpha_ig_i(x)\)</span>才会最小。满足条件4是因为不等式条件约束在坐标系中的图形为一个扇面，当我们取值刚好在扇面的起点部分时<span
class="math inline">\(g_i(x)=0\)</span>，该不等式参与约束，那么该不等式约束条件的系数<span
class="math inline">\(\alpha_i\ge0\)</span>，否则在其他点要么就是不满足不等式约束条件，要么就是不等式约束条件不参与约束，当不等式约束条件不参与约束时我们认为<span
class="math inline">\(\alpha_i=0\)</span>，即任何时候<span
class="math inline">\(\alpha_ig_i(x) =
0\)</span>。现在通过KKT条件理论，我们的优化目标成为 <span
class="math display">\[
L(x,\alpha,\beta) = f(x) + \sum_{i=1}^n\alpha_ig_i(x) +
\sum_{i=1}^n\beta_ih_i(x)\\
s.t. \quad \sum_{i=1}^n\alpha_i g_i(x)=0\\
\alpha_i \ge0
\]</span> 现在看起来应该和我们SVM算法中的优化问题 <span
class="math display">\[
\frac 12 min(w^Tw) \\
s.t. \quad y(w^Tx+b) \ge 1
\]</span> 类似了，可以直接引入KKT条件，SVM算法中的优化问题成为 <span
class="math display">\[
\begin{align}
L(w,b,\alpha) &amp;= \frac 12
w^Tw+\alpha_1g_1(x)+\cdots+\alpha_ng_n(x)\\
&amp;=\frac
12w^Tw+\alpha_1(1-y_i(w^Tx_i+b))+\cdots+\alpha_n(1-y_n(w^Tx_n+b))\\
&amp;=\frac
12w^Tw-\alpha_1(y_i(w^Tx_i+b)-1)-\cdots-\alpha_n(y_n(w^Tx_n+b)-1)\\
&amp;=\frac
12w^Tw-\sum_{i=1}^n\alpha_iy_i(w^Tx_i+b)+\sum_{i=1}^n\alpha_i\\
\end{align}
\]</span> 然后对目标函数<span
class="math inline">\(L(w,b,\alpha)\)</span>求导 <span
class="math display">\[
\frac {\partial L}{\partial w}=w-\sum_{i=1}^n\alpha_iy_ix_i=0\Rightarrow
w=\sum_{i=i}^n\alpha_iy_ix_i\\
\frac{\partial L}{\partial b}=-\sum_{i=1}^n\alpha_iy_i=0\Rightarrow
\sum_{i=1}^n\alpha_iy_i=0
\]</span> 然后带回函数<span
class="math inline">\(L(w,b,\alpha)\)</span>中 <span
class="math display">\[
\begin{align}
w(\alpha) &amp;= L(w,b,\alpha)\\
&amp;=\frac 12
(\sum_{i=i}^n\alpha_iy_ix_i)^T(\sum_{j=1}^n\alpha_jy_jx_j)-\sum_{i=1}^n\alpha_iy_i((\sum_{i=i}^n\alpha_iy_ix_i)^Tx_i+b)+\sum_{i=1}^n\alpha_i\\
&amp;=\frac 12
\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j-(\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j)+b\sum_{i=1}^n\alpha_iy_i+\sum_{i=1}^n\alpha_i\\
&amp;=-\frac12(\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j)+\sum_{i=1}^n\alpha_i\\
\end{align}
\]</span> 最后我们SVM算法的优化目标函数被推导为 <span
class="math display">\[
max_\alpha\left[\sum_{i=1}^m\alpha-\frac12\sum_{i,j=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j\right]\\
s.t.\quad \alpha\ge0\\
\sum_{i=1}^n\alpha_iy_i=0
\]</span>
  得到了最终的优化目标函数，我们就可以开始算法实现了？理想很丰满，现实很骨感啊，事实上在平时我们接触到的数据集中很难可以找到完全线性可分的数据集，甚至有些点会越过分隔超平面错误的分类到错误的类别，这些不常规的点我们叫做离群点或噪声点，所以我们上面所做的一切工作会因为这些噪声点而失效。</p>
<p>  为了在算法中避免一些噪声点的干扰导致算法结果的出错，所以我们引入一个<code>松弛变量</code>的概念，每个数据点的松弛变量被解释为允许该数据点在一定距离上的移动，就是给了所有数据点一定的容错机会，并且这个小的移动距离不会影响我们的类别判定，被认为是可接受范围。加入松弛变量后，意味着我们放弃了对这些点的精确分类，但是这种分类损失可以使超平面不必向这些点的方向移动而得到更大的几何间隔。SVM算法的约束条件就会更新，那么新的算法优化问题为
<span class="math display">\[
min \quad \frac 12w^Tw+C\sum_{i=1}^n\epsilon _i\\
s.t. \quad y_i(w^Tx_i+b) \ge 1-\epsilon_i\\
\epsilon \ge 0
\]</span> 函数中的<span
class="math inline">\(C\)</span>被称作<code>惩罚因子</code>，惩罚因子决定了我们对噪声点带来的损失有多重视，如果惩罚因子的值越大，噪声点对算法结果的影响越严重，因为这样表明我们不愿意放弃这些离群点。所以惩罚因子的出现只是让不可分的数据集变成可分的数据集而已。那么我们重新根据KKT条件推断优化目标函数
<span class="math display">\[
\begin{align}
L(w,b,\alpha,\beta,\epsilon)
&amp;=\frac 12w^Tw+C\sum_{i=1}^n\epsilon
_i+\alpha_1g^1_1(x)+\cdots+\alpha_ng^1_n(x)+\beta_1g^2_1(x)+\cdots+\beta_ng^2_n(x)\\
&amp;=\frac 12w^Tw+C\sum_{i=1}^n\epsilon
_i+\sum_{i=1}^n\alpha_ig_i^1(x)+\sum_{i=1}^n\beta_ig_i^2(x)\\
&amp;=\frac 12w^Tw+C\sum_{i=1}^n\epsilon
_i+\sum_{i=1}^n\alpha_i(1-\epsilon_i-y_i(w^Tx_i+b))+\sum_{i=1}^n\beta_i(-\epsilon_i)\\
&amp;=\frac 12w^Tw+C\sum_{i=1}^n\epsilon
_i-\sum_{i=1}^n\alpha_i(\epsilon_i+y_i(w^Tx_i+b)-1)-\sum_{i=1}^n\beta_i\epsilon_i\\
&amp;=\frac
12w^Tw+C\sum_{i=1}^n\epsilon_i-\sum_{i=1}^n\alpha_iy_i(w^Tx_i+b)+\sum_{i=1}^n\alpha_i-\sum_{i=1}^n\beta_i\epsilon_i\\
\end{align}
\]</span> 然后对<span
class="math inline">\(w,b,\epsilon\)</span>分别求导 <span
class="math display">\[
\frac {\partial L}{\partial
w}=2w-\sum_{i=1}^n\alpha_iy_ix_i=0\Rightarrow
w=\sum_{i=i}^n\alpha_iy_ix_i\\
\frac{\partial L}{\partial b}=-\sum_{i=1}^n\alpha_iy_i=0\Rightarrow
\sum_{i=1}^n\alpha_iy_i=0\\
\frac{\partial L}{\partial \epsilon}=0\Rightarrow C-\alpha_i-\beta_i=0
\]</span> 通过上面的求导结果我可以观察到惩罚因子<span
class="math inline">\(C\)</span>的条件 <span class="math display">\[
0\le \alpha_i \le C
\]</span> 将上面求导的结果带入目标函数中 <span class="math display">\[
\begin{align}
w(\alpha)
&amp;=L(w,b,\alpha,\beta,\epsilon)\\
&amp;=\frac
12w^Tw-\sum_{i=1}^n\alpha_iy_i(w^Tx_i+b)+C\sum_{i=1}^n\epsilon_i+\sum_{i=1}^n\alpha_i-\sum_{i=1}^n\beta_i\epsilon_i\\
&amp;=(\sum_{i=i}^n\alpha_iy_ix_i)^T(\sum_{j=1}^n\alpha_jy_jx_j)-\sum_{i=1}^n\alpha_iy_i((\sum_{i=i}^n\alpha_iy_ix_i)^Tx_i+b)+C\sum_{i=1}^n\epsilon_i+\sum_{i=1}^n\alpha_i-\sum_{i=1}^n\beta_i\epsilon_i\\
&amp;=\frac12(\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j)-\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j+C\sum_{i=1}^n\epsilon_i+\sum_{i=1}^n\alpha_i-\sum_{i=1}^n\epsilon_i(C-\alpha_i)\\
&amp;=-\frac12(\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j)+\sum_{i=1}^n\alpha_i\\
\end{align}
\]</span>
发现溜达了一圈回来SVM算法中优化目标函数和没加惩罚因子时一摸一样，只是条件更新了
<span class="math display">\[
max_\alpha\left[\sum_{i=1}^m\alpha-\frac12\sum_{i,j=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j\right]\\
s.t.\quad C\ge\alpha\ge0\\
\sum_{i=1}^n\alpha_iy_i=0
\]</span></p>
<h2 id="smo算法">SMO算法</h2>
<hr />
<p>  从上面对KKT条件的推导中，我们最后得出了最终的带约束条件的优化目标函数，现在的问题就剩下解这个目标函数得到一组<span
class="math inline">\(\alpha\)</span>的值使得目标函数的取值最大。SMO算法是很好的一个计算KKT条件目标函数的方法。</p>
<p>  SMO算法的实现原理是首先对所有的<span
class="math inline">\(\alpha\)</span>取默认值，然后迭代去更新这些<span
class="math inline">\(\alpha\)</span>，SMO算法是一个逐渐被优化和逐渐完善到最优解的算法过程。我们知道在SVM算法的最终目标是找到一个超平面从数据类别的维度来最好的去分隔我们提供的数据集，SMO算法在逐渐优化的过程在SVM算法表现为分隔超平面从最差一直优化到一个最佳的分隔超平面。我们知道数据集中的一个数据点会对应一个<span
class="math inline">\(\alpha\)</span>的值，在SMO算法优化的某一次迭代更新中，我们假设SVM算法找到了一个分隔超平面，当然不是最佳分隔超平面，那么使用该分隔超平面分隔数据会有一部分数据点是被分到了正确的分类下面，还有一部分点是被分在了错误的分类下面或者是不能很好的做出分类判定的数据点，那么这些该次迭代就是针对这些点做点对应<span
class="math inline">\(\alpha\)</span>值的更新，因为我们会有很多的<span
class="math inline">\(\alpha\)</span>值需要更新，而往往是每更新一个<span
class="math inline">\(\alpha\)</span>则分隔超平面都会发生变化，分隔超平面的变化会使其他所有的<span
class="math inline">\(\alpha\)</span>产生变化，那么多的点我们需要怎么更新呢？SMO算法采取的策略就是选择当前迭代中被当前生成的分隔超平面分类错误数据点中的一个<span
class="math inline">\(\alpha\)</span>，因为修改这个错误数据点的<span
class="math inline">\(\alpha\)</span>值会使得其他所有的<span
class="math inline">\(\alpha\)</span>变化且我们一次兼顾不了那么多的<span
class="math inline">\(\alpha\)</span>，所以SMO算法会在剩下的数据点中在选择一个数据点的<span
class="math inline">\(\alpha\)</span>进行同步更新，虽然对这两个点的更新不会是最好的更新或者说因为考虑其他<span
class="math inline">\(\alpha\)</span>的影响所以对这两个点的更新不是最后的优化更新，但是我们可以知道这是一个慢慢变好的过程，因为至少每次都会有一个被当前迭代中生成的分隔超平面分隔错误的点被更新到正确的点，当然如果我们选取的第二个数据点刚好也是分类错误的点，那么我们就一次纠正了两个错误的数据点。这样在迭代中每次选择一个被当前迭代生成的分隔超平面分类错误的点进行更新，迭代直到找不到被分类错误的点为止，既然我们找不到任何一个被分类错误的点并且所有的数据点都满足KKT条件的目标函数和所有约束条件，那么我们就找到了那个最佳的超平面。</p>
<p>  知道了SMO算法对实现KKT条件求解的策略，我们需要讨论的就是在SMO算法实现中每个小过程的解释和推导。首先我们回顾一下最终的SVM算法目标函数和约束条件
<span class="math display">\[
max_\alpha\left[\sum_{i=1}^m\alpha-\frac12\sum_{i,j=1}^ny_iy_j\alpha_i\alpha_jx_i^Tx_j\right]\\
s.t.\quad C\ge\alpha\ge0\\
\sum_{i=1}^n\alpha_iy_i=0
\]</span>
我们在所有的数据集中找到一个数据点，然后判定该数据点是否被正确的分类。我们知道数据点如果处在正确的分类位置，那么必须满足条件
<span class="math display">\[
f(w,b)=y_i(w^Tx_i+b) \ge1
\]</span>
这也是SVM算法中对所有数据点的约束条件，在KKT条件中加入系数<span
class="math inline">\(\alpha\)</span>后 <span class="math display">\[
a_i(1-y_i(w^Tx_i+b)) = 0\\
s.t.\quad \alpha_i \ge 0\\
1-y_i(w^T+b) \le 0
\]</span> 所以在两个约束条件<span class="math inline">\(\alpha_i \ge
0\)</span>和<span class="math inline">\(1-y_i(w^T+b) \le
0\)</span>中至少有一个为0，我们在KKT条件的阐述中表明当<span
class="math inline">\(\alpha_i\)</span>为0的时候，则表明该数据点是边界上的点或者是被正确分类的点。在坐标系中，分别在距离分隔超平面长度为1的位置两个分类的边界则数据集中所有的数据点必须满足下面的任意条件
<span class="math display">\[
a_i=0 \Rightarrow y_if(w,b) \ge1\quad(正确分类)\\
0\le\alpha_i \le C \Rightarrow y_if(w,b) = 1\quad(在边界上)\\
a_i=C \Rightarrow y_if(w,b) \le 1\quad(在边界之间)
\]</span> 当一个数据点满足上面一个条件时表示该数据点不需要做<span
class="math inline">\(\alpha\)</span>调整，相反需要做调整的数据点需要满足下面任意条件
<span class="math display">\[
y_if(w,b)\le1\quad但是\quad\alpha_i \lt C\\
y_if(w,b)\ge1\quad但是\quad\alpha_i \gt 0\\
y_if(w,b)\le1\quad但是\quad\alpha_i=0 或 \alpha_i=C
\]</span>
找到需要调整的数据点之后，根据SMO算法的求解策略，我们还需要在剩下的所有数据点中找到一个数据点作为和需要调整的数据点的同步更新那个点。</p>
<p>  现在我们找到需要调整的数据点A和剩余那部分点中的数据点B，数据点A对应<span
class="math inline">\(\alpha_A\)</span>，数据点B对应<span
class="math inline">\(\alpha_B\)</span>。还记得SVM算法的最终目标函数的约束条件么
<span class="math display">\[
\sum_{i=1}^n\alpha_iy_i=0
\]</span> 在只修改<span class="math inline">\(\alpha_A\)</span>和<span
class="math inline">\(\alpha_B\)</span>且其他<span
class="math inline">\(\alpha\)</span>不变的情况下有等式 <span
class="math display">\[
\alpha_A^{new}y_A+\alpha_B^{new}y_B=\alpha_A^{old}y_A+\alpha_B^{old}y_B=K
\]</span> 其中<span
class="math inline">\(K\)</span>只是一个常数值，因为SVM算法的分类值为1和-1中取值，所以上面式子有
<span class="math display">\[
y_A=y_B\quad \alpha_A^{new}+\alpha_B^{new} =
\alpha_A^{old}+\alpha_B^{old}\\
y_A\neq y_B\quad \alpha_A^{new}-\alpha_B^{new} =
\alpha_A^{old}-\alpha_B^{old}\\
s.t.\quad 0\le\alpha\le C
\]</span> 通过分析可以获取<span
class="math inline">\(\alpha_B^{new}\)</span>的区间为 <span
class="math display">\[
y_A= y_B\quad
L=max(0,\alpha_B^{old}+\alpha_A^{old}-C)，H=min(C,\alpha_2^{old}+\alpha_1^{old})\\
y_A\neq y_B\quad
L=max(0,\alpha_B^{old}-\alpha_A^{old})，H=min(C,C+\alpha_2^{old}-\alpha_1^{old})
\]</span>   现在我们知道了<span
class="math inline">\(\alpha_B^{new}\)</span>的区间，但是我们最终是要计算<span
class="math inline">\(\alpha_B^{new}\)</span>的值。还记得KKT条件的目标函数
<span class="math display">\[
w(\alpha)=\sum_{i=1}^n\alpha_i-\frac12(\sum_{i,j=1}^n\alpha_iy_i\alpha_jy_jx_i^Tx_j)
\]</span> 因为我们这里只用到数据点A和数据点B对应的<span
class="math inline">\(\alpha\)</span>，所以将函数分解并带入上面<span
class="math inline">\(\alpha_A\)</span>和<span
class="math inline">\(\alpha_B\)</span>的关系求导可以得到<span
class="math inline">\(\alpha_B^{new}\)</span> <span
class="math display">\[
\alpha_B^{new} = \alpha_B^{old}-\frac{y_B(E_A-E_B)}{\eta}\\
E_i=f(w,b)-y_i\\
\eta=2x_A^Tx_B-x_A^Tx_A-x_B^Tx_B
\]</span> 然后对求出来的<span
class="math inline">\(\alpha_B^{new}\)</span>值使用上面计算得到的范围确定具体的值，然后带入计算<span
class="math inline">\(\alpha_A^{new}\)</span>。</p>
<p>  SMO算法到这一步后，我们知道了新的<span
class="math inline">\(\alpha\)</span>，然后可以通过之前的推导出来的<span
class="math inline">\(w\)</span>计算公式 <span class="math display">\[
w=\sum_{i=1}^n\alpha_iy_ix_i
\]</span></p>
<p>计算出相对应<span
class="math inline">\(w\)</span>的值。回顾分类预测函数 <span
class="math display">\[
f(w,b)=w^Tx+b
\]</span> 发现我们还需要一个<span
class="math inline">\(b\)</span>的值，在回顾一下距离公式 <span
class="math display">\[
y(w^Tx+b)\ge1
\]</span> 并且当前更新后的<span
class="math inline">\(\alpha\)</span>的值对应的数据点因为分割平面的变化成为边界点，所以有
<span class="math display">\[
y_A(w_{new}^Tx_A+b_A^{new})=1\\
y_B(w_{new}^Tx_B+b_B^{new})=1
\]</span> 对方程求解后有 <span class="math display">\[
b_A^{new}=b^{old}-E_A-y_A(\alpha_A^{new}-\alpha_A^{old})x_A^Tx_A-y_B(\alpha_B^{new}-\alpha_B^{old})x_A^Tx_B\\
b_B^{new}=b^{old}-E_B-y_A(\alpha_A^{new}-\alpha_A^{old})x_A^Tx_B-y_B(\alpha_B^{new}-\alpha_B^{old})x_B^Tx_B
\]</span> 结果中两个<span
class="math inline">\(b\)</span>的选择依据是更新<span
class="math inline">\(\alpha\)</span>后的数据点哪个在边界上就是哪个<span
class="math inline">\(b\)</span> <span class="math display">\[
b= \begin{cases}
b_A, &amp; {if \quad 0\le \alpha_A^{new}\le C} \\
b_B, &amp; {if \quad 0\le \alpha_B^{new}\le C}\\
(b_A+b_B)/2 &amp;others
\end{cases}
\]</span>   到这里我们得到了<span
class="math inline">\(\alpha、b\)</span>的值，针对简单线性并且带有松弛条件的SMO算法就完成了。</p>
<h2 id="启发方法">启发方法</h2>
<hr />
<p>  这里引入启发式思想去讨论算法实现中的一些细节。</p>
<p>  为了使算法在选择<span
class="math inline">\(\alpha\)</span>的时候可以更快的选择出最合适的<span
class="math inline">\(\alpha\)</span>，所以我们在选择第一个<span
class="math inline">\(\alpha\)</span>时候用两种方式，一种就是在所有数据集上进行单遍扫描，另一种就是在非边界点对应的<span
class="math inline">\(\alpha\)</span>中实现单遍扫描，我们知道非边界的<span
class="math inline">\(\alpha\)</span>值代表那些不等于边界0或<span
class="math inline">\(C\)</span>的<span
class="math inline">\(\alpha\)</span>值，并且第二种方式我们需要跳过那些已知不会改变的<span
class="math inline">\(\alpha\)</span>的值。</p>
<p>  算法实现中，每次循环中使用哪种方式选择第一个<span
class="math inline">\(\alpha\)</span>的值去迭代更新取决于上一次循环的迭代中有没有<span
class="math inline">\(\alpha\)</span>的值被更新，如果上一次循环中没有<span
class="math inline">\(\alpha\)</span>的值被迭代更新，说明没有数据点处于边界中，但是并不表示我们找到的分隔超平面就是最佳分隔超平面，因为我们不知道上一次循环中取第一个<span
class="math inline">\(\alpha\)</span>的方式是哪种，如果是第一种，那么有可能当前的分隔超平面面就是最佳分隔超平面，但是如果是第二种则更不能确定该超平面就是我们要求的最佳超平面，所以本次循环还需要在数据集上进行单遍扫描去迭代更新<span
class="math inline">\(\alpha\)</span>的值；如果上一次循环中有<span
class="math inline">\(\alpha\)</span>的值被迭代更新，那么本次循环则优先调整上次迭代中处于数据集两个边界中的所有点对应的<span
class="math inline">\(\alpha\)</span>值，即<span
class="math inline">\(\alpha\)</span>在0和<span
class="math inline">\(C\)</span>区间内的数据点。这样我们就不知道什么时候我们选取到的分隔超平面就是最佳分隔超平面，所以我们会指定算法循环的次数，如果循环到一定次数就会停止算法训练，这样做的好处是如果算法在训练中不收敛或者有波动，可以避免算法一直不停的训练下去生成死循环问题。</p>
<p>  我们选取到第一个待更新的<span
class="math inline">\(\alpha\)</span>的值后，如果该点不满足KKT条件，那么我们选择第二个待更新的<span
class="math inline">\(\alpha\)</span>。第二个<span
class="math inline">\(\alpha\)</span>选取的方式也有两种方式，第一种方式就是在数据集中随机取一个<span
class="math inline">\(\alpha\)</span>，另一种方式就是通过计算所有<span
class="math inline">\(\alpha\)</span>对应数据点分类预测结果和真实结果误差，然后选去一个误差最大的，就是噪声最大的噪声点进行更新，即选择具有最大步长的第二个点，这样做的好处就是可以使算法更快的收敛。那么选取第二个待更新数据点的<span
class="math inline">\(\alpha\)</span>的值用哪种方式，这就取决于当前算法训练处于那个阶段，也就是说在当前迭代中有没有在数据边界内的噪声点，如果有那么就使用第二种方式，否则选择第一种方式。</p>
<h2 id="非线性分类应用核函数">非线性分类应用：核函数</h2>
<hr />
<p>  在SVM算法的实际应用中，我们很难找到一个可以完全线性可分的算法训练数据集，往往我们接触到的数据集都是非线性可分的，但是非线性可分的数据集也存在一个可以识别的分隔模式，所以我们要做的就是使用一种工具来捕获这种模式使得数据集支持SVM的算法。下面我们介绍叫做<code>核函数</code>的一种工具。</p>
<p>  核函数处理数据是对数据进行某种形式的转换来获取一些新的变量来表示数据，使数据更容易展示与之对应的类别，所以使用核函数来处理数据也是将数据从一个特征空间转换到另一个特征空间的的过程，经过转换后的的数据就可以在高维空间中解决线性问题，相当于我们在低维空间中解决非线性问题。</p>
<p>  在SVM算法中所有的运算都是两个向量相乘之后得到耽搁标量或数值的内积形式，在非线性数据集中，我们可以将内积德运算替换成核函数方式，这种方式被称作<code>核技巧</code>。</p>
<h2 id="径向基核函数">径向基核函数</h2>
<hr />
<p>  径向基函数是SVM算法中常被用到的一个核函数。径向基函数采用向量作为自变量函数，并且能够基于向量距离运算输出一个标量。径向基函数的高斯版本的公式为
<span class="math display">\[
k(x,y)=exp\left(\frac{-\mid\mid x-y\mid\mid^2}{2\sigma^2}\right)
\]</span> 其中<span
class="math inline">\(\sigma\)</span>是用户定义的用户确定到达率或者说函数值跌落到0的速度。</p>
<p>  径向基函数将数据从其特征空间映射到更高维的空间，并且我们不需要具体知道具体的维数，因为SVM算法的内积运算结果和核函数的结果都是一个表示距离的值。但是运用核函数的算法还是可控的，因为还有一个自定义的变量<span
class="math inline">\(\sigma\)</span>。在SVM算法实现中运用核函数的做法就是将算法中运用到内积运算的部分替换为核函数就完成了SVM算法训练数据集的转换。</p>
<h2 id="算法实现">算法实现</h2>
<hr />
<h3 id="python">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="keyword">from</span> time <span class="keyword">import</span> sleep</span><br><span class="line"></span><br><span class="line"><span class="comment"># 核函数实现</span></span><br><span class="line"><span class="comment"># X：所有样本集数据</span></span><br><span class="line"><span class="comment"># A：将要被处理的一个样本数据</span></span><br><span class="line"><span class="comment"># kTup：径向基函数用到的参数，格式为（核函数类型，sigma）</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">kernelTrans</span>(<span class="params">X, A, kTup</span>): </span><br><span class="line">    <span class="comment"># 样本集矩阵规格</span></span><br><span class="line">    m,n = shape(X)</span><br><span class="line">    <span class="comment"># 将样本数据处理后的初始化数据</span></span><br><span class="line">    K = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 根据核函数类型确定转换方式</span></span><br><span class="line">    <span class="keyword">if</span> kTup[<span class="number">0</span>]==<span class="string">&#x27;lin&#x27;</span>: </span><br><span class="line">        K = X * A.T</span><br><span class="line">    <span class="keyword">elif</span> kTup[<span class="number">0</span>]==<span class="string">&#x27;rbf&#x27;</span>:</span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">            deltaRow = X[j,:] - A</span><br><span class="line">            K[j] = deltaRow*deltaRow.T</span><br><span class="line">        K = exp(K/(-<span class="number">1</span>*kTup[<span class="number">1</span>]**<span class="number">2</span>))</span><br><span class="line">    <span class="keyword">else</span>: <span class="keyword">raise</span> NameError(<span class="string">&#x27;Houston We Have a Problem -- That Kernel is not recognized&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> K</span><br><span class="line"><span class="comment"># 一个算法参数的集合结构，包括算法中用到的参数内容</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">optStruct</span>:</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,dataMatIn, classLabels, C, toler, kTup</span>):</span><br><span class="line">        <span class="comment"># 数据集矩阵</span></span><br><span class="line">        self.X = dataMatIn</span><br><span class="line">        <span class="comment"># 数据集中与数据对应的真实分类</span></span><br><span class="line">        self.labelMat = classLabels</span><br><span class="line">        <span class="comment"># 常数C，算法目标函数中约束条件中有出现</span></span><br><span class="line">        self.C = C</span><br><span class="line">        <span class="comment"># 理解为机器误差</span></span><br><span class="line">        self.tol = toler</span><br><span class="line">        <span class="comment"># 数据集的尺寸，即有多少样本在数据集中</span></span><br><span class="line">        self.m = shape(dataMatIn)[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># alpha列表，smo算法最终输出的内容，一个样本对应一个alpha，初始值为0</span></span><br><span class="line">        self.alphas = mat(zeros((self.m,<span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># 预测函数中出现的参数b</span></span><br><span class="line">        self.b = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 一个缓存数据的属性</span></span><br><span class="line">        self.eCache = mat(zeros((self.m,<span class="number">2</span>)))</span><br><span class="line">        <span class="comment"># 经过核函数转换过的样本集矩阵，将样本维度大小转为样本集尺寸大小相等</span></span><br><span class="line">        self.K = mat(zeros((self.m,self.m)))</span><br><span class="line">        <span class="comment"># 数据通过核函数处理填充上面的K矩阵</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(self.m):</span><br><span class="line">            <span class="comment"># 将数据调用核函数</span></span><br><span class="line">            self.K[:,i] = kernelTrans(self.X, self.X[i,:], kTup)</span><br><span class="line"><span class="comment"># 使用随机方法选择第二个alpha</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectJrand</span>(<span class="params">i,m</span>):</span><br><span class="line">    j=i</span><br><span class="line">    <span class="keyword">while</span> (j==i):</span><br><span class="line">        j = <span class="built_in">int</span>(random.uniform(<span class="number">0</span>,m))</span><br><span class="line">    <span class="keyword">return</span> j</span><br><span class="line"><span class="comment"># 实现查找第二个alpha的值</span></span><br><span class="line"><span class="comment"># i：第一个alpha的矩阵索引</span></span><br><span class="line"><span class="comment"># oS：算法数据结构实体</span></span><br><span class="line"><span class="comment"># Ei：第一个alpha的预测误差</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">selectJ</span>(<span class="params">i, oS, Ei</span>):</span><br><span class="line">    <span class="comment"># 步长最大的alpha矩阵索引</span></span><br><span class="line">    maxK = -<span class="number">1</span></span><br><span class="line">    <span class="comment"># 临时误差差距</span></span><br><span class="line">    maxDeltaE = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 第二个alpha的预测误差</span></span><br><span class="line">    Ej = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 更新第一个alpha的误差值到缓存列表</span></span><br><span class="line">    oS.eCache[i] = [<span class="number">1</span>,Ei]</span><br><span class="line">    <span class="comment"># 获取缓存列表中所有不为0的误差值的索引</span></span><br><span class="line">    validEcacheList = nonzero(oS.eCache[:,<span class="number">0</span>].A)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 如果所有数据点中有跟实际值有误差的点，大于0的原因是排除第一个点的影响</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="built_in">len</span>(validEcacheList)) &gt; <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 循环有误差的所有点列表</span></span><br><span class="line">        <span class="keyword">for</span> k <span class="keyword">in</span> validEcacheList:</span><br><span class="line">            <span class="comment"># 第二个点确定不能和第一个点是同一个点</span></span><br><span class="line">            <span class="keyword">if</span> k == i: </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算当前循环到的点的新误差</span></span><br><span class="line">            Ek = calcEk(oS, k)</span><br><span class="line">            <span class="comment"># 计算步长</span></span><br><span class="line">            deltaE = <span class="built_in">abs</span>(Ei - Ek)</span><br><span class="line">            <span class="comment"># 如果当前点的步长大，则选定该点</span></span><br><span class="line">            <span class="keyword">if</span> (deltaE &gt; maxDeltaE):</span><br><span class="line">                maxK = k</span><br><span class="line">                maxDeltaE = deltaE</span><br><span class="line">                Ej = Ek</span><br><span class="line">        <span class="keyword">return</span> maxK, Ej</span><br><span class="line">    <span class="comment"># 如果不存在有误差的值则使用随机方法获取第二个alpha的值</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        j = selectJrand(i, oS.m)</span><br><span class="line">        Ej = calcEk(oS, j)</span><br><span class="line">    <span class="keyword">return</span> j, Ej</span><br><span class="line"><span class="comment"># 设置新alpha的值</span></span><br><span class="line"><span class="comment"># aj：新的值</span></span><br><span class="line"><span class="comment"># H：上限</span></span><br><span class="line"><span class="comment"># L：下限</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">clipAlpha</span>(<span class="params">aj,H,L</span>):</span><br><span class="line">    <span class="keyword">if</span> aj &gt; H: </span><br><span class="line">        aj = H</span><br><span class="line">    <span class="keyword">if</span> L &gt; aj:</span><br><span class="line">        aj = L</span><br><span class="line">    <span class="keyword">return</span> aj</span><br><span class="line"><span class="comment"># 计算误差的实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">calcEk</span>(<span class="params">oS, k</span>):</span><br><span class="line">    <span class="comment"># 根据预测函数公式，计算处于索引k处的预测结果</span></span><br><span class="line">    <span class="comment"># 核函数推导：oS.K[:,k] = dataMatrix*dataMatrix[i,:].T)</span></span><br><span class="line">    fXk = <span class="built_in">float</span>(multiply(oS.alphas,oS.labelMat).T*oS.K[:,k] + oS.b)</span><br><span class="line">    <span class="comment"># 计算预测结果误差</span></span><br><span class="line">    Ek = fXk - <span class="built_in">float</span>(oS.labelMat[k])</span><br><span class="line">    <span class="keyword">return</span> Ek</span><br><span class="line"><span class="comment"># 更新缓存</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">updateEk</span>(<span class="params">oS, k</span>):</span><br><span class="line">    <span class="comment"># 使用最新的alpha值更新预测误差并更新缓存</span></span><br><span class="line">    Ek = calcEk(oS, k)</span><br><span class="line">    oS.eCache[k] = [<span class="number">1</span>,Ek]</span><br><span class="line"><span class="comment"># 进行选定alpha更新</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">innerL</span>(<span class="params">i, oS</span>):</span><br><span class="line">    <span class="comment"># 计算第一个alpha的误差</span></span><br><span class="line">    Ei = calcEk(oS, i)</span><br><span class="line">    <span class="comment"># 判断选取的alpha是否满足KKT条件</span></span><br><span class="line">    <span class="keyword">if</span> ((oS.labelMat[i]*Ei &lt; -oS.tol) <span class="keyword">and</span> (oS.alphas[i] &lt; oS.C)) <span class="keyword">or</span> ((oS.labelMat[i]*Ei &gt; oS.tol) <span class="keyword">and</span> (oS.alphas[i] &gt; <span class="number">0</span>)):</span><br><span class="line">        <span class="comment"># 选取第二个alpha的值</span></span><br><span class="line">        j,Ej = selectJ(i, oS, Ei)</span><br><span class="line">        <span class="comment"># 复制两个旧的alpha值，供后面计算</span></span><br><span class="line">        alphaIold = oS.alphas[i].copy()</span><br><span class="line">        alphaJold = oS.alphas[j].copy()</span><br><span class="line">        <span class="comment"># 根据alpha区间公式限定alpha的值</span></span><br><span class="line">        <span class="keyword">if</span> (oS.labelMat[i] != oS.labelMat[j]):</span><br><span class="line">            L = <span class="built_in">max</span>(<span class="number">0</span>, oS.alphas[j] - oS.alphas[i])</span><br><span class="line">            H = <span class="built_in">min</span>(oS.C, oS.C + oS.alphas[j] - oS.alphas[i])</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            L = <span class="built_in">max</span>(<span class="number">0</span>, oS.alphas[j] + oS.alphas[i] - oS.C)</span><br><span class="line">            H = <span class="built_in">min</span>(oS.C, oS.alphas[j] + oS.alphas[i])</span><br><span class="line">        <span class="keyword">if</span> L==H: </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 计算公式推导中的eta参数，用来计算新的alpha</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[i,j] = dataMatrix[i,:]*dataMatrix[j,:].T</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[i,i] = dataMatrix[i,:]*dataMatrix[i,:].T</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[j,j] = dataMatrix[j,:]*dataMatrix[j,:].T</span></span><br><span class="line">        eta = <span class="number">2.0</span> * oS.K[i,j] - oS.K[i,i] - oS.K[j,j]</span><br><span class="line">        <span class="keyword">if</span> eta &gt;= <span class="number">0</span>: </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 通过公式计算新的alpha值</span></span><br><span class="line">        oS.alphas[j] -= oS.labelMat[j]*(Ei - Ej)/eta</span><br><span class="line">        <span class="comment"># 限定新alpha值的范围</span></span><br><span class="line">        oS.alphas[j] = clipAlpha(oS.alphas[j],H,L)</span><br><span class="line">        <span class="comment"># 通过新的alpha值更新预测误差</span></span><br><span class="line">        updateEk(oS, j)</span><br><span class="line">        <span class="keyword">if</span> (<span class="built_in">abs</span>(oS.alphas[j] - alphaJold) &lt; <span class="number">0.00001</span>): </span><br><span class="line">            <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line">        <span class="comment"># 根据其中一个alpha的值，带入公式更新另一个alpha的值</span></span><br><span class="line">        oS.alphas[i] += oS.labelMat[j]*oS.labelMat[i]*(alphaJold - oS.alphas[j])</span><br><span class="line">        <span class="comment"># 更新另一个alpha值的缓存</span></span><br><span class="line">        updateEk(oS, i)</span><br><span class="line">        <span class="comment"># 计算两个alpha值的b</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[i,j] = dataMatrix[i,:]*dataMatrix[j,:].T</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[i,i] = dataMatrix[i,:]*dataMatrix[i,:].T</span></span><br><span class="line">        <span class="comment"># 核函数推导：oS.K[j,j] = dataMatrix[j,:]*dataMatrix[j,:].T</span></span><br><span class="line">        b1 = oS.b - Ei- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,i] - oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[i,j]</span><br><span class="line">        b2 = oS.b - Ej- oS.labelMat[i]*(oS.alphas[i]-alphaIold)*oS.K[i,j]- oS.labelMat[j]*(oS.alphas[j]-alphaJold)*oS.K[j,j]</span><br><span class="line">        <span class="comment"># 根据参数b的选取条件确定算法中b的值</span></span><br><span class="line">        <span class="keyword">if</span> (<span class="number">0</span> &lt; oS.alphas[i]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[i]): </span><br><span class="line">            oS.b = b1</span><br><span class="line">        <span class="keyword">elif</span> (<span class="number">0</span> &lt; oS.alphas[j]) <span class="keyword">and</span> (oS.C &gt; oS.alphas[j]): </span><br><span class="line">            oS.b = b2</span><br><span class="line">        <span class="keyword">else</span>: </span><br><span class="line">            oS.b = (b1 + b2)/<span class="number">2.0</span></span><br><span class="line">        <span class="keyword">return</span> <span class="number">1</span></span><br><span class="line">    <span class="keyword">else</span>: </span><br><span class="line">        <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"><span class="comment"># smo算法的实现函数</span></span><br><span class="line"><span class="comment"># dataMatIn：数据集特征列表</span></span><br><span class="line"><span class="comment"># classLabels：数据集对应分类列表</span></span><br><span class="line"><span class="comment"># C：算法推导中出现的常数C，也是最终目标函数中约束条件中出现的参数C</span></span><br><span class="line"><span class="comment"># toler：容错率，理解为允许的机器误差吧</span></span><br><span class="line"><span class="comment"># maxIter：最大循环次数</span></span><br><span class="line"><span class="comment"># kTup：核函数中使用到的值，0为径向基函数中的自定义变量sigma</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">smoP</span>(<span class="params">dataMatIn, classLabels, C, toler, maxIter,kTup=(<span class="params"><span class="string">&#x27;lin&#x27;</span>, <span class="number">0</span></span>)</span>):</span><br><span class="line">    <span class="comment"># 初始化一个跟算法相关的参数（数据）结构实体</span></span><br><span class="line">    oS = optStruct(mat(dataMatIn),mat(classLabels).transpose(),C,toler, kTup)</span><br><span class="line">    <span class="comment"># 记录当前循环次数</span></span><br><span class="line">    <span class="built_in">iter</span> = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 选择第一个alpha用那种方式</span></span><br><span class="line">    entireSet = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 是否有alpha的值被更新</span></span><br><span class="line">    alphaPairsChanged = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 同时满足两种情况会继续循环迭代，</span></span><br><span class="line">    <span class="comment"># 1、循环次数不能超过设置的最大循环次数</span></span><br><span class="line">    <span class="comment"># 2、alphaPairsChanged大于0或者entireSet为真</span></span><br><span class="line">    <span class="keyword">while</span> (<span class="built_in">iter</span> &lt; maxIter) <span class="keyword">and</span> ((alphaPairsChanged &gt; <span class="number">0</span>) <span class="keyword">or</span> (entireSet)):</span><br><span class="line">        <span class="comment"># 将alpha的是否被更新初始化为否</span></span><br><span class="line">        alphaPairsChanged = <span class="number">0</span></span><br><span class="line">        <span class="comment"># 如果entireSet值为真，采用所有数据集遍历的方式找到第一个alpha的值</span></span><br><span class="line">        <span class="keyword">if</span> entireSet:</span><br><span class="line">            <span class="comment"># 遍历所有数据集</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(oS.m):</span><br><span class="line">                <span class="comment"># 完成alpha值的更新</span></span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="comment"># 寻找数据集在边界上的所有数据点，使用乘法可以剔除那些分类正确的点</span></span><br><span class="line">            <span class="comment"># 该函数返回一个不为0的数据列表，列表项为之前列表项的索引值</span></span><br><span class="line">            nonBoundIs = nonzero((oS.alphas.A &gt; <span class="number">0</span>) * (oS.alphas.A &lt; C))[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 遍历边界内的点</span></span><br><span class="line">            <span class="keyword">for</span> i <span class="keyword">in</span> nonBoundIs:</span><br><span class="line">                <span class="comment"># 完成alpha值的更新</span></span><br><span class="line">                alphaPairsChanged += innerL(i,oS)</span><br><span class="line">        <span class="comment"># 递增循环次数</span></span><br><span class="line">        <span class="built_in">iter</span> += <span class="number">1</span></span><br><span class="line">        <span class="comment"># 如果当前循环中取第一个alpha的方式是全样本集遍历，那么设置下次循环为边界内数据点遍历</span></span><br><span class="line">        <span class="keyword">if</span> entireSet: </span><br><span class="line">            entireSet = <span class="literal">False</span></span><br><span class="line">        <span class="comment"># 如果当前循环中取第一个alpha的方式是边界内数据点遍历并且没有更新到alpha，那么设置下次为全样本集遍历</span></span><br><span class="line">        <span class="keyword">elif</span> (alphaPairsChanged == <span class="number">0</span>): </span><br><span class="line">            entireSet = <span class="literal">True</span></span><br><span class="line">    <span class="comment"># 最终计算出b的值和alpha列表</span></span><br><span class="line">    <span class="keyword">return</span> oS.b,oS.alphas</span><br><span class="line"><span class="comment"># 测试算法函数，k1:径向基函数中的自定义变量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">testRbf</span>(<span class="params">k1=<span class="number">1.3</span></span>):</span><br><span class="line">    <span class="comment"># 从文件中加载训练样本集，dataArr：样本数据集的特征数据，labelArr：数据集中数据对应真实类别</span></span><br><span class="line">    dataArr,labelArr = loadDataSet(<span class="string">&#x27;testSetRBF.txt&#x27;</span>)</span><br><span class="line">    <span class="comment"># 调用smo算法函数计算参数b和alphas的值</span></span><br><span class="line">    b,alphas = smoP(dataArr, labelArr, <span class="number">200</span>, <span class="number">0.0001</span>, <span class="number">10000</span>, (<span class="string">&#x27;rbf&#x27;</span>, k1))</span><br><span class="line">    <span class="comment">### 算法测试部分 ###</span></span><br><span class="line">    datMat=mat(dataArr)</span><br><span class="line">    labelMat = mat(labelArr).transpose()</span><br><span class="line">    <span class="comment"># 所有支持向量的矩阵索引</span></span><br><span class="line">    svInd=nonzero(alphas.A&gt;<span class="number">0</span>)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 所有支持向量的样本数据</span></span><br><span class="line">    sVs=datMat[svInd]</span><br><span class="line">    <span class="comment"># 所有支持向量的类别数据</span></span><br><span class="line">    labelSV = labelMat[svInd];</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;there are %d Support Vectors&quot;</span> % shape(sVs)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 样本集矩阵规格</span></span><br><span class="line">    m,n = shape(datMat)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">&#x27;rbf&#x27;</span>, k1))</span><br><span class="line">        <span class="comment"># 根据分类预测函数和w求解公式和核函数推导出的预测结果计算方法</span></span><br><span class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): </span><br><span class="line">            errorCount += <span class="number">1</span></span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;the training error rate is: %f&quot;</span> % (<span class="built_in">float</span>(errorCount)/m)</span><br><span class="line">    <span class="comment"># 测试新的样本数据</span></span><br><span class="line">    dataArr,labelArr = loadDataSet(<span class="string">&#x27;testSetRBF2.txt&#x27;</span>)</span><br><span class="line">    errorCount = <span class="number">0</span></span><br><span class="line">    datMat=mat(dataArr)</span><br><span class="line">    labelMat = mat(labelArr).transpose()</span><br><span class="line">    m,n = shape(datMat)</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">        kernelEval = kernelTrans(sVs,datMat[i,:],(<span class="string">&#x27;rbf&#x27;</span>, k1))</span><br><span class="line">        predict=kernelEval.T * multiply(labelSV,alphas[svInd]) + b</span><br><span class="line">        <span class="keyword">if</span> sign(predict)!=sign(labelArr[i]): </span><br><span class="line">            errorCount += <span class="number">1</span>    </span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;the test error rate is: %f&quot;</span> % (<span class="built_in">float</span>(errorCount)/m)</span><br></pre></td></tr></table></figure>
<p>上面算法中用到的公式有 <span class="math display">\[
分类预测函数\quad f(w,b)=w^Tx+b\\
w值求解公式\quad w=\sum_{i=i}^n\alpha_iy_ix_i\\
预测误差公式\quad E_i=f(w,b)-y_i\\
\alpha 区间判定\quad \begin{cases}y_A= y_B\quad
L=max(0,\alpha_B^{old}+\alpha_A^{old}-C)，H=min(C,\alpha_2^{old}+\alpha_1^{old})\\
y_A\neq y_B\quad
L=max(0,\alpha_B^{old}-\alpha_A^{old})，H=min(C,C+\alpha_2^{old}-\alpha_1^{old})\end{cases}\\
\eta 求解公式\quad \eta=2x_A^Tx_B-x_A^Tx_A-x_B^Tx_B\\
新\alpha计算公式\quad \alpha_B^{new} =
\alpha_B^{old}-\frac{y_B(E_A-E_B)}{\eta}\\
计算另一个\alpha公式推导\quad
\alpha_A^{new}y_A+\alpha_B^{new}y_B=\alpha_A^{old}y_A+\alpha_B^{old}y_B\\
两个新b值的取值\quad
\begin{cases}b_A^{new}=b^{old}-E_A-y_A(\alpha_A^{new}-\alpha_A^{old})x_A^Tx_A-y_B(\alpha_B^{new}-\alpha_B^{old})x_A^Tx_B\\
b_B^{new}=b^{old}-E_B-y_A(\alpha_A^{new}-\alpha_A^{old})x_A^Tx_B-y_B(\alpha_B^{new}-\alpha_B^{old})x_B^Tx_B\end{cases}\\
b值取值\quad b= \begin{cases}
b_A, &amp; {if \quad 0\le \alpha_A^{new}\le C} \\
b_B, &amp; {if \quad 0\le \alpha_B^{new}\le C}\\
(b_A+b_B)/2 &amp;others
\end{cases}
\]</span></p>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>支持向量机</tag>
        <tag>SVM</tag>
        <tag>拉格朗日乘子</tag>
        <tag>KKT条件</tag>
        <tag>SMO</tag>
        <tag>核函数</tag>
        <tag>径向基核函数</tag>
      </tags>
  </entry>
  <entry>
    <title>AdaBoost元算法</title>
    <url>/2017/05/15/AdaBoost%E5%85%83%E7%AE%97%E6%B3%95/</url>
    <content><![CDATA[<p>  在机器学习中，当我们处理分类判定问题中，如果我们使用一种算法对目标样本做出判断后虽然分类结果是算法根据给定的所有数据样本集做出的最优结果，但是往往我们会对结果感觉持一定的怀疑态度，即这个分类确定就是该目标样本的最终结果？</p>
<p>  带着上面的问题我们就要想怎么才能得出一个更令我们信服的结果是接下来要探讨的问题。</p>
<span id="more"></span>
<h2 id="元算法">元算法</h2>
<hr />
<p>  我们将各种算法的结果进行分组和整合，然后从中科学的选取一个结果作为我们的最终分类判定结果，这就是<code>元算法</code>。</p>
<p>  在元算法的实现中，我们可以使用不同的算法分类器组合起来得出组合结果，这种原算法的组合方式多种多样，可以是一种算法在不同参数调优下的实现，也可以是不同算法的组合实现，还可以是数据集不同部分分配给不同分类器的组合等等。</p>
<h2
id="bagging随机抽样数据的分类器构建">bagging：随机抽样数据的分类器构建</h2>
<hr />
<p>  <code>自举汇聚法</code>也叫做<code>bagging</code>方法，实现原理为从原始数据集中有放回的抽取S次后得到S个新的数据集，并且新数据集的大小和原始数据集的大小相等，因为是有放回随机抽取的缘故，所以在新数据集中可以有重复的样本和在原始数据集中存在的一些样本在新数据集中找不到。</p>
<p>  当我们获取到了S个样本集后，分别将一个机器学习算法作用域每个新的样本集进行类别判定，在分类结果中选取一个出现次数做多的类别作为最后的分类结果，该方法相当于由一个分类器投票结果。</p>
<h2 id="boosting">boosting</h2>
<hr />
<p>  boosting算法和bagging算法类似，不同的是boosting算法引入了一个分类器权重的概念，即在所有的算法分类器都会有一个结果权重，每个权重的定义都是在上次迭代中根据分类器分类错误的样本数据进行重新的分类器训练。boosting分类的结果是基于所有分类器的加权求和结果，每个权重代表的是其对应分类器在上一轮迭代中的成功率。</p>
<h2 id="adaboost">AdaBoost</h2>
<hr />
<p>  <code>AdaBoost</code>算法是由多个弱分类器构建一个强分类器。</p>
<p>  AdaBoost算法的实现原理是给所有训练样本数据赋予一个初始权重值，这些权重值构成一个向量D，并且使所有权重值相加结果为1，然后在训练数据上训练出一个弱分类器并计算该分类器的错误率
<span class="math display">\[
\epsilon = \frac {未正确分类的样本数}{所有样本数目}
\]</span> 使用该错误率计算该分类器的对决策结果的权重 <span
class="math display">\[
\alpha = \frac 12ln\left(\frac{1-\epsilon}{\epsilon}\right)
\]</span>
在下一次进行分类器训练前，对向量D更新，即更新每个数据样本的权重值，更新策略为如果这次该样本通过训练的分类器获得正确的分类，那么我们减小该样本的权重
<span class="math display">\[
D_i^{(t+1)} = \frac{D_i^te^{-\alpha}}{Sum(D)}
\]</span> 而如果该样本被分类器错分，那么我们增加该样本的权重 <span
class="math display">\[
D_i^{(t+1)} = \frac{D_i^te^{\alpha}}{Sum(D)}
\]</span>
这样一直迭代获取新的分类器并且保存每次迭代后获取的分类器和分类器信息直到算法训练的分类器错误率为0，这样我们就获得了一个分类器组。</p>
<p>  做目标样本分类判定的时候，由于我们已经有一个分类器组，所以分别将待求结果样本输入到所有分类器中，并通过该分类器的权重计算出最后的样本分类。</p>
<h2 id="算法实现">算法实现</h2>
<hr />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 构造一个简单的数据集做算法实现</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">loadSimpData</span>():</span><br><span class="line">    datMat = matrix([[ <span class="number">1.</span> ,  <span class="number">2.1</span>],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.1</span>],</span><br><span class="line">        [ <span class="number">1.3</span>,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">1.</span> ,  <span class="number">1.</span> ],</span><br><span class="line">        [ <span class="number">2.</span> ,  <span class="number">1.</span> ]])</span><br><span class="line">    classLabels = [<span class="number">1.0</span>, <span class="number">1.0</span>, -<span class="number">1.0</span>, -<span class="number">1.0</span>, <span class="number">1.0</span>]</span><br><span class="line">    <span class="keyword">return</span> datMat,classLabels</span><br><span class="line"><span class="comment"># 使用单层决策数来构造弱分类器</span></span><br><span class="line"><span class="comment"># 单层决策树是只使用样本数据的一个特征做决策树构建</span></span><br><span class="line"><span class="comment"># 因为是弱分类器，所以通过简单的特征值比大小方式确定样本分类</span></span><br><span class="line"><span class="comment"># 如果特征值符合给定的阈值和条件，那么确定该样本分类</span></span><br><span class="line"><span class="comment"># 分类为二分类问题，由1和-1表示</span></span><br><span class="line"><span class="comment"># 全面性考虑，所以条件判断分别判定大于和小于</span></span><br><span class="line"><span class="comment"># dataMatrix：输入样本数据集</span></span><br><span class="line"><span class="comment"># dimen：选取的特征</span></span><br><span class="line"><span class="comment"># threshVal：选定的阈值，集样本特征值和该值做比较</span></span><br><span class="line"><span class="comment"># threshIneq：比较条件</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">stumpClassify</span>(<span class="params">dataMatrix,dimen,threshVal,threshIneq</span>):</span><br><span class="line">    <span class="comment"># 样本数据集的预测类别</span></span><br><span class="line">    retArray = ones((shape(dataMatrix)[<span class="number">0</span>],<span class="number">1</span>))</span><br><span class="line">    <span class="comment"># 根据条件做预测判定</span></span><br><span class="line">    <span class="keyword">if</span> threshIneq == <span class="string">&#x27;lt&#x27;</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &lt;= threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        retArray[dataMatrix[:,dimen] &gt; threshVal] = -<span class="number">1.0</span></span><br><span class="line">    <span class="keyword">return</span> retArray</span><br><span class="line"><span class="comment"># 构建单层决策树</span></span><br><span class="line"><span class="comment"># 根据递归方式构建分类器，并用梯度的方式确定所有可能的阈值</span></span><br><span class="line"><span class="comment"># dataArr：样本数据集</span></span><br><span class="line"><span class="comment"># classLabels：样本真实类别</span></span><br><span class="line"><span class="comment"># D：样本的权重向量</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">buildStump</span>(<span class="params">dataArr,classLabels,D</span>):</span><br><span class="line">    dataMatrix = mat(dataArr)</span><br><span class="line">    labelMat = mat(classLabels).T</span><br><span class="line">    m,n = shape(dataMatrix)</span><br><span class="line">    <span class="comment"># 定义阈值范围</span></span><br><span class="line">    numSteps = <span class="number">10.0</span></span><br><span class="line">    <span class="comment"># 存储分类器信息的变量</span></span><br><span class="line">    bestStump = &#123;&#125;</span><br><span class="line">    <span class="comment"># 最佳分类器分类结果</span></span><br><span class="line">    bestClasEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 最小的错误率，初始化为无限大的错误率</span></span><br><span class="line">    minError = inf</span><br><span class="line">    <span class="comment"># 遍历所有样本特征，即选择没一个特征训练决策树，然后比较错误率</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(n):</span><br><span class="line">        <span class="comment"># 获取样本特征值的最小值</span></span><br><span class="line">        rangeMin = dataMatrix[:,i].<span class="built_in">min</span>()</span><br><span class="line">        <span class="comment"># 获取样本特征值的最大值</span></span><br><span class="line">        rangeMax = dataMatrix[:,i].<span class="built_in">max</span>()</span><br><span class="line">        <span class="comment"># 设置阈值选择的步长，即计算一个阈值做决策树</span></span><br><span class="line">        stepSize = (rangeMax-rangeMin)/numSteps</span><br><span class="line">        <span class="comment"># 循环确定阈值的值</span></span><br><span class="line">        <span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(-<span class="number">1</span>,<span class="built_in">int</span>(numSteps)+<span class="number">1</span>):</span><br><span class="line">            <span class="comment"># 确定所有的预测比较条件</span></span><br><span class="line">            <span class="keyword">for</span> inequal <span class="keyword">in</span> [<span class="string">&#x27;lt&#x27;</span>, <span class="string">&#x27;gt&#x27;</span>]: </span><br><span class="line">                <span class="comment"># 确定阈值，使用步长计算</span></span><br><span class="line">                threshVal = (rangeMin + <span class="built_in">float</span>(j) * stepSize)</span><br><span class="line">                <span class="comment"># 使用预测函数预测所有样本的预测结果</span></span><br><span class="line">                predictedVals = stumpClassify(dataMatrix,i,threshVal,inequal)</span><br><span class="line">                <span class="comment"># 使用分类器预测结果正确与否的矩阵列表，默认都正确表示为1</span></span><br><span class="line">                errArr = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">                <span class="comment"># 将所有预测结果和真实分类不同的修改为错误分类标记0</span></span><br><span class="line">                errArr[predictedVals == labelMat] = <span class="number">0</span></span><br><span class="line">                <span class="comment"># 使用矩阵计算，并通过样本权重计算分类器错误率</span></span><br><span class="line">                weightedError = D.T*errArr</span><br><span class="line">                <span class="comment"># 选择一个错误率最小的分类器即最佳弱分类器</span></span><br><span class="line">                <span class="keyword">if</span> weightedError &lt; minError:</span><br><span class="line">                    minError = weightedError</span><br><span class="line">                    bestClasEst = predictedVals.copy()</span><br><span class="line">                    <span class="comment"># 保存分类器信息</span></span><br><span class="line">                    bestStump[<span class="string">&#x27;dim&#x27;</span>] = i</span><br><span class="line">                    bestStump[<span class="string">&#x27;thresh&#x27;</span>] = threshVal</span><br><span class="line">                    bestStump[<span class="string">&#x27;ineq&#x27;</span>] = inequal</span><br><span class="line">    <span class="keyword">return</span> bestStump,minError,bestClasEst</span><br><span class="line"><span class="comment"># 实现AdaBoost算法</span></span><br><span class="line"><span class="comment"># dataArr：样本数据</span></span><br><span class="line"><span class="comment"># classLabels：样本集对应样本分类</span></span><br><span class="line"><span class="comment"># numIt：循环次数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adaBoostTrainDS</span>(<span class="params">dataArr,classLabels,numIt=<span class="number">40</span></span>):</span><br><span class="line">    <span class="comment"># 弱分类器组，此处为单层决策树组</span></span><br><span class="line">    weakClassArr = []</span><br><span class="line">    <span class="comment"># 样本集大小</span></span><br><span class="line">    m = shape(dataArr)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 默认的样本权重，所有权重和为1</span></span><br><span class="line">    D = mat(ones((m,<span class="number">1</span>))/m)</span><br><span class="line">    <span class="comment"># 类别估计值，即对样本集通过弱分类器的判定，最后的分类结果</span></span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numIt):</span><br><span class="line">        <span class="comment"># 获取一个弱分类器</span></span><br><span class="line">        <span class="comment"># bestStump：该分类器信息</span></span><br><span class="line">        <span class="comment"># error：错误率</span></span><br><span class="line">        <span class="comment"># classEst：分类预测结果</span></span><br><span class="line">        bestStump,error,classEst = buildStump(dataArr,classLabels,D)</span><br><span class="line">        <span class="comment"># 通过公式计算分类器权重alpha</span></span><br><span class="line">        alpha = <span class="built_in">float</span>(<span class="number">0.5</span>*log((<span class="number">1.0</span>-error)/<span class="built_in">max</span>(error,<span class="number">1e-16</span>)))</span><br><span class="line">        <span class="comment"># 将分类器权重添加到分类器信息对象</span></span><br><span class="line">        bestStump[<span class="string">&#x27;alpha&#x27;</span>] = alpha</span><br><span class="line">        <span class="comment"># 将该弱分类器添加到分类器组</span></span><br><span class="line">        weakClassArr.append(bestStump)</span><br><span class="line">        <span class="comment"># 通过公式计算新的样本权重</span></span><br><span class="line">        expon = multiply(-<span class="number">1</span>*alpha*mat(classLabels).T,classEst)</span><br><span class="line">        D = multiply(D,exp(expon)) </span><br><span class="line">        D = D/D.<span class="built_in">sum</span>()</span><br><span class="line">        <span class="comment"># 通过循环获取的弱分类器计算样本集的分类</span></span><br><span class="line">        aggClassEst += alpha*classEst</span><br><span class="line">        <span class="comment"># 分类错误与正确的列表</span></span><br><span class="line">        aggErrors = multiply(sign(aggClassEst) != mat(classLabels).T,ones((m,<span class="number">1</span>)))</span><br><span class="line">        <span class="comment"># 计算错误率</span></span><br><span class="line">        errorRate = aggErrors.<span class="built_in">sum</span>()/m</span><br><span class="line">        <span class="comment"># 如果错误率为0.则推出循环</span></span><br><span class="line">        <span class="keyword">if</span> errorRate == <span class="number">0.0</span>: </span><br><span class="line">            <span class="keyword">break</span></span><br><span class="line">    <span class="keyword">return</span> weakClassArr,aggClassEst</span><br><span class="line"><span class="comment"># 通过算法训练结果，进行分类预测</span></span><br><span class="line"><span class="comment"># datToClass：待预测的目标数据</span></span><br><span class="line"><span class="comment"># classifierArr：弱分类器组</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">adaClassify</span>(<span class="params">datToClass,classifierArr</span>):</span><br><span class="line">    dataMatrix = mat(datToClass)</span><br><span class="line">    m = shape(dataMatrix)[<span class="number">0</span>]</span><br><span class="line">    aggClassEst = mat(zeros((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 循环所有弱分类器，并使用分类器预测函数进行分类预测</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(classifierArr)):</span><br><span class="line">        <span class="comment"># 将分类器信息带入预测函数做分类预测</span></span><br><span class="line">        classEst = stumpClassify(dataMatrix,classifierArr[i][<span class="string">&#x27;dim&#x27;</span>], classifierArr[i][<span class="string">&#x27;thresh&#x27;</span>], classifierArr[i][<span class="string">&#x27;ineq&#x27;</span>])</span><br><span class="line">        <span class="comment"># 对分类结果和该分类器的权重值进行最终分类迭代判断</span></span><br><span class="line">        aggClassEst += classifierArr[i][<span class="string">&#x27;alpha&#x27;</span>]*classEst</span><br><span class="line">    <span class="comment"># 实现最终分类判定，如果大于0返回则分类为+1，否则为-1</span></span><br><span class="line">    <span class="keyword">return</span> sign(aggClassEst)</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>机器学习</tag>
        <tag>AdaBoost</tag>
        <tag>元算法</tag>
      </tags>
  </entry>
  <entry>
    <title>预测数值型数据：回归</title>
    <url>/2017/05/16/%E9%A2%84%E6%B5%8B%E6%95%B0%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%EF%BC%9A%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<p>  回归算法适用于好多算法环境，比如做分类预测的Logistic回归，下面我们介绍的所有内容都是进行数值型预测的回归算法。</p>
<p>  回归算法就是对给定数据样本集数据进行拟合，我们将拟合的过程叫做回归。回归算法的目的就是找到一组最佳回归系数，然后通过回归系数构建一个预测函数，通过输入待预测样本来求解预测结果。回归算法中常用的函数基本形式为
<span class="math display">\[
y=w_0+w_1x_1+w_2x_2+ \cdots +w_nx_n
\]</span> 预测函数中<span
class="math inline">\(w\)</span>的值就表示我们需要训练的回归系数，使用矩阵的方式，预测函数可以被表示为
<span class="math display">\[
y=w^Tx\\
s.t. \quad x_1=1
\]</span></p>
<span id="more"></span>
<h2 id="线性回归">线性回归</h2>
<hr />
<p>  在数值型预测的回归算法中，我们给定训练数据样本集，然后通过算法训练出使得预测函数的预测误差最小的最佳回归系数<span
class="math inline">\(w\)</span>，预测结果<span
class="math inline">\(y\)</span>和真实结果<span
class="math inline">\(y\)</span>之间的差值为我们评测回归系数好坏的唯一标准，我们采用平方误差计算样本集训练误差
<span class="math display">\[
\epsilon = \sum_{i=1}^n(y_i-x_i^Tw)^2
\]</span> 同样，使用矩阵的方式表示为 <span class="math display">\[
\epsilon = (y-x^Tw)^T(y-x^Tw)
\]</span> 我们要找到<span
class="math inline">\(\epsilon\)</span>的最小值，所以<span
class="math inline">\(\epsilon\)</span>对<span
class="math inline">\(w\)</span>求导且等于0可以得出<span
class="math inline">\(w\)</span>的最优解方程 <span
class="math display">\[
\hat w = (x^Tx)^{-1}x^Ty
\]</span> 由于方程中<span
class="math inline">\((x^Tx)^{-1}\)</span>是一个对矩阵求逆的计算，我们知道并不是所有的矩阵都可以求逆，所以在算法训练中需要确认是否可以对该矩阵求逆。</p>
<h2 id="算法实现">算法实现</h2>
<hr />
<h3 id="python">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 样本集数据</span></span><br><span class="line">xMat = mat([[...], []])</span><br><span class="line"><span class="comment"># 对应样本集数据的类别</span></span><br><span class="line">yMat = mat([[...], []])</span><br><span class="line"><span class="comment"># 根据系数求解方程计算回归系数</span></span><br><span class="line">xTx = xMat.T*xMat</span><br><span class="line"><span class="comment"># 检测矩阵是否可以求逆</span></span><br><span class="line"><span class="keyword">if</span> linalg.det(xTx) == <span class="number">0.0</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;This matrix is singular, cannot do inverse&quot;</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"><span class="comment"># 根据系数求解方程计算回归系数</span></span><br><span class="line">ws = xTx.I * (xMat.T*yMat)</span><br></pre></td></tr></table></figure>
<center>
<img src="/2017/05/16/%E9%A2%84%E6%B5%8B%E6%95%B0%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%EF%BC%9A%E5%9B%9E%E5%BD%92/QQ20170516-152457@2x.png" class="" title="线性回归结果">
</center>
<p>  观察上图中线性回归中的算法训练结果，虽然样本集经过拟合，已经完全可以做结果预测，但是直观感受上好像现在的回归算法结果有点“鲁莽”，就是不能取得一个很好的预测结果，这样的拟合情况我们称之为<code>欠拟合</code>，产生欠拟合是因为线性算法求的是具有最小均方误差的无偏估计，接下来我们研究一些可以更好拟合的回归算法。</p>
<h2 id="局部加权线性回归">局部加权线性回归</h2>
<hr />
<p>  由于没有考虑估计偏差线性回归会出现欠拟合现象，因此在局部加权线性回归算法我们引入一些偏差来降低预测中的均方误差。</p>
<p>  局部加权线性回归算法中，我们给待预测点附近的每个点赋予一定的权重<span
class="math inline">\(W\)</span>，然后将最小均方误差作用于待预测点附近的这些点。这样对于每个不一样的待预测点的回归系数都是不同的。添加样本集中点的权重<span
class="math inline">\(W\)</span>后，回归系数的计算公式更新为 <span
class="math display">\[
\hat w = (x^TWx)^{-1}x^TWy
\]</span>
公式中样本集点的权重值我们使用核给待预测点附近的所有点一个权重值，这里我们使用高斯核
<span class="math display">\[
W(i,j) = exp\left(\frac {\mid x_i-x\mid}{-2k^2}\right)
\]</span></p>
<p>高斯核构建了一个对角元素的权重矩阵<span
class="math inline">\(W\)</span>，并且样本集中点的<span
class="math inline">\(x\)</span>距离点<span
class="math inline">\(x_i\)</span>越近，该点的权重<span
class="math inline">\(W(i,i)\)</span>将会越大，并且高斯核引入一个指定参数<span
class="math inline">\(k\)</span>来决定对附近的点赋予多大的权重。</p>
<h2 id="算法实现-1">算法实现</h2>
<hr />
<h3 id="python-1">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 样本集数据矩阵</span></span><br><span class="line">xMat = mat([[...],[...]])</span><br><span class="line"><span class="comment"># 样本集数据对应的样本类别</span></span><br><span class="line">yMat = mat([[...],[...]])</span><br><span class="line"><span class="comment"># 待预测样本点</span></span><br><span class="line">testPoint = [...]</span><br><span class="line"><span class="comment"># 高斯核自定义参数</span></span><br><span class="line">k = <span class="number">0.01</span></span><br><span class="line"><span class="comment"># 样本集尺寸</span></span><br><span class="line">m = shape(xMat)[<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 初始化所有样本集数据点的权重对角线矩阵</span></span><br><span class="line">weights = mat(eye((m)))</span><br><span class="line"><span class="comment"># 使用循环对每个数据点赋予一个权重</span></span><br><span class="line"><span class="keyword">for</span> j <span class="keyword">in</span> <span class="built_in">range</span>(m):</span><br><span class="line">    <span class="comment"># 根据高斯核函数公式进行计算</span></span><br><span class="line">    diffMat = testPoint - xMat[j,:]</span><br><span class="line">    weights[j,j] = exp(diffMat*diffMat.T/(-<span class="number">2.0</span>*k**<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 根据回归系数计算公式计算回归系数</span></span><br><span class="line">xTx = xMat.T * (weights * xMat)</span><br><span class="line"><span class="comment"># 检测是否可以对矩阵求逆</span></span><br><span class="line"><span class="keyword">if</span> linalg.det(xTx) == <span class="number">0.0</span>:</span><br><span class="line">    <span class="built_in">print</span> <span class="string">&quot;This matrix is singular, cannot do inverse&quot;</span></span><br><span class="line">    <span class="keyword">return</span></span><br><span class="line"><span class="comment"># 根据回归系数计算公式计算回归系数</span></span><br><span class="line">ws = xTx.I * (xMat.T * (weights * yMat))</span><br><span class="line"><span class="comment"># 对待预测样本进行结果预测</span></span><br><span class="line">y = testPoint * ws</span><br></pre></td></tr></table></figure>
<center>
<img src="/2017/05/16/%E9%A2%84%E6%B5%8B%E6%95%B0%E5%80%BC%E5%9E%8B%E6%95%B0%E6%8D%AE%EF%BC%9A%E5%9B%9E%E5%BD%92/QQ20170516-161658@2x.png" class="" title="局部加权线性回归结果">
</center>
<p>  观察上图的算法训练结果可知，局部加权线性回归算法比线性回归算法的预测结果合理了很多并且解决了欠拟合的情况，但是由于自定义参数<span
class="math inline">\(k\)</span>的可变性，所以在实际算法中需要修改参数<span
class="math inline">\(k\)</span>的值进行多次训练找到一个最佳拟合曲线，同时由于<span
class="math inline">\(k\)</span>取值的不同，可能还会出现欠拟合和过拟合的情形，欠拟合在线性回归中讲过，过拟合产生的原因是算法考虑了太多的噪声点而导致的。</p>
<h2 id="岭回归">岭回归</h2>
<hr />
<p>  试想如果我们获取到的算法训练样本集中样本特征数量比我们样本集大小还大，那么我们在使用回归系数求解公式中的求逆运算<span
class="math inline">\((x^Tx)^{-1}\)</span>会出问题，因为输入数据的矩阵不是满秩矩阵，而非满秩矩阵在求逆时会出问题。<code>岭回归</code>就是解决这个问题的。</p>
<p>  岭回归就是在矩阵<span
class="math inline">\(x^Tx\)</span>上加一个<span
class="math inline">\(\lambda I\)</span>使矩阵非奇异，这样就可以对<span
class="math inline">\(x^Tx+\lambda I\)</span>顺利求逆。其中矩阵<span
class="math inline">\(I\)</span>是一个<span
class="math inline">\(m\times
m\)</span>的单位矩阵，并且除对角线元素全为1外其他元素都为0，所以回归公式被更新为
<span class="math display">\[
\hat w = (x^Tx+\lambda I)^{-1}x^Ty
\]</span> 其中参数<span
class="math inline">\(\lambda\)</span>为自定义参数，对于不同的<span
class="math inline">\(\lambda\)</span>算法的预测误差也是不同的。</p>
<h2 id="算法实现-2">算法实现</h2>
<hr />
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="comment"># 计算回归系数函数</span></span><br><span class="line"><span class="comment"># xMat：样本集</span></span><br><span class="line"><span class="comment"># yMat：样本集对应类别矩阵</span></span><br><span class="line"><span class="comment"># lam：岭回归中的自定义参数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ridgeRegres</span>(<span class="params">xMat,yMat,lam=<span class="number">0.2</span></span>):</span><br><span class="line">    <span class="comment"># 下面完全根据公式计算回归系数</span></span><br><span class="line">    xTx = xMat.T*xMat</span><br><span class="line">    denom = xTx + eye(shape(xMat)[<span class="number">1</span>])*lam</span><br><span class="line">    <span class="comment"># 避免lam参数为0使的不可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(denom) == <span class="number">0.0</span>:</span><br><span class="line">        <span class="built_in">print</span> <span class="string">&quot;This matrix is singular, cannot do inverse&quot;</span></span><br><span class="line">        <span class="keyword">return</span></span><br><span class="line">    ws = denom.I * (xMat.T*yMat)</span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"><span class="comment"># 岭回归测试函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">ridgeTest</span>(<span class="params">xArr,yArr</span>):</span><br><span class="line">    xMat = mat(xArr)</span><br><span class="line">    yMat=mat(yArr).T</span><br><span class="line">    <span class="comment"># 接下来的计算是为了实现样本集数据标准化</span></span><br><span class="line">    <span class="comment"># 计算平均值</span></span><br><span class="line">    yMean = mean(yMat,<span class="number">0</span>)</span><br><span class="line">    yMat = yMat - yMean</span><br><span class="line">    xMeans = mean(xMat,<span class="number">0</span>)</span><br><span class="line">    xVar = var(xMat,<span class="number">0</span>)</span><br><span class="line">    xMat = (xMat - xMeans)/xVar</span><br><span class="line">    <span class="comment"># 使用不同的lam测试次数</span></span><br><span class="line">    numTestPts = <span class="number">30</span></span><br><span class="line">    wMat = zeros((numTestPts,shape(xMat)[<span class="number">1</span>]))</span><br><span class="line">    <span class="comment"># 循环，带入不同的lam计算回归系数，为了更方便观察，lam以指数级变化</span></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(numTestPts):</span><br><span class="line">        ws = ridgeRegres(xMat,yMat,exp(i-<span class="number">10</span>))</span><br><span class="line">        wMat[i,:]=ws.T</span><br><span class="line">    <span class="keyword">return</span> wMat</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>回归</tag>
      </tags>
  </entry>
  <entry>
    <title>树回归</title>
    <url>/2017/05/17/%E6%A0%91%E5%9B%9E%E5%BD%92/</url>
    <content><![CDATA[<p>  在机器学习算法中，树的算法模型在分类判定和回归问题都可以使用，ID3算法就是一个构造决策树模型的分类判定算法，这里我们讨论决策树中的CART算法。ID3和CART不同在ID3算法是每次选取当前最佳的特征来做数据分隔，并且会按照该特征的所有特征值做数据集切分，在切分过程中，如果按照一个特征切分后，该特征在之后的算法切分中不会再起作用，所以ID3算法不能直接处理连续型数据的特征，在连续型特征的样本集中使用ID3算法，必须提前将样本集数据处理为离散型数据且这么做会破坏样本集数据的某种潜在规律。</p>
<p>  还有种切分数据的方式就是二元切分法，实现为每次将数据集切分为两部分，根据特征值的切分条件，所有数据分别切分为数据的左子树和右子树。</p>
<span id="more"></span>
<h2 id="回归树">回归树</h2>
<hr />
<p>  回归树的原理和ID3算法的构建相似，在树的叶子节点位置存储算法的结果。在回归树中，因为处理的是连续型样本集数据，所以在构建树后，叶子节点为一个单值。</p>
<p>  回归树的实现原理是：迭代使用数据集特征和特质值做数据切分，根据数据切分方式将数据切分为左子树和右子树，然后分别计算左子树和右子树的数据集误差，选择误差小的一个做为最佳切分特征和特征值并且保持切分过程信息，直到切分后的子树数据集中值相等或者是达到我们的停止条件，然后计算数据集的均值作为叶子节点，这样迭代完成后就构成一个可供使用的回归树。</p>
<h2 id="算法实现">算法实现</h2>
<hr />
<h3 id="python">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="comment"># 选择最佳分隔特征和特征值实现方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chooseBestSplit</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 最小子树误差，即迭代停止条件</span></span><br><span class="line">    tolS = <span class="number">1</span> </span><br><span class="line">    <span class="comment"># 最小子树大小，迭代停止条件</span></span><br><span class="line">    tolN = <span class="number">4</span></span><br><span class="line">    <span class="comment"># 如果给定样本集所有值相等，则表示到达叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">set</span>(dataSet[:,-<span class="number">1</span>].T.tolist()[<span class="number">0</span>])) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 返回分隔特征为空和当前样本集中的平均值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, mean(dataSet[:,-<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 样本集规格</span></span><br><span class="line">    m,n = shape(dataSet)</span><br><span class="line">    <span class="comment"># 样本集原始误差，此处使用样本集均方差，乘以样本集个数表示样本集误差</span></span><br><span class="line">    S = var(dataSet[:,-<span class="number">1</span>]) * shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 最小误差，初始化为无限大，因为要找最小</span></span><br><span class="line">    bestS = inf</span><br><span class="line">    <span class="comment"># 最佳分隔特征</span></span><br><span class="line">    bestIndex = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 最佳分隔特征的特征值</span></span><br><span class="line">    bestValue = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 循环所有特征</span></span><br><span class="line">    <span class="keyword">for</span> featIndex <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 循环所有特征值</span></span><br><span class="line">        <span class="keyword">for</span> splitVal <span class="keyword">in</span> <span class="built_in">set</span>(dataSet[:,featIndex]):</span><br><span class="line">            <span class="comment"># 按照特征和特征值做数据集二元切分</span></span><br><span class="line">            mat0 = dataSet[nonzero(dataSet[:,featIndex] &gt; splitVal)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">            mat1 = dataSet[nonzero(dataSet[:,featIndex] &lt;= splitVal)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 判断终止条件</span></span><br><span class="line">            <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN): </span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算子集误差值和作为新的误差值</span></span><br><span class="line">            newS = var(mat0[:,-<span class="number">1</span>]) * shape(mat0)[<span class="number">0</span>] + var(mat1[:,-<span class="number">1</span>]) * shape(mat1)[<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 选择一个最小误差</span></span><br><span class="line">            <span class="keyword">if</span> newS &lt; bestS: </span><br><span class="line">                bestIndex = featIndex</span><br><span class="line">                bestValue = splitVal</span><br><span class="line">                bestS = newS</span><br><span class="line">    <span class="comment"># 如果误差值小于我们提供的最小误差，则表示到叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> (S - bestS) &lt; tolS: </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, var(dataSet[:,-<span class="number">1</span>]) * shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 根据最佳分隔特征和特征值做数据集切分</span></span><br><span class="line">    mat0 = dataSet[nonzero(dataSet[:,bestIndex] &gt; bestValue)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    mat1 = dataSet[nonzero(dataSet[:,bestIndex] &lt;= bestValue)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 判断终止切割数据集条件</span></span><br><span class="line">    <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, var(dataSet[:,-<span class="number">1</span>]) * shape(dataSet)[<span class="number">0</span>]</span><br><span class="line">    <span class="keyword">return</span> bestIndex,bestValue</span><br><span class="line"><span class="comment"># 创建决策树方法</span></span><br><span class="line"><span class="comment"># dataSet：样本集数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 选取最佳分隔特征和特征值</span></span><br><span class="line">    feat, val = chooseBestSplit(dataSet)</span><br><span class="line">    <span class="comment"># 如果没有最佳切割特征，则表示到叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> feat == <span class="literal">None</span>: </span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line">    <span class="comment"># 树词典</span></span><br><span class="line">    retTree = &#123;&#125;</span><br><span class="line">    <span class="comment"># 保存树分隔过程信息</span></span><br><span class="line">    retTree[<span class="string">&#x27;spInd&#x27;</span>] = feat</span><br><span class="line">    retTree[<span class="string">&#x27;spVal&#x27;</span>] = val</span><br><span class="line">    lSet = dataSet[nonzero(dataSet[:,feat] &gt; val)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    rSet = dataSet[nonzero(dataSet[:,feat] &lt;= val)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 迭代调用树创建方法，进行树枝干部分的构建</span></span><br><span class="line">    retTree[<span class="string">&#x27;left&#x27;</span>] = createTree(lSet)</span><br><span class="line">    retTree[<span class="string">&#x27;right&#x27;</span>] = createTree(rSet)</span><br><span class="line">    <span class="keyword">return</span> retTree  </span><br></pre></td></tr></table></figure>
<h2 id="树剪枝">树剪枝</h2>
<hr />
<p>  树剪枝指降低构造的决策树复杂度，避免拟合过程的过拟合现象，过拟合表现为决策树的节点过多。</p>
<h2 id="预剪枝">预剪枝</h2>
<hr />
<p>  预剪枝表示为在算法训练的过程中进行决策树剪枝，方法就是调整算法训练中的停止条件，即算法参数来完成。但是我们并不知道要将算法训练结果调整到一个什么样的状态。并且调整上述算法参数也是很费时间的，所以我们还可以使用后剪枝。</p>
<h2 id="后剪枝">后剪枝</h2>
<hr />
<p>  后剪枝顾名思义就是在算法训练完成以后进行树剪枝，后剪枝方法的实现原理是使用一个测试样本集对算法训练生成的决策树进行测试，然后通过对测试样本集根据已经训练好的决策树进行分隔，并且迭代到叶子节点处，然后计算两个叶子节点合并后的误差是不是比不合并的误差要小，小的话即进行两个叶子节点的合并完成树剪枝。</p>
<h2 id="算法实现-1">算法实现</h2>
<hr />
<h3 id="python-1">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">isTree</span>(<span class="params">obj</span>):</span><br><span class="line">    <span class="keyword">return</span> (<span class="built_in">type</span>(obj).__name__==<span class="string">&#x27;dict&#x27;</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">getMean</span>(<span class="params">tree</span>):</span><br><span class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">&#x27;right&#x27;</span>]):</span><br><span class="line">        tree[<span class="string">&#x27;right&#x27;</span>] = getMean(tree[<span class="string">&#x27;right&#x27;</span>])</span><br><span class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">&#x27;left&#x27;</span>]):</span><br><span class="line">        tree[<span class="string">&#x27;left&#x27;</span>] = getMean(tree[<span class="string">&#x27;left&#x27;</span>])</span><br><span class="line">    <span class="keyword">return</span> (tree[<span class="string">&#x27;left&#x27;</span>]+tree[<span class="string">&#x27;right&#x27;</span>])/<span class="number">2.0</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">def</span> <span class="title function_">prune</span>(<span class="params">tree, testData</span>):</span><br><span class="line">    <span class="keyword">if</span> shape(testData)[<span class="number">0</span>] == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> getMean(tree)</span><br><span class="line">    <span class="keyword">if</span> (isTree(tree[<span class="string">&#x27;right&#x27;</span>]) <span class="keyword">or</span> isTree(tree[<span class="string">&#x27;left&#x27;</span>])):</span><br><span class="line">        lSet, rSet = binSplitDataSet(testData, tree[<span class="string">&#x27;spInd&#x27;</span>], tree[<span class="string">&#x27;spVal&#x27;</span>])</span><br><span class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">&#x27;left&#x27;</span>]):</span><br><span class="line">        tree[<span class="string">&#x27;left&#x27;</span>] = prune(tree[<span class="string">&#x27;left&#x27;</span>], lSet)</span><br><span class="line">    <span class="keyword">if</span> isTree(tree[<span class="string">&#x27;right&#x27;</span>]):</span><br><span class="line">        tree[<span class="string">&#x27;right&#x27;</span>] = prune(tree[<span class="string">&#x27;right&#x27;</span>], rSet)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> isTree(tree[<span class="string">&#x27;left&#x27;</span>]) <span class="keyword">and</span> <span class="keyword">not</span> isTree(tree[<span class="string">&#x27;right&#x27;</span>]):</span><br><span class="line">        lSet, rSet = binSplitDataSet(testData, tree[<span class="string">&#x27;spInd&#x27;</span>], tree[<span class="string">&#x27;spVal&#x27;</span>])</span><br><span class="line">        errorNoMerge = <span class="built_in">sum</span>(power(lSet[:,-<span class="number">1</span>] - tree[<span class="string">&#x27;left&#x27;</span>],<span class="number">2</span>)) + <span class="built_in">sum</span>(power(rSet[:,-<span class="number">1</span>] - tree[<span class="string">&#x27;right&#x27;</span>],<span class="number">2</span>))</span><br><span class="line">        treeMean = (tree[<span class="string">&#x27;left&#x27;</span>]+tree[<span class="string">&#x27;right&#x27;</span>])/<span class="number">2.0</span></span><br><span class="line">        errorMerge = <span class="built_in">sum</span>(power(testData[:,-<span class="number">1</span>] - treeMean,<span class="number">2</span>))</span><br><span class="line">        <span class="keyword">if</span> errorMerge &lt; errorNoMerge: </span><br><span class="line">            <span class="keyword">return</span> treeMean</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            <span class="keyword">return</span> tree</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        <span class="keyword">return</span> tree</span><br></pre></td></tr></table></figure>
<h2 id="模型树">模型树</h2>
<hr />
<p>  用树来对数据建模，除了把叶节点简单地设定为常数值外，我们还可以把叶节点设定为分段的线性函数，分段线性表示该模型由多个线性片段组成。</p>
<h2 id="算法实现-2">算法实现</h2>
<hr />
<h3 id="python-2">Python</h3>
<figure class="highlight python"><table><tr><td class="code"><pre><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"><span class="comment"># 线性函数，即叶子节点的模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">linearSolve</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 数据子集规格</span></span><br><span class="line">    m,n = shape(dataSet)</span><br><span class="line">    <span class="comment"># 构造线性函数的样本集</span></span><br><span class="line">    X = mat(ones((m,n)))</span><br><span class="line">    <span class="comment"># 构造线性函数样本集对应的类别</span></span><br><span class="line">    Y = mat(ones((m,<span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># 根据子集填充线性函数样本集</span></span><br><span class="line">    X[:,<span class="number">1</span>:n] = dataSet[:,<span class="number">0</span>:n-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 根据子集填充线性函数样本集类别</span></span><br><span class="line">    Y = dataSet[:,-<span class="number">1</span>]</span><br><span class="line">    <span class="comment"># 根据线性函数公式计算回归系数</span></span><br><span class="line">    xTx = X.T*X</span><br><span class="line">    <span class="comment"># 检测矩阵是否可逆</span></span><br><span class="line">    <span class="keyword">if</span> linalg.det(xTx) == <span class="number">0.0</span>:</span><br><span class="line">        <span class="keyword">raise</span> NameError(<span class="string">&#x27;This matrix is singular, cannot do inverse,\n try increasing the second value of ops&#x27;</span>)</span><br><span class="line">    <span class="comment"># 根据线性回归公式计算回归系数</span></span><br><span class="line">    ws = xTx.I * (X.T * Y)</span><br><span class="line">    <span class="keyword">return</span> ws,X,Y</span><br><span class="line"><span class="comment"># 叶子节点内容，即该叶子节点对应的线性回归函数的最佳回归系数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modelLeaf</span>(<span class="params">dataSet</span>):</span><br><span class="line">    ws,X,Y = linearSolve(dataSet)</span><br><span class="line">    <span class="keyword">return</span> ws</span><br><span class="line"><span class="comment"># 计算子集误差，差值平方求和</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">modelErr</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 根据当前子集调用线性回归函数</span></span><br><span class="line">    ws,X,Y = linearSolve(dataSet)</span><br><span class="line">    <span class="comment"># 预测结果</span></span><br><span class="line">    yHat = X * ws</span><br><span class="line">    <span class="comment"># 计算误差</span></span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">sum</span>(power(Y - yHat,<span class="number">2</span>))</span><br><span class="line"><span class="comment"># 选择最佳分隔特征和特征值实现方法</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">chooseBestSplit</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 最小子树误差，即迭代停止条件</span></span><br><span class="line">    tolS = <span class="number">1</span> </span><br><span class="line">    <span class="comment"># 最小子树大小，迭代停止条件</span></span><br><span class="line">    tolN = <span class="number">4</span></span><br><span class="line">    <span class="comment"># 如果给定样本集所有值相等，则表示到达叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> <span class="built_in">len</span>(<span class="built_in">set</span>(dataSet[:,-<span class="number">1</span>].T.tolist()[<span class="number">0</span>])) == <span class="number">1</span>:</span><br><span class="line">        <span class="comment"># 返回分隔特征为空和当前样本集中的平均值</span></span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, mean(dataSet[:,-<span class="number">1</span>])</span><br><span class="line">    <span class="comment"># 样本集规格</span></span><br><span class="line">    m,n = shape(dataSet)</span><br><span class="line">    <span class="comment"># 样本集原始误差</span></span><br><span class="line">    S = modelErr(dataSet)</span><br><span class="line">    <span class="comment"># 最小误差，初始化为无限大，因为要找最小</span></span><br><span class="line">    bestS = inf</span><br><span class="line">    <span class="comment"># 最佳分隔特征</span></span><br><span class="line">    bestIndex = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 最佳分隔特征的特征值</span></span><br><span class="line">    bestValue = <span class="number">0</span></span><br><span class="line">    <span class="comment"># 循环所有特征</span></span><br><span class="line">    <span class="keyword">for</span> featIndex <span class="keyword">in</span> <span class="built_in">range</span>(n-<span class="number">1</span>):</span><br><span class="line">        <span class="comment"># 循环所有特征值</span></span><br><span class="line">        <span class="keyword">for</span> splitVal <span class="keyword">in</span> <span class="built_in">set</span>(dataSet[:,featIndex]):</span><br><span class="line">            <span class="comment"># 按照特征和特征值做数据集二元切分</span></span><br><span class="line">            mat0 = dataSet[nonzero(dataSet[:,featIndex] &gt; splitVal)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">            mat1 = dataSet[nonzero(dataSet[:,featIndex] &lt;= splitVal)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">            <span class="comment"># 判断终止条件</span></span><br><span class="line">            <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):</span><br><span class="line">                <span class="keyword">continue</span></span><br><span class="line">            <span class="comment"># 计算子集误差值和作为新的误差值</span></span><br><span class="line">            newS = modelErr(mat0) + modelErr(mat1)</span><br><span class="line">            <span class="comment"># 选择一个最小误差</span></span><br><span class="line">            <span class="keyword">if</span> newS &lt; bestS: </span><br><span class="line">                bestIndex = featIndex</span><br><span class="line">                bestValue = splitVal</span><br><span class="line">                bestS = newS</span><br><span class="line">    <span class="comment"># 如果误差值小于我们提供的最小误差，则表示到叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> (S - bestS) &lt; tolS: </span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, modelLeaf(dataSet)</span><br><span class="line">    <span class="comment"># 根据最佳分隔特征和特征值做数据集切分</span></span><br><span class="line">    mat0 = dataSet[nonzero(dataSet[:,bestIndex] &gt; bestValue)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    mat1 = dataSet[nonzero(dataSet[:,bestIndex] &lt;= bestValue)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 判断终止切割数据集条件</span></span><br><span class="line">    <span class="keyword">if</span> (shape(mat0)[<span class="number">0</span>] &lt; tolN) <span class="keyword">or</span> (shape(mat1)[<span class="number">0</span>] &lt; tolN):</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">None</span>, modelLeaf(dataSet)</span><br><span class="line">    <span class="keyword">return</span> bestIndex,bestValue</span><br><span class="line"><span class="comment"># 创建决策树方法</span></span><br><span class="line"><span class="comment"># dataSet：样本集数据</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">createTree</span>(<span class="params">dataSet</span>):</span><br><span class="line">    <span class="comment"># 选取最佳分隔特征和特征值</span></span><br><span class="line">    feat, val = chooseBestSplit(dataSet)</span><br><span class="line">    <span class="comment"># 如果没有最佳切割特征，则表示到叶子节点</span></span><br><span class="line">    <span class="keyword">if</span> feat == <span class="literal">None</span>: </span><br><span class="line">        <span class="keyword">return</span> val</span><br><span class="line">    <span class="comment"># 树词典</span></span><br><span class="line">    retTree = &#123;&#125;</span><br><span class="line">    <span class="comment"># 保存树分隔过程信息</span></span><br><span class="line">    retTree[<span class="string">&#x27;spInd&#x27;</span>] = feat</span><br><span class="line">    retTree[<span class="string">&#x27;spVal&#x27;</span>] = val</span><br><span class="line">    lSet = dataSet[nonzero(dataSet[:,feat] &gt; val)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    rSet = dataSet[nonzero(dataSet[:,feat] &lt;= val)[<span class="number">0</span>],:][<span class="number">0</span>]</span><br><span class="line">    <span class="comment"># 迭代调用树创建方法，进行树枝干部分的构建</span></span><br><span class="line">    retTree[<span class="string">&#x27;left&#x27;</span>] = createTree(lSet)</span><br><span class="line">    retTree[<span class="string">&#x27;right&#x27;</span>] = createTree(rSet)</span><br><span class="line">    <span class="keyword">return</span> retTree</span><br></pre></td></tr></table></figure>
]]></content>
      <categories>
        <category>机器学习</category>
      </categories>
      <tags>
        <tag>树回归</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark概述</title>
    <url>/2017/06/02/Spark%E6%A6%82%E8%BF%B0/</url>
    <content><![CDATA[<p>  Spark是UC Berkeley AMP lab
(加州大学伯克利分校的AMP实验室)所开源的类似Hadoop
MapReduce的通用并行框架，它拥有Hadoop
MapReduce所具有的优点，但不同于MapReduce的是Job中间输出结果可以保存在内存中，从而不需要读写Hdfs，因此Spark能更好的适用于数据挖掘与机器学习等需要迭代的MapReduce算法。</p>
<p>  Spark是在Scala语言中实现的，它将Scala用作其应用程序的框架。与Hadoop不同的是，Spark和Scala能够紧密集成，其中的Scala可以像操作本地集合对象一样轻松的操作分布式数据集。Spark其实是对Hadoop的补充，可以在Hadoop文件系统中并行运行，通过Mesos的第三方集群框架可以支持此行为。</p>
<span id="more"></span>
<p>  在Spark项目开源后，在2013年Spark成为了Apache基金会下的项目，由于其代码量少、轻量级和使用内存的特性受到大数据行业的关注，在众多第三方开发者的维护下，Spark进度高速发展期而成为了Apache基金会的顶级项目。</p>
<p>  Apache对Spark的定义为：通用的大数据快速处理引擎。Spark是一种专为大规模数据处理而设计的快速通用的计算引擎，使用一个技术堆栈就完美地解决大数据领域的各种计算任务。</p>
<h2 id="spark组成">Spark组成</h2>
<hr />
<p>  Spark是一个一站式的大数据计算框架，其中包括Spark Core、Spark
Sql、Spark
Streaming、MLlib和GraphX，分别在大数据领域中解决了离线批处理、交互式查询、实时流计算、机器学习与图计算的所有任务和问题。另外由于Spark基于内存存储的特性，使得Spark的计算性能超过MapReduce和Hive的的数倍以上，所以越来越多的IT公司使用Spark+Hadoop的组合来使用Spark进行大数据的计算任务，用Hadoop解决大数据的存储问题。</p>
<h2 id="spark运行原理">Spark运行原理</h2>
<hr />
<ol type="1">
<li>我们将写好的Spark应用在Spark集群上的某个节点提交并开始执行；</li>
<li>应用被提交后，节点生成一个Driver，Driver启动后，对该Spark应用进行初始化操作，并请求集群Master节点进行Spark应用的注册，通知Master进行资源的分配；</li>
<li>Master节点在收到应用的注册请求后发送给所有节点的Worker，Worker进行资源的调整和分配，即启动Executor；</li>
<li>节点启动Executor后会与Driver通信进行反注册，即告知Driver在集群中哪些Executor是为该Driver服务的；</li>
<li>之后Driver开始读取应用中数据源中的数据来创建RDD；</li>
<li>Driver根据Spark应用中定义的对RDD的操作生成一大推Task并发送给Executor；</li>
<li>Executor接收到Task后，启动多个线程去执行收到的Task；</li>
<li>对RDD的partition数据执行完指定操作后形成新的RDD partition；</li>
</ol>
<h2 id="spark中的rdd">Spark中的RDD</h2>
<hr />
<p>  RDD是Spark提供的核心抽象概念，是Resillient Distributed
Dataset的缩写，即弹性分布式数据集。</p>
<p>  RDD在抽象上说是一种元素的集合，包含了数据且是被分区的，其中每个分区被分布在集群中的不同节点上使得RDD中的数据可以被并行操作。</p>
<p>  RDD具备像MapReduce等数据流模型的容错特性，并允许开发人员在大型集群上执行基于内存的计算，因此有效解决了大数据计算中的迭代算法问题和交互式数据挖掘。</p>
<p>  RDD是只读的数据集合，是一种高度受限的共享内存，并且只能基于在稳定物理存储中的数据集和其他已有的RDD上执行确定性操作来创建。</p>
<h2 id="rdd操作">RDD操作</h2>
<hr />
<p>  Spark支持两种RDD操作：transformation和action。transformation操作会针对已有的RDD创建一个新的RDD；而action则主要是对RDD进行最后的操作，如遍历、reduce和保存到文件等。</p>
<p>  transformation操作有lazy特性，该特性表示如果一个Spark应用中只定义了transformation操作，那么即使你执行该该应用，这些操作也不会实际执行。换句话说transformation操作时不会触发Spark程序的执行，它们只是记录了对RDD的操作，只有当transformation操作之后接着执行一个action操作，那么Spark应用才会被实际执行。lazy这种特性使得Spark应用不会产生过多的中间结果。</p>
<p>  常用的transformation操作如下：</p>
<table>
<colgroup>
<col style="width: 21%" />
<col style="width: 78%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">操作</th>
<th style="text-align: left;">简介</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">map</td>
<td
style="text-align: left;">将RDD中的每个元素传入自定义函数并获取一个新的元素，然后用所有的新元素组成新的RDD</td>
</tr>
<tr class="even">
<td style="text-align: center;">filter</td>
<td
style="text-align: left;">对RDD中每个元素进行判断，如果返回true则保留，否则被剔除</td>
</tr>
<tr class="odd">
<td style="text-align: center;">flatMap</td>
<td
style="text-align: left;">与map类似，但是对每一个元素都可以返回一个或多个新的元素</td>
</tr>
<tr class="even">
<td style="text-align: center;">groupByKey</td>
<td
style="text-align: left;">根据key进行分组，然后每个key对应一个Iterable<value></td>
</tr>
<tr class="odd">
<td style="text-align: center;">reduceByKey</td>
<td style="text-align: left;">对每个key对应的value进行reduce操作</td>
</tr>
<tr class="even">
<td style="text-align: center;">sortByKey</td>
<td style="text-align: left;">对每个key对应的value进行排序操作</td>
</tr>
<tr class="odd">
<td style="text-align: center;">join</td>
<td style="text-align: left;">对两个包含&lt;key,
value&gt;对的RDD进行join操作，每个key
join上的pair，都会传入自定义函数进行处理</td>
</tr>
<tr class="even">
<td style="text-align: center;">cogroup</td>
<td
style="text-align: left;">同join，但是每个key对应的Iterable<value>都会传入自定义函数进行处理</td>
</tr>
</tbody>
</table>
<p>  常用action操作如下：</p>
<table>
<colgroup>
<col style="width: 25%" />
<col style="width: 74%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">操作</th>
<th>简介</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">reduce</td>
<td>将RDD中的所有元素进行聚合操作，第一个和第二个元素聚合后产生的值与第三个元素聚合，以此类推</td>
</tr>
<tr class="even">
<td style="text-align: center;">collect</td>
<td>将RDD中所有元素获取到本地客户端</td>
</tr>
<tr class="odd">
<td style="text-align: center;">count</td>
<td>获取RDD元素</td>
</tr>
<tr class="even">
<td style="text-align: center;">take(n)</td>
<td>获取RDD中前n个元素</td>
</tr>
<tr class="odd">
<td style="text-align: center;">saveAsTextFile</td>
<td>将RDD元素保存到文件中，对每个元素调用toString方法</td>
</tr>
<tr class="even">
<td style="text-align: center;">countByKey</td>
<td>对每个key对应的值进行count计数</td>
</tr>
<tr class="odd">
<td style="text-align: center;">foreach</td>
<td>遍历RDD中的每个元素</td>
</tr>
</tbody>
</table>
<h2 id="rdd持久化">RDD持久化</h2>
<hr />
<p>  RDD的持久化功能室Spark中非常重要的一个功能特性，由于Spark底层的固有特性，当创建了一个RDD之后，使用transformation对该RDD执行下一步操作后，之前的RDD是会被销毁的，也就是Spark默认当对现有的一个RDD进行transformation操作后上一个RDD被处理为没用的RDD而被马上销毁，但是如果在特定业务场景下如果对现有的RDD会有两次以上的操作时，销毁会被认为是没必要的，如果要对RDD进行第二次transformation操作时由于该RDD已经被Spark销毁，所以必须重新构建，如果在一个很大的数据中去构建一个RDD两次以上，这对Spark应用的性能上来说无非是灾难性的，所以Spark会提供一个RDD持久化的功能，这样就保证二次以上的RDD操作无需重新构建RDD，而是直接从被持久化的RDD中进行transformation操作。</p>
<p>  对RDD执行持久化操作时，每个节点都会将自己操作RDD的partition持久化到内存或硬盘中供之后对该RDD进行反复操作，使二次以上的RDD操作不需要重新构建该RDD而是直接从缓存中读取对应节点操作的partition部分。</p>
<h2 id="rdd持久化策略">RDD持久化策略</h2>
<hr />
<p>  RDD持久化是可以手动指定不同的持久化策略的，如果可以将RDD持久化到内存中、到磁盘中、使用序列化的方式等。</p>
<p>  RDD持久化的策略列表如下：</p>
<table>
<colgroup>
<col style="width: 45%" />
<col style="width: 54%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">持久化策略</th>
<th>简介</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">MEMORY_ONLY</td>
<td>以非序列化的Java对象持久化在JVM内存中，如果内存无法完全存储RDD所有的partition，那么那些没用持久化的partition就会在下一次需要使用它的时候重新被计算</td>
</tr>
<tr class="even">
<td style="text-align: center;">MEMORY_AND_DISK</td>
<td>同上MEMORY_ONLY，但是当某些partition无法存储在内存中时，会持久化到磁盘中，下次需要使用这些partition时从磁盘读取</td>
</tr>
<tr class="odd">
<td style="text-align: center;">MEMORY_ONLY_SER</td>
<td>同上MEMORY_ONLY，但是会使用Java序列化的方式，将Java对象序列化之后进行持久化，可以减少内存开销，但是在使用时会进行反序列化操作，所以会加大CPU的开销</td>
</tr>
<tr class="even">
<td style="text-align: center;">MEMORY_AND_DSK_SER</td>
<td>同MEMORY_AND_DISK，但是使用序列化方式持久化Java对象</td>
</tr>
<tr class="odd">
<td style="text-align: center;">DISK_ONLY</td>
<td>使用非序列化Java对象的方式持久化，完全存储到磁盘上。</td>
</tr>
<tr class="even">
<td
style="text-align: center;">MEMORY_ONLY_2、MEMORY_AND_DISK_2、等等</td>
<td>如果尾部加了2的持久化策略，表示会将持久化数据复制一份保存到其他节点而保障数据的容错性能</td>
</tr>
</tbody>
</table>
<h2 id="spark中的共享变量">Spark中的共享变量</h2>
<hr />
<p>  在日常的生产开发中，经常会使用全局变量的情况，在Spark应用中也会有使用全局变量的业务场景，比如全局范围内统计等等，这里的全局变量就是Spark中的共享变量。</p>
<p>  在Spark中如果要使用一个外部变量时的默认的做法是将该变量拷贝到每个节点中的每个task中，也就是说每个task操作的只是该变量的一个拷贝副本，还达不到共享的功能。当然Spark也解决了使用共享变量的特性。Spark提供了两种共享变量的使用，一种时广播变量（Broadcast
Variable），另一种时累加变量（Accumulator
Variable）。广播变量会将使用到的变量为每个节点拷贝一份，而累加变量则可以让多个task共同操作一份变量。</p>
<p>  广播变量是只读的，并且每个节点只会存在一份副本，而不会为每个task都拷贝一份，这样最大限度的减少了变量到每个节点的网络传输消耗和节点上的内存消耗。</p>
<p>  累加变量用于多个节点对一个变量进行共享性的操作，值得注意的是Spark中对累加变量的操作只限与累加并且不能读取该累加变量的值，只有Driver程序可以。所以Spark中的累加变量类似于Hadoop
MapReduce中的计数器组件。</p>
<h2 id="spark-sql">Spark SQL</h2>
<hr />
<p>  提到Spark
SQL的由来我们必须先说说Hive，Hadoop的Hive是让那些不熟悉Java的数据分析师在无法深入进行MapReduce编程时可以使用他们熟悉的关系型数据库的SQL模型来进行操作Hdfs数据完成数据仓库的建模和建设并针对数据仓库的数据进行统计和分析使用，但是Hive的底层基于MapReduce，因为MapReduce计算是基于磁盘IO和网络IO的，所以导致Hive性能的底下。</p>
<p>  Spark起初在Hive的基础上推出了Shark，Shark基于Hive的语法解析器和查询优化器等组件但是修改了内存管理、物理计划和执行三个模块并底层使用Spark基于内存的计算模型使得Shark的计算性能较Hive有很大的提升，但是由于Shark和Hive的关系紧密，所以对Shark性能的提升还是造成了制约，所以Spark推出了全新的Spark
SQL，并且Spark
SQL可以支持更多的数据源查询，如Hive、RDD、Parquet、Json和JDBC等。</p>
<p>  Spark SQL是Spark中的一个模块，主要用于进行结构化数据的处理。</p>
<h2 id="spark-sql中的dataframe">Spark SQL中的DataFrame</h2>
<hr />
<p>  DataFrame是Spark
SQL中最核心的编程抽象，是以列的形式组织的分布式的数据结合，DataFrame和关系型数据库中的表类似。DataFrame可以通过很多的数据源进行构建。</p>
<h2 id="spark-streaming">Spark Streaming</h2>
<hr />
<p>  Spark Streaming是Spark
Core的一种拓展，它可以用于进行大规模、高吞吐量、容错的实时数据流的处理。Spark
Streaming支持从很多数据源中读取数据。常见的如Kafka、Flume、Twitter、ZeroMQ、Kinesis以及Tcp
Socket。</p>
<p>  Spark
Streaming的工作流程为接收一个实时输入数据流，然后用时间关系将接收到的数据拆分为多个batch，比如每收集1秒然后将数据封装为一个batch，然后将每个batch交给Spark进行计算处理，最后会生成一个结果数据流并且也是由一个一个batch组成。</p>
<h2 id="spark-streaming中的dstream">Spark Streaming中的DStream</h2>
<hr />
<p>  DStream类似于Spark
SQL中的DataFrame，也是一种数据的高级抽象概念，通俗的被叫做离散流，表示为一个持续不断的数据流。DStream可以通过输入数据源来创建，也可以通过其他DStream应用的高阶函数来创建。其实在DStream的内部是一系列持续不断产生的RDD，每个RDD中都办函了一个时间段内的数据。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>Spark入门</title>
    <url>/2017/06/03/Spark%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<p>  在编写Spark应用程序之前我们应该清楚一点，Spark应用是构建在Scala语言的基础上，但是Apache官方封装了其他语言的版本，如Java、Python等，本文是基于Java语言实现的。在Spark应用程序实现中，我们需要有一个应用入口，在Java语言中即main函数，也就是说在Java版本的Spark应用是从main函数开始执行的。</p>
<span id="more"></span>
<h2 id="sparkconf">SparkConf</h2>
<hr />
<p>  在编写Spark应用开始，我们必须获取Spark集群的一些配置信息，即new一个SparkConf对象，该对象存储了Spark应用运行过程中所需要的所有配置内容</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>();</span><br></pre></td></tr></table></figure>
<p>  接下来会设置一些Spark应用运行时需要的参数，通过调用SparkConf中的方法去指定。</p>
<p>  指定Spark应用的名称</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">conf.setAppName(<span class="string">&quot;My Frist Spark App.&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>  配置Spark应用需要链接的Spark集群，这里被设置为集群中Master几点的URL</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">conf.setMaster(<span class="string">&quot;spark://spark1:7077&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>  如果Spark应用在本地测试运行的时候，可以指定URL为local则表示该Spark应用在本地执行</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">conf.setMaster(<span class="string">&quot;local&quot;</span>);</span><br></pre></td></tr></table></figure>
<h2 id="sparkcontext">SparkContext</h2>
<hr />
<p>  在Spark中，SparkContext时所有Spark功能的一个入口，所以无论使用哪种编程语言都需要一个SparkContext对象，它作用于Spark应用的初始化所需的一些核心组件，包括资源调度器（DAGSchedule、TaskScheduler）和在Master节点注册应用。</p>
<p>  根据Spark应用需要实现的任务和编程语言的不同，SparkContext对象也有不同的名字，如果使用Scala或Python开发，则默认为SparkContext；使用Java语言开发，则SparkContext被定义为JavaSparkContext。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">JavaSparkContext</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line">\\ ....</span><br><span class="line">\\ 所有计算操作</span><br><span class="line">\\ ....</span><br><span class="line">sc.close();</span><br></pre></td></tr></table></figure>
<p>对象参数为我们构建的SparkConf对象，并在应用完成后进行关闭操作。</p>
<h2 id="创建rdd">创建RDD</h2>
<hr />
<p>  Spark应用的运行配置和初始化完成后，我们需要创建初始的RDD，即从数据源中获取数据并完成RDD的创建工作。输入源的数据会被打散并分配到RDD的每个partition中形成一个初始的分布式数据集。</p>
<h3 id="并行化集合创建">并行化集合创建</h3>
<p>  使用并行化集合的方式可以使Spark应用在程序实现过程中手动创造一个数据集作为Spark应用的数据输入源</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numberRDD = sc.parallelize(numbers);</span><br></pre></td></tr></table></figure>
<h3 id="文本文件创建">文本文件创建</h3>
<p>  以文本文件作为Spark应用的数据源时，RDD中的每一个元素相当于文本文件中每一行的内容</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;spark.txt&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>textFile方法会读取文件内数据生成我们的初始RDD。</p>
<h3 id="hdfs创建">Hdfs创建</h3>
<p>  以Hdfs作为Spark应用的数据源和文本文件类似，不同的是输入参数被替换为Hdfs链接的格式</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="textfile">textFile</h3>
<p>  SparkContext对象的textFile方法支持目录、压缩文件和通配符进行RDD创建并且默认会为每一个文件创建partition，并支持使用第二个参数手动设置partition数量。</p>
<h2 id="rdd操作">RDD操作</h2>
<hr />
<p>  在Spark应用中，其实我们最主要的部分就是对RDD进行运算的部分，其中包括RDD的筛选、合并等操作，即transformation和action操作。</p>
<h3 id="map">map</h3>
<p>  map操作将自定义函数分别作用于RDD中每个元素并获取一个新的元素，然后将所有新元素组成一个新的RDD。对任何类型的RDD，map算子都可以调用。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; lineLength = lines.map(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Function</span>&lt;String, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(String v1)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> v1.length();</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>  Function类中第一个泛型参数为传入自定义函数的类型，第二个泛型参数为自定义函数返回的数据类型，map操作将自定义函数的返回数据作为新RDD的元素。</p>
<h3 id="filter">filter</h3>
<p>  filter算子是将自定义函数作用于RDD中每个元素进行运算且自定义函数中call()方法的返回类型必须为Boolean，如果需要保留RDD中某个元素，那么在将该元素调用自定义函数的时候返回true，否则返回false不保留该元素</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numberRDD = sc.parallelize(numbers);</span><br><span class="line">JavaRDD&lt;Integer&gt; evenNumberRDD = numberRDD.filter(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, Boolean&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Boolean <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> v1 % <span class="number">2</span> == <span class="number">0</span>;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br><span class="line">evenNumberRDD.foreach(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">VoidFunction</span>&lt;Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">(Integer t)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        System.out.println(t);</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>  跟map算子形同，Function类中第一个泛型参数为传入自定义函数的类型，第二个泛型参数为自定义函数返回的数据类型，filter操作将根据自定义函数的返回值确定是否保留当前元素。</p>
<h3 id="flatmap">flatMap</h3>
<p>  flatMap通常在将RDD中数据拆分成多个元素的场景使用，该操作会将我们提供的RDD中每一个元素都调用我们传入的自定义函数并返回一个新的元素或多个新的元素组成一个新的RDD等待下一步处理</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; words = lines.flatMap(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Iterable&lt;String&gt; <span class="title function_">call</span><span class="params">(String line)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(line.split(<span class="string">&quot;&quot;</span>));</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>  FlatMapFunction类有两个泛型参数分别代表输入和输出类型，这里将每行文本作为输入然后做字符串分隔并返回多个元素组成新的RDD。</p>
<h3 id="maptopair">mapToPair</h3>
<p>  mapToPair通常在将RDD元素变换为（word，1）这种Tuple格式时使用</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; words = lines.flatMap(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Iterable&lt;String&gt; <span class="title function_">call</span><span class="params">(String line)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(line.split(<span class="string">&quot;&quot;</span>));</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">PairFunction</span>&lt;String, String, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Tuple2&lt;String, integer&gt; <span class="title function_">call</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(word, <span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>  JavaPairRDD也是RDD，它的两个泛型参数表示其中Tuple元素中第一个值和第二个值的类型。mapToPair要求和PairFunction搭配使用，PairFunction中的三个泛型参数分别表述输入类型和返回元素Tuple中两个子元素类型。</p>
<h3 id="groupbykey">groupByKey</h3>
<p>  groupByKey算子是一个聚合类型的算子，是对RDD中元素进行分组。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Tuple2&lt;String, Integer&gt;&gt; scoreList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;class1&quot;</span>, <span class="number">80</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;class2&quot;</span>, <span class="number">75</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;class1&quot;</span>, <span class="number">90</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(<span class="string">&quot;class2&quot;</span>, <span class="number">65</span>),</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; scores = sc.parallelizePairs(scoreList);</span><br><span class="line">JavaPairRDD&lt;String, Iterable&lt;Integer&gt;&gt; groupedScores = scores.groupByKey();</span><br></pre></td></tr></table></figure>
<p>  使用groupByKey算子返回一个新的对key相同的元素进行聚合后的RDD。</p>
<h3 id="reducebykey">reduceByKey</h3>
<p>  reduceByKey作用于RDD元素的每个key并进行reduce操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; words = lines.flatMap(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Iterable&lt;String&gt; <span class="title function_">call</span><span class="params">(String line)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(line.split(<span class="string">&quot;&quot;</span>));</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">PairFunction</span>&lt;String, String, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Tuple2&lt;String, integer&gt; <span class="title function_">call</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(word, <span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; wordCounts = pairs.reduceByKey(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">Function2</span>&lt;Integer, Integer, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(Integer v1, Integer v2)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> v1 + v2;</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>  该计算会将所有RDD元素传入自定义函数，并对所有key相同的元素进行第二个元素的相加操作，Function2的三个泛型参数分别表示输入两个相同key的value值和返回后的结果。</p>
<h3 id="sortbykey">sortByKey</h3>
<p>  sortByKey是一个排序算子，是对输入RDD中所有的key进行排序后返回新的RDD，新的RDD和就的RDD中元素没用变换，只是顺序不同而已。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Tuple2&lt;Integer, String&gt;&gt; scoreList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">80</span>, <span class="string">&quot;class1&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">75</span>, <span class="string">&quot;class2&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">90</span>, <span class="string">&quot;class1&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">65</span>, <span class="string">&quot;class2&quot;</span>),,</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;Integer, String&gt; scores = sc.parallelizePairs(scoreList);</span><br><span class="line">JavaPairRDD&lt;Integer, String&gt; sortedScores = scores.sortByKey(<span class="literal">false</span>);</span><br></pre></td></tr></table></figure>
<p>  在Spark应用的排序操作中，有时会遇到复杂的排序需求，即不只是简单的数字排序，那么此时我们需要自定义我们的排序key来完成RDD中元素的排序。</p>
<p>  自定义的排序key必须实现Ordered和Serializable接口，完成<span
class="math inline">\(greater、\)</span>greater<span
class="math inline">\(eq、\)</span>less、<span
class="math inline">\(less\)</span>eq、compare、compareTo和getter、setter、hascode、equals方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SecondarySortKey</span> <span class="keyword">implements</span> <span class="title class_">Ordered</span>&lt;SecondarySortKey&gt;, Serializable&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> first;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> second;</span><br><span class="line">  <span class="keyword">public</span> <span class="title function_">SecondarySortKey</span><span class="params">(<span class="type">int</span> first, <span class="type">int</span> second)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.first = first;</span><br><span class="line">    <span class="built_in">this</span>.second = second;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> $greater(SecondarySortkey other)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first &gt; other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first != other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.second &gt; other.getSecond())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> $greater$eq(SecondarySortKey other)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.$greater(other))</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first != other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.second == other.getSecond())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> $less(SecondarySortKey other)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first &lt; other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first != other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.second &lt; other.getSecond())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> $less$eq(SecondarySortKey other)&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.$less(other))</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.frist != other.getFirst())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.second == other.getSecond())</span><br><span class="line">      <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compare</span><span class="params">(SecondarySortKey other)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first - other.getFirst() != <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>.first - other.getFirst();</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.second - other.getSecond();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">compareTo</span><span class="params">(SecondarySortKey other)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span>.first - other.getFirst() != <span class="number">0</span>)</span><br><span class="line">      <span class="keyword">return</span> <span class="built_in">this</span>.first - other.getFirst();</span><br><span class="line">    <span class="keyword">return</span> <span class="built_in">this</span>.second - other.getSecond();</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getFirst</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> first;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setFirst</span><span class="params">(<span class="type">int</span> first)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.first = first;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getSecond</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> second;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setSecond</span><span class="params">(<span class="type">int</span> second)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.second = second;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">hasCode</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">final</span> <span class="type">int</span> <span class="variable">prime</span> <span class="operator">=</span> <span class="number">31</span>;</span><br><span class="line">    <span class="type">int</span> <span class="variable">result</span> <span class="operator">=</span> <span class="number">1</span>;</span><br><span class="line">    result = prime * result + first;</span><br><span class="line">    result = prime * result + second;</span><br><span class="line">    <span class="keyword">return</span> result;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="meta">@Override</span></span><br><span class="line">  <span class="keyword">public</span> <span class="type">boolean</span> <span class="title function_">equals</span><span class="params">(Object obj)</span>&#123;</span><br><span class="line">    <span class="keyword">if</span>(<span class="built_in">this</span> == obj) <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    <span class="keyword">if</span>(obj == <span class="literal">null</span>) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(getClass() != obj.getClass()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="type">SecondarySortKey</span> <span class="variable">other</span> <span class="operator">=</span> (SecondarySortKey) obj;</span><br><span class="line">    <span class="keyword">if</span>(first != other.getFirst()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">if</span>(second != other.getSecond()) <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>使用时直接将自定义好的key类型作为待排序RDD中元素的key。</p>
<h3 id="join">join</h3>
<p>  join算子实现了两个RDD的链接操作，进行join操作时，根据两个RDD中的key进行join</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Tuple2&lt;Integer, String&gt;&gt; studentList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">1</span>, <span class="string">&quot;leo&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">2</span>, <span class="string">&quot;jack&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">3</span>, <span class="string">&quot;tom&quot;</span>)</span><br><span class="line">);</span><br><span class="line">List&lt;Tuple2&lt;Integer, Integer&gt;&gt; scoreList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">100</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">90</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">60</span>)</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;Integer, String&gt; students = sc.parallelizePairs(studentList);</span><br><span class="line">JavaPairRDD&lt;Integer, Integer&gt; scores = sc.parallelizePairs(scoreList);</span><br><span class="line">JavaPairRDD&lt;Integer, Tuple2&lt;String, Integer&gt;&gt; studentScores = students.join(scores);</span><br></pre></td></tr></table></figure>
<p>  join操作后返回一个新的RDD，新RDD的第一个泛型参数为原RDD的key的类型，第二个泛型参数中包括两个原RDD中所有的值的类型。假如有一个RDD（1，1）（1，2）（1，3）和（1，4）（2，1）（2，2），进行join以后会得到（1，（1，4））（1，（2，4））（1，（3，4））。</p>
<h3 id="cogroup">cogroup</h3>
<p>  cogroup和join类似，不同的是cogroup会将所有关联到的元素都放到一个Iterable的对象中</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Tuple2&lt;Integer, String&gt;&gt; studentList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">1</span>, <span class="string">&quot;leo&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">2</span>, <span class="string">&quot;jack&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, String&gt;(<span class="number">3</span>, <span class="string">&quot;tom&quot;</span>)</span><br><span class="line">);</span><br><span class="line">List&lt;Tuple2&lt;Integer, Integer&gt;&gt; scoreList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">100</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">90</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">60</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">1</span>, <span class="number">70</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">2</span>, <span class="number">80</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;Integer, Integer&gt;(<span class="number">3</span>, <span class="number">50</span>)</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;Integer, String&gt; students = sc.parallelizePairs(studentList);</span><br><span class="line">JavaPairRDD&lt;Integer, Integer&gt; scores = sc.parallelizePairs(scoreList);</span><br><span class="line">JavaPairRDD&lt;Integer, Tuple2&lt;Iterable&lt;String&gt;, Iterable&lt;Integer&gt;&gt;&gt; studentScores = students.cogroup(scores);</span><br></pre></td></tr></table></figure>
<h3 id="reduce">reduce</h3>
<p>  reduce操作是对RDD中每个元素进行reduce操作即对输入RDD中所有元素进行聚合操作并获取一个最终结果。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numbers = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numberRDD = sc.parallelize(numbers);</span><br><span class="line"><span class="type">int</span> <span class="variable">sum</span> <span class="operator">=</span> numberRDD.reduce(</span><br><span class="line">    <span class="keyword">new</span> <span class="title class_">Function2</span>&lt;Integer, Integer, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(Integer v1, Integer v2)</span> <span class="keyword">throws</span> Exception &#123;</span><br><span class="line">        <span class="keyword">return</span> v1 + v2;</span><br><span class="line">      &#125;</span><br><span class="line">    &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h3 id="collect">collect</h3>
<p>  collect操作的作用是将远程集群上面的RDD拉取到本地进行操作，考虑到数据量的问题，一般不会使用到该操作</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line">List&lt;Integer&gt; doubleNumberList = numbers.collect();</span><br></pre></td></tr></table></figure>
<h3 id="count">count</h3>
<p>  count是一个统计操作，对一个RDD进行count操作会返回一个数值型数据表示该RDD中有多少个元素</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line"><span class="type">long</span> <span class="variable">count</span> <span class="operator">=</span> numbers.count();</span><br></pre></td></tr></table></figure>
<h3 id="taken">take(n)</h3>
<p>  take(n)操作和collect类似，只是take(n)操作只获取RDD中前n个元素，collect为获取所有RDD中的元素</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line">javaRDD&lt;Integer&gt; sortedNumb = numbers.sortByKey(<span class="literal">true</span>);</span><br><span class="line">List&lt;Integer&gt; topNumber = sortedNumb.take(<span class="number">3</span>);</span><br></pre></td></tr></table></figure>
<h3 id="saveastextfile">saveAsTextFile</h3>
<p>  saveAsTextFile操作会将RDD中的数据保存在一个文件中，也可以是hdfs系统文件，并且我们需要指定一个具体的保存文件的目录而不是文件名</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line">javaRDD&lt;Integer&gt; sortedNumb = numbers.sortByKey(<span class="literal">true</span>);</span><br><span class="line">sortedNumb.saveAsTextFile(<span class="string">&quot;hdfs://spark1:9000/test&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="countbykey">countByKey</h3>
<p>  countByKey操作时统计RDD中每个key对应的元素个数</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;Tuple2&lt;String, String&gt;&gt; scoreList = Arrays.asList(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, String&gt;(<span class="string">&quot;class1&quot;</span>, <span class="string">&quot;leo&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, String&gt;(<span class="string">&quot;class2&quot;</span>, <span class="string">&quot;jack&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, String&gt;(<span class="string">&quot;class1&quot;</span>, <span class="string">&quot;marry&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, String&gt;(<span class="string">&quot;class2&quot;</span>, <span class="string">&quot;tom&quot;</span>),</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, String&gt;(<span class="string">&quot;class2&quot;</span>, <span class="string">&quot;david&quot;</span>)</span><br><span class="line">); </span><br><span class="line">JavaPairRDD&lt;String, String&gt; students = sc.parallelizePairs(scoreList);</span><br><span class="line">Map&lt;String, Object&gt; studentCounts = students.countByKey();</span><br></pre></td></tr></table></figure>
<h3 id="foreach">foreach</h3>
<p>  foreach是一个action操作，用来遍历所有RDD数据集</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;hdfs://spark1:9000/spark.txt&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; words = lines.flatMap(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Iterable&lt;String&gt; <span class="title function_">call</span><span class="params">(String line)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> Arrays.asList(line.split(<span class="string">&quot;&quot;</span>));</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; pairs = words.mapToPair(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">PairFunction</span>&lt;String, String, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Tuple2&lt;String, integer&gt; <span class="title function_">call</span><span class="params">(String word)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Tuple2</span>&lt;String, Integer&gt;(word, <span class="number">1</span>);</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">JavaPairRDD&lt;String, Integer&gt; wordCounts = pairs.reduceByKey(</span><br><span class="line">	<span class="keyword">new</span> <span class="title class_">Function2</span>&lt;Integer, Integer, Integer&gt;()&#123;</span><br><span class="line">      <span class="meta">@Override</span></span><br><span class="line">      <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(Integer v1, Integer v2)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">        <span class="keyword">return</span> v1 + v2;</span><br><span class="line">      &#125;</span><br><span class="line">	&#125;</span><br><span class="line">);</span><br><span class="line">wordCounts.foreach(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">VoidFunction</span>&lt;Tuple2&lt;String, Integer&gt;&gt;()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">(Tuple2&lt;String, Integer&gt; wordCount)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">      System.out.println(wordCount._1 + <span class="string">&quot;:&quot;</span> + wordCount._2);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h2 id="rdd持久化">RDD持久化</h2>
<hr />
<p>  因为在Spark应用中，对当前RDD进行一个算子操作后为了保障系统资源的合理利用和减少中间结果数据的资源消耗原RDD就会被及时销毁，所以如果想再次使用之前被构建的RDD则必须重新读取数据进行RDD构建或提前将RDD缓存下来避开Spark集群的销毁策略，同样的考虑Spark应用的性能和效率，所以我们在大数据处理场景下应该避免RDD的重复构建而使用将未来可能会用到的RDD缓存下来的方法，这里我们叫RDD的持久化操作。</p>
<p>  Spark应用中使用cache()和persist()两个方法进行RDD的持久化操作，cache()方法调用的是persist()的无参版本，默认会将RDD持久化到内存中persist(MEMORY_ONLY)，如果需要使用其他的持久化策略，则修改具体的参数即可。在Spark应用中销毁我们持久化后的RDD，使用unpersist()方法。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;spark.txt&quot;</span>).cache();</span><br></pre></td></tr></table></figure>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;spark.txt&quot;</span>).persist(MEMORY_ONLY);</span><br></pre></td></tr></table></figure>
<p>  需要注意的是RDD的持久化操作必须在该RDD创建完成后马上进行。</p>
<h2 id="共享变量">共享变量</h2>
<hr />
<p>  Spark为Spark应用提供两个实现Spark集群共享变量的方案，分别为广播变量和递增变量。</p>
<h3 id="广播变量">广播变量</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> <span class="type">int</span> <span class="variable">factor</span> <span class="operator">=</span> <span class="number">3</span>;</span><br><span class="line"><span class="keyword">final</span> Broadcast&lt;Integer&gt; factorBroadcast = sc.broadcast(factor);</span><br><span class="line">list&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line">JavaRDD&lt;Integer&gt; multipleNumbers = numbers.map(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">Function</span>&lt;Integer, Integer&gt;()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Integer <span class="title function_">call</span><span class="params">(Integer v1)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">      <span class="type">int</span> <span class="variable">factor</span> <span class="operator">=</span> factorBroadcast.value();</span><br><span class="line">      <span class="keyword">return</span> v1 * factor;</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<h3 id="递增变量">递增变量</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">final</span> Accumulator&lt;Integer&gt; sum = sc.accumulator(<span class="number">0</span>);</span><br><span class="line">list&lt;Integer&gt; numberList = Arrays.asList(<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">4</span>, <span class="number">5</span>);</span><br><span class="line">JavaRDD&lt;Integer&gt; numbers = sc.parallelize(numberList);</span><br><span class="line">numbers.foreach(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">VoidFunction</span>&lt;Integer&gt;()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">call</span><span class="params">(Integer t)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">      sum.add(t);</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">);</span><br><span class="line">System.out.println(sum.value());</span><br></pre></td></tr></table></figure>
<h2 id="spark-sql">Spark SQL</h2>
<hr />
<p>  Spark可以使用类似Hive的方式进行开发Spark应用，Spark
SQL支持多种数据源的数据输入且性能比Hive高出很多。</p>
<h3 id="sqlcontext">SQLContext</h3>
<p>  开发Spark
SQL应用，除了要构建一个SparkContext对象外，还需要构建Spark
SQL特有的SQLContext对象</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">SQLContext</span> <span class="variable">sqlContext</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SQLContext</span>(sc);</span><br></pre></td></tr></table></figure>
<h3 id="hivecontext">HiveContext</h3>
<p>  开发Spark
SQL应用时也可以使用SQLContext对象的子类HiveContext，HiveContext除了包括SQLContext提供的所有功能外，还可以使用HiveQL语法来编写和执行SQL、使用Hive中的UDF函数、从Hive表读取数据等。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">HiveContext</span> <span class="variable">hiveContext</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HiveContext</span>(sc.sc());</span><br></pre></td></tr></table></figure>
<p>当然使用HiveContext的前提是必须已经安装了Hive且HiveContext构造函数只接收SparkContext对象。</p>
<h2 id="dataframe">DataFrame</h2>
<hr />
<p>  DataFrame时Spark
SQL中的抽象化数据表示形式，可以形象理解为数据库中的表。DataFrame支持多种数据源来构建。DataFrame的创建有共同的load和save操作，在Save操作的时候，我们可以使用save方法的第二个参数来指定写操作的策略</p>
<table>
<colgroup>
<col style="width: 43%" />
<col style="width: 56%" />
</colgroup>
<thead>
<tr class="header">
<th style="text-align: center;">Sava Mode</th>
<th style="text-align: center;">简介</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td style="text-align: center;">SaveMode.ErrorIfExists（默认）</td>
<td
style="text-align: center;">如果目标位置已经存在数据，那么抛出一个异常</td>
</tr>
<tr class="even">
<td style="text-align: center;">SaveMode.Append</td>
<td
style="text-align: center;">如果目标位置已经存在数据，那么将新数据追加进去</td>
</tr>
<tr class="odd">
<td style="text-align: center;">SaveMode.Overwrite</td>
<td
style="text-align: center;">如果目标位置已经存在数据，那么将已经存在的数据删除，用新数据进行覆盖</td>
</tr>
<tr class="even">
<td style="text-align: center;">SaveMode.Ignore</td>
<td
style="text-align: center;">如果目标位置已经存在数据就忽略不做任何操作</td>
</tr>
</tbody>
</table>
<h3 id="parquet">parquet</h3>
<p>加载数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> sqlContext.read().format(<span class="string">&quot;parquet&quot;</span>).load(<span class="string">&quot;spark.parquet&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> sqlContext.read().parquet(<span class="string">&quot;spark.parquet&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>使用save方法写数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.write().format(<span class="string">&quot;parquet&quot;</span>).save(<span class="string">&quot;spark1&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="json">Json</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> sqlContext.read().format(<span class="string">&quot;json&quot;</span>).load(<span class="string">&quot;spark.json&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> sqlContext.read().json(<span class="string">&quot;hdfs://spark1:9000/spark.json&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">List&lt;String&gt; studentInfoJSONs = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;String&gt;();</span><br><span class="line">studentInfoJSONs.add(<span class="string">&quot;&#123;\&quot;name\&quot;:\&quot;Leo\&quot;, \&quot;age\&quot;:18&#125;&quot;</span>);  </span><br><span class="line">studentInfoJSONs.add(<span class="string">&quot;&#123;\&quot;name\&quot;:\&quot;Marry\&quot;, \&quot;age\&quot;:17&#125;&quot;</span>);  </span><br><span class="line">studentInfoJSONs.add(<span class="string">&quot;&#123;\&quot;name\&quot;:\&quot;Jack\&quot;, \&quot;age\&quot;:19&#125;&quot;</span>);</span><br><span class="line">JavaRDD&lt;String&gt; studentInfoJSONsRDD = sc.parallelize(studentInfoJSONs);</span><br><span class="line"><span class="type">DataFrame</span> <span class="variable">studentInfosDF</span> <span class="operator">=</span> sqlContext.read().json(studentInfoJSONsRDD);</span><br></pre></td></tr></table></figure>
<p>使用save方法写数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.write().format(<span class="string">&quot;json&quot;</span>).save(<span class="string">&quot;spark1.json&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>使用Json数据构建DataFrame，会使用Json中对象的键值作为表字段名来显示数据。</p>
<h3 id="hive">Hive</h3>
<p>  Spark SQL支持对Hive中存储的数据进行读写。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> hiveContext.sql(<span class="string">&quot;select * from table&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> hiveContext.table(<span class="string">&quot;table&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>使用saveAsTable方法写数据</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.saveAsTable(<span class="string">&quot;table&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="jdbc">JDBC</h3>
<p>  Spark SQL支持从关系型数据库中读取数据。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">Map&lt;String, String&gt; options = <span class="keyword">new</span> <span class="title class_">HashMap</span>&lt;String, String&gt;();</span><br><span class="line">options.put(<span class="string">&quot;url&quot;</span>, <span class="string">&quot;jdbc:mysql://spark1:3306/testdb&quot;</span>);</span><br><span class="line">options.put(<span class="string">&quot;dbtable&quot;</span>, <span class="string">&quot;spark&quot;</span>);</span><br><span class="line"><span class="type">DataFrame</span> <span class="variable">df</span> <span class="operator">=</span> sqlContext.read().format(<span class="string">&quot;jdbc&quot;</span>).options(options).load();</span><br></pre></td></tr></table></figure>
<h3 id="rdd">RDD</h3>
<p>  将RDD直接转换为DataFrame，可以使用任何数据源构建的RDD进行Spark
SQL操作，但是构建DataFrame我们需要知道数据的元数据，但是多数场景下我们并没有预先提供数据的元数据信息，所以需要动态绑定的方式构建RDD。</p>
<p>  当我们知道RDD的元数据时，我们使用反射来判断特定数据类型的RDD元数据，用作反射的JavaBean必须实现Serializable接口，表示可以被序列化的。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Student</span> <span class="keyword">implements</span> <span class="title class_">Serializable</span>&#123;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> id;</span><br><span class="line">  <span class="keyword">private</span> String name;</span><br><span class="line">  <span class="keyword">private</span> <span class="type">int</span> age;</span><br><span class="line">  <span class="keyword">public</span> <span class="title function_">Student</span><span class="params">(<span class="type">int</span> id, String name, <span class="type">int</span> age)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.id = id;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">    <span class="built_in">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getId</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> id;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setId</span><span class="params">(<span class="type">int</span> id)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.id = id;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> String <span class="title function_">getName</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> name;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setName</span><span class="params">(String name)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.name = name;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getAge</span><span class="params">()</span>&#123;</span><br><span class="line">    <span class="keyword">return</span> age;</span><br><span class="line">  &#125;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">setAge</span><span class="params">(<span class="type">int</span> age)</span>&#123;</span><br><span class="line">    <span class="built_in">this</span>.age = age;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RDD2DataFrame</span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">    <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;RDD2DataFrame&quot;</span>);</span><br><span class="line">    <span class="type">JavaSparkContext</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line">    <span class="type">SQLContext</span> <span class="variable">sqlContext</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SQLContext</span>(sc);</span><br><span class="line">    JavaRDD&lt;String&gt; lins = sc.textFile(<span class="string">&quot;spark.txt&quot;</span>);</span><br><span class="line">    JavaRDD&lt;Student&gt; studends = lines.map(</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">Function</span>&lt;String, Student&gt;()&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Student <span class="title function_">call</span><span class="params">(String lin)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">          <span class="keyword">return</span> <span class="keyword">new</span> <span class="title class_">Student</span>(Integer.valueOf(line.split(<span class="string">&quot;,&quot;</span>)[<span class="number">0</span>]), line.split(<span class="string">&quot;,&quot;</span>)[<span class="number">1</span>], Integer.valueOf(line.split(<span class="string">&quot;,&quot;</span>)[<span class="number">2</span>]));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    );</span><br><span class="line">    <span class="type">DataFrame</span> <span class="variable">studentDF</span> <span class="operator">=</span> sqlContext.createDataFrame(students, Student.class);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>  同样的，考虑这么一个场景，根据输入数据的不同，我们可以会在其他地方动态的获取RDD的元数据信息，然后去动态的构建一个DataFrame</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">RDD2DataFrame</span>&#123;</span><br><span class="line">  <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span>&#123;</span><br><span class="line">    <span class="type">SparkConf</span> <span class="variable">conf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SparkConf</span>().setMaster(<span class="string">&quot;local&quot;</span>).setAppName(<span class="string">&quot;RDD2DataFrame&quot;</span>);</span><br><span class="line">    <span class="type">JavaSparkContext</span> <span class="variable">sc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaSparkContext</span>(conf);</span><br><span class="line">    <span class="type">SQLContext</span> <span class="variable">sqlContext</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">SQLContext</span>(sc);</span><br><span class="line">    JavaRDD&lt;String&gt; lines = sc.textFile(<span class="string">&quot;spark.txt&quot;</span>);</span><br><span class="line">    JavaRDD&lt;Row&gt; studentRDD = lines.map(</span><br><span class="line">      <span class="keyword">new</span> <span class="title class_">Function</span>&lt;String, Row&gt;()&#123;</span><br><span class="line">        <span class="meta">@Override</span></span><br><span class="line">        <span class="keyword">public</span> Row <span class="title function_">call</span><span class="params">(String line)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">          String[] linePart = line.split(<span class="string">&quot;,&quot;</span>);</span><br><span class="line">          <span class="keyword">return</span> RowFactory.create(Integer.valueOf(linePart[<span class="number">0</span>]), linePart[<span class="number">1</span>], Integer.valueOf(linePart[<span class="number">2</span>]));</span><br><span class="line">        &#125;</span><br><span class="line">      &#125;</span><br><span class="line">    );</span><br><span class="line">    List&lt;StructField&gt; structFields = <span class="keyword">new</span> <span class="title class_">ArrayList</span>&lt;StructField&gt;();</span><br><span class="line">    structField.add(DataTypes.createStructField(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">true</span>));</span><br><span class="line">    structField.add(DataTypes.createStructField(<span class="string">&quot;name&quot;</span>, DataTypes.StringType, <span class="literal">true</span>));</span><br><span class="line">    structField.add(DataTypes.createStructField(<span class="string">&quot;age&quot;</span>, DataTypes.IntegerType, <span class="literal">true</span>));</span><br><span class="line">    <span class="type">StructType</span> <span class="variable">structType</span> <span class="operator">=</span> DataTypes.createStructType(structFields);</span><br><span class="line">    <span class="type">DataFrame</span> <span class="variable">studentDF</span> <span class="operator">=</span> sqlContext.createDataFrame(studentRDD, structType);</span><br><span class="line">  &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="dataframe操作">DataFrame操作</h2>
<hr />
<p>  在Spark
SQL应用开发中，构建好DataFrame后可以类似操作数据表一样操作和查询DataFrame，也可以使用DataFrame创建临时表进行SQL语句的查询。</p>
<h3 id="临时表">临时表</h3>
<p>  使用DataFrame可以注册实现一个临时的数据表供SQL语句的查询，该临时表并不是物理存在的，在应用运行结束后会动态销毁。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.registerTempTable(<span class="string">&quot;tempTable&quot;</span>);</span><br><span class="line"><span class="type">DataFrame</span> <span class="variable">newDf</span> <span class="operator">=</span> sqlContext.sql(<span class="string">&quot;select * from tempTable&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="show">show</h3>
<p>  对DataFrame进行show操作是展示所有DataFrame中的数据，类似于对数据表数据的展示。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.show();</span><br></pre></td></tr></table></figure>
<h3 id="printschema">printSchema</h3>
<p>  打印DataFrame的元数据信息</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.printSchema();</span><br></pre></td></tr></table></figure>
<h3 id="select">select</h3>
<p>  查询DataFrame中的列数据，查询一列</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.select(<span class="string">&quot;name&quot;</span>);</span><br></pre></td></tr></table></figure>
<p>或者查询多列</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.select(df.col(<span class="string">&quot;name&quot;</span>), df.col(<span class="string">&quot;age&quot;</span>));</span><br></pre></td></tr></table></figure>
<h3 id="filter-1">filter</h3>
<p>  DataFrame数据过滤</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.filter(df.col(<span class="string">&quot;age&quot;</span>).gt(<span class="number">18</span>));</span><br></pre></td></tr></table></figure>
<h3 id="groupby">groupBy</h3>
<p>  数据分组</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">df.groupBy(df.col(<span class="string">&quot;age&quot;</span>));</span><br></pre></td></tr></table></figure>
<h2 id="spark-streaming">Spark Streaming</h2>
<hr />
<p>  Spark
Streaming是Spark提供的一个实时计算的模块，它可以应用于大规模、高吞吐量、容错的实时数据流处理。</p>
<h3 id="sparkstreamingcontext">SparkStreamingContext</h3>
<hr />
<p>  要运行Spark
Streaming应用，必须创建一个SparkStreamingContext对象，SparkStreamingContext对象类似于SparkContext，和SparkContext不同的是，SparkStreamingContext对象除了接收一个SparkConf实例外，还需要接收一个整型参数，定义每收集多长时间的数据划分为一个batch</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">JavaStreamingContext</span> <span class="variable">jsc</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">JavaStreamingContext</span>(conf, Durations.seconds(<span class="number">1</span>));</span><br></pre></td></tr></table></figure>
<p>并且在实现计算过程后需要手动启动SparkStreamingContext进行数据流的监控</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">jsc.start();</span><br><span class="line">jsc.awaitTermination();</span><br></pre></td></tr></table></figure>
<h3 id="dstream">DStream</h3>
<hr />
<p>  DStream表示一个从数据源来的持续不断的实时数据流，根据SparkStreamingContext中设置的数据划分参数，将每隔一个单位时间接收到的数据流数据封装成一个DStream，并交给应用进行实时计算</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaReceiverInputDStream&lt;String&gt; lines = jsc.socketTextStream(<span class="string">&quot;local&quot;</span>, <span class="number">80</span>);</span><br></pre></td></tr></table></figure>
<p>使用socket的方式监听数据流，并封装到JavaReceiverInputDStream对象，可以理解JavaReceiverInputDStream为一个元素为String类型的RDD，然后可以直接进行RDD运算</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaDStream&lt;String&gt; words = lines.flatMap(</span><br><span class="line">  <span class="keyword">new</span> <span class="title class_">FlatMapFunction</span>&lt;String, String&gt;()&#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> Iterable&lt;String&gt; <span class="title function_">call</span><span class="params">(String t)</span> <span class="keyword">throws</span> Exception&#123;</span><br><span class="line">      <span class="keyword">return</span> Arrays.asList(t.split(<span class="string">&quot;&quot;</span>));</span><br><span class="line">    &#125;</span><br><span class="line">  &#125;</span><br><span class="line">);</span><br></pre></td></tr></table></figure>
<p>注意的是这里的RDD对象不再是之前的RDD，都变成DStream的形式。</p>
<h3 id="hdfs">Hdfs</h3>
<p>  将Hdfs作为Spark
Streaming的输入源比较特殊，该方式没有Receiver的参与，是对一个Hdfs目录的监控，只要出现新的文件就进行实时处理，并且目录中的每个文件只会处理一次</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line">JavaDStream&lt;String&gt; lines = jsc.textFileStream(<span class="string">&quot;hdfs://spark1:9000/spark&quot;</span>);</span><br></pre></td></tr></table></figure>
<h3 id="其他">其他</h3>
<p>  将其他的数据源作为Spark
Streaming的输入源时往往需要借助一些第三方开发的类包。</p>
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>Spark</tag>
      </tags>
  </entry>
  <entry>
    <title>机器学习中的特征工程</title>
    <url>/2017/06/13/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E7%89%B9%E5%BE%81%E5%B7%A5%E7%A8%8B/</url>
    <content><![CDATA[<p>  在机器学习算法中，算法的实现过程固然重要，但是作为算法训练的输入也决定算法好坏和算法预测结果准确性的重要因素。我们知道作为机器学习算法的输入是训练样本集，训练样本集中包含很多样本，并且每个样本都会有很多的特征作为机器学习算法的计算依据，所以在样本特征的选取和处理也显得格外重要。</p>
<p>  特征工程（Feature
Engineering）需要解决的问题就是将传统的数据内容处理为对算法有用的特征内容，包括文档的切词、值的二值化、分箱／分区、进行离散化等处理方式，本文重点介绍在机器学习领域常见的一些特征处理，包括特征的提取、转化和选择。</p>
<span id="more"></span>
<p>  在进行机器学习算法训练前的特征选择时，我们需要尽可能的考虑业务规则，即基于业务的理解去选择是否使用一个特征进行机器学习算法的训练，因为在算法训练的过程中，我们除了需要考虑算法的准确性外还应该考虑算法的训练和计算性能，如果选择一个无关的特征可能会对算法结果有影响和影响算法性能。此外在特征选择时我们还应该考虑特征在算法训练样本集中的覆盖率、准确率、信息量评估、差别性评估等，如果我们打算使用的特征需要及时去获取，那么我们还应该考虑该特征的获取难度，即对选择特征的可用性评估，我们不能捡了芝麻而丢了西瓜啊。</p>
<p>  接下来我们要做的就是进行特征的处理，包括数据的清洗和数据的预处理，根据我们选择的算法模型进行特征的处理工作，使特征更适合我们选择的算法模型。下面介绍几种常见的特征处理方式和实现方案：</p>
<h2 id="分词">分词</h2>
<hr />
<p>  分词是机器学习算法中简单常用的操作，例如将文档样本生成向量特征的时候经常会使用分词器进行文档的分词切割，常用的方法就是以空格作为分隔符将文档分隔成单词群。</p>
<h3 id="spark-mllib中实现">Spark Mllib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkTokenizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkTokenizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 Tokenizer 分词器以空格作为分隔符分隔文档</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 RegexTokenizer 分词器分词</span></span><br><span class="line"><span class="comment">         * 可以使用正则表达式的方式作为分隔符</span></span><br><span class="line"><span class="comment">         * 当设置 gaps 参数为 false 时正则表达式作用为提取关键词</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">RegexTokenizer</span> <span class="variable">regexTokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">RegexTokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                <span class="comment">//设置 gaps 参数</span></span><br><span class="line">                .setGaps(<span class="literal">false</span>)</span><br><span class="line">                .setPattern(<span class="string">&quot;\\\\W&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        wordsDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="停用词过滤">停用词过滤</h2>
<hr />
<p>  停用词是在进行分词的时候去除一些在文档中频繁出现，但是未携带太多意义的词语，因为这些没意义的单词不应该参与算法运算。</p>
<h3 id="spark-mllib中实现-1">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStopWordsRemover</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkStopWordsRemover&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line"></span><br><span class="line">        <span class="type">StopWordsRemover</span> <span class="variable">stopWordsRemover</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StopWordsRemover</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;filtered&quot;</span>)</span><br><span class="line">                <span class="comment">//设置停用词</span></span><br><span class="line">                <span class="comment">//.setStopWords(new String[]&#123;&quot;i&quot;, &quot;the&quot;, &quot;are&quot;&#125;)</span></span><br><span class="line">                <span class="comment">//设置是否区分大小写</span></span><br><span class="line">                .setCaseSensitive(<span class="literal">true</span>);</span><br><span class="line">        Dataset&lt;Row&gt; filteredDF = stopWordsRemover.transform(wordsDF);</span><br><span class="line">        filteredDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="tf-idf">TF-IDF</h2>
<hr />
<p>  TF-IDF（Term Frequency-Inverse Document
Frequency）被叫做词频-逆向文档频率。是一种在文本挖掘中广泛使用的特征向量化方法，用来反映一个单词在语料库文档中的重要性。</p>
<p>  我们把很多文档的集合叫做语料库，我们需要计算语料库文档中每个单词<span
class="math inline">\(t\)</span>在整个语料库文档中的权重度量用来表示该单词对于该类文档的重要性，通常我们使用概率来确定该度量信息，然后通过机器学习算法进行预测文档类别的时候，通过单词的权重来确定该文档更相似于语料库中哪篇文档来达到预测的目的。</p>
<h3 id="tf">TF</h3>
<p>  TF（Term Frequency）即词频，表示单词<span
class="math inline">\(t\)</span>在文档<span
class="math inline">\(d\)</span>中的的出现频率，所以有 <span
class="math display">\[
TF(t,d) = \frac{n_{t,d}}{\sum_k n_{k,d}}
\]</span></p>
<h3 id="idf">IDF</h3>
<p>  IDF（Inverse Document Frequency）即逆向文档频率，表示如果单词<span
class="math inline">\(t\)</span>在语料库中出现的频率极高，那么该词及有可能没有携带针对文档的某些特殊信息，例如的、是和我等词，所以我们需要降低该词的权重信息，我们将语料库表示为<span
class="math inline">\(D\)</span>，所以有 <span class="math display">\[
IDF(t,D) = log \frac {\mid D\mid}{\mid DF(t,D)\mid}
\]</span> 其中<span class="math inline">\(\mid
D\mid\)</span>表示为语料库中文档总数，<span class="math inline">\(\mid
DF(t,D)\mid\)</span>表示为单词<span
class="math inline">\(t\)</span>在语料库中出现的次数，为了避免分母为0的情况，所以公式更新为
<span class="math display">\[
IDF(t,D) = log \frac {\mid D\mid+1}{\mid DF(t,D)\mid+1}
\]</span> 因为取对数的缘故，当单词<span
class="math inline">\(t\)</span>出现在所有文档中时，<span
class="math inline">\(IDF(t,D)\)</span>的值为0，合理的下降了单词<span
class="math inline">\(t\)</span>的权重。</p>
<h3 id="tf-idf-1">TF-IDF</h3>
<p>  最终我们TF-IDF的结果会被表示为 <span class="math display">\[
TFIDF(t,d,D) = TF(t,d)·IDF(t,D)
\]</span></p>
<h3 id="spark-mllib中实现-2">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkTFIDF</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession.builder()</span><br><span class="line">                .appName(<span class="string">&quot;SparkTFIDF&quot;</span>)</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0.0</span>, <span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">0.0</span>, <span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1.0</span>, <span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;label&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; sentenceData = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>().setInputCol(<span class="string">&quot;sentence&quot;</span>).setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsData = tokenizer.transform(sentenceData);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 HashingTF 进行词频统计</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * HashingTF 运用 Hashing trick 方法进行进行特征降维处理</span></span><br><span class="line"><span class="comment">         * 哈希函数使用 murmurHash 3</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">HashingTF</span> <span class="variable">hashingTF</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">HashingTF</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;rawFeatures&quot;</span>)</span><br><span class="line">                <span class="comment">//设置为以二进制方式进行词频统计，即单词出现被记录为1，不出现记录为0</span></span><br><span class="line">                <span class="comment">//.setBinary(true)</span></span><br><span class="line">                <span class="comment">//设置输出维数，默认维数为 262144</span></span><br><span class="line">                .setNumFeatures(<span class="number">20</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 使用 CountVectorizer 进行词频统计</span></span><br><span class="line"><span class="comment">         *</span></span><br><span class="line"><span class="comment">         * CountVectorizer 是使用文档中单词计数的方式进行特征提取</span></span><br><span class="line"><span class="comment">         */</span></span><br><span class="line">        <span class="type">CountVectorizerModel</span> <span class="variable">countVectorizerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">CountVectorizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;rawFeatures&quot;</span>)</span><br><span class="line">                <span class="comment">//设置为以二进制方式进行词频统计，即单词出现被记录为1，不出现记录为0</span></span><br><span class="line">                <span class="comment">//.setBinary(true)</span></span><br><span class="line">                <span class="comment">//设置输出向量的结果维数，或理解为Top n的词列表</span></span><br><span class="line">                .setVocabSize(<span class="number">20</span>)</span><br><span class="line">                <span class="comment">//设置最小输出</span></span><br><span class="line">                .setMinDF(<span class="number">0</span>)</span><br><span class="line">                .fit(wordsData);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; featurizedData = hashingTF.transform(wordsData);</span><br><span class="line">        <span class="type">IDF</span> <span class="variable">idf</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IDF</span>().setInputCol(<span class="string">&quot;rawFeatures&quot;</span>).setOutputCol(<span class="string">&quot;features&quot;</span>);</span><br><span class="line">        <span class="type">IDFModel</span> <span class="variable">idfModel</span> <span class="operator">=</span> idf.fit(featurizedData);</span><br><span class="line">        Dataset&lt;Row&gt; rescaledData = idfModel.transform(featurizedData);</span><br><span class="line">        rescaledData.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="word2vec">Word2Vec</h2>
<hr />
<p>  word2vec是将一个文档用分布式特征向量的方式表示出来，便于在机器学习算法中进行文档相似度等计算。该方式将每个单词映射到一个唯一的固定维度大小的向量中，向量被表示为每个词在空间向量中的距离，可以理解为语义相似度。</p>
<h3 id="spark-mllib中实现-3">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkWord2Vec</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkWord2Vec&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>().setInputCol(<span class="string">&quot;sentence&quot;</span>).setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        <span class="type">Word2Vec</span> <span class="variable">word2Vec</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Word2Vec</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;result&quot;</span>)</span><br><span class="line">                <span class="comment">//设置最终输出的向量长度</span></span><br><span class="line">                .setVectorSize(<span class="number">3</span>)</span><br><span class="line">                <span class="comment">//因为有使用梯度下降算法计算最大似然估计，所以可以设置迭代次数</span></span><br><span class="line">                .setMaxIter(<span class="number">100</span>)</span><br><span class="line">                .setMinCount(<span class="number">0</span>);</span><br><span class="line">        <span class="type">Word2VecModel</span> <span class="variable">model</span> <span class="operator">=</span> word2Vec.fit(wordsDF);</span><br><span class="line">        Dataset&lt;Row&gt; result = model.transform(wordsDF);</span><br><span class="line">        result.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="n-gramn元模型">N-Gram（N元模型）</h2>
<hr />
<p>  n-gram被表示为一个长度为n的单词的序列，即将输入的特征值重新组合为以空格为分隔符的两个单词为单位的特征，常用的在Word2Vec中被用作上下文表示。例如[a,
b, c]会生成[a b, b c]，即输出某个单词在相对的语义环境中的表示。</p>
<h3 id="spark-mllib中实现-4">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkNGram</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkNGram&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Hi I heard about Spark&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;I wish Java could use case classes&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="string">&quot;Logistic regression models are neat&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;sentence&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; documentDF = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Tokenizer</span> <span class="variable">tokenizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Tokenizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;sentence&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;words&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; wordsDF = tokenizer.transform(documentDF);</span><br><span class="line">        <span class="type">NGram</span> <span class="variable">ngram</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">NGram</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;words&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;ngrams&quot;</span>)</span><br><span class="line">          		<span class="comment">//设置n的值</span></span><br><span class="line">                .setN(<span class="number">2</span>);</span><br><span class="line">        Dataset&lt;Row&gt; ngramDataFrame = ngram.transform(wordsDF);</span><br><span class="line">        ngramDataFrame.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="二值化binarizer">二值化（Binarizer）</h2>
<hr />
<p>  二值化是将特征值转化为二进制（0/1）的过程，在实际使用中我们需要确定一个阈值，如果特征值大于我们确定的阈值则特征被二值化为1，否则为0。</p>
<h3 id="spark-mllib中实现-5">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkBinarizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkBinarizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;feature&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; continuousDataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Binarizer</span> <span class="variable">binarizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Binarizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;feature&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;binarized_feature&quot;</span>)</span><br><span class="line">                .setThreshold(<span class="number">0.5</span>);</span><br><span class="line">        Dataset&lt;Row&gt; binarizedDataFrame = binarizer.transform(continuousDataFrame);</span><br><span class="line">        binarizedDataFrame.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="pca主元分析">PCA（主元分析）</h2>
<hr />
<p>  PCA（Principal Components
Analysis）即主成分分析，也叫主元分析。PCA在机器学习算法的经常在特征值降维中使用，就是将原本复杂的特征在不影响原信息表示的前提下从高维降至低维特征，使特征可以更方便的进行机器学习算法的计算。</p>
<blockquote>
<p>关于PCA原理和推导的文档：</p>
</blockquote>
<h3 id="spark-mllib中实现-6">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkPCA</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkPCA&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.sparse(<span class="number">5</span>, <span class="keyword">new</span> <span class="title class_">int</span>[]&#123;<span class="number">1</span>, <span class="number">3</span>&#125;, <span class="keyword">new</span> <span class="title class_">double</span>[]&#123;<span class="number">1.0</span>, <span class="number">7.0</span>&#125;)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">0.0</span>, <span class="number">3.0</span>, <span class="number">4.0</span>, <span class="number">5.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">4.0</span>, <span class="number">0.0</span>, <span class="number">0.0</span>, <span class="number">6.0</span>, <span class="number">7.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">PCAModel</span> <span class="variable">pca</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PCA</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;pcaFeatures&quot;</span>)</span><br><span class="line">                .setK(<span class="number">3</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; result = pca.transform(df);</span><br><span class="line">        result.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="多项式扩展">多项式扩展</h2>
<hr />
<p>  多项式扩展（Polynomial
expansion）也叫做多项式展开，是将特征从低维扩展为高维空间的过程。</p>
<h3 id="spark-mllib中实现-7">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkPoly</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkPoly&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">0.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">3.0</span>, -<span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line"></span><br><span class="line">        <span class="type">PolynomialExpansion</span> <span class="variable">polyExpansion</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">PolynomialExpansion</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;polyFeatures&quot;</span>)</span><br><span class="line">                .setDegree(<span class="number">3</span>);</span><br><span class="line">        Dataset&lt;Row&gt; polyDF = polyExpansion.transform(df);</span><br><span class="line">        polyDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="dct">DCT</h2>
<hr />
<p>  DCT（Discrete Cosine
Transform）即离散余弦变换，是将时域的N维实数序列转换为频域的N维实数序列</p>
<h3 id="spark-mllib中实现-8">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkDCT</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkDCT&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">1.0</span>, -<span class="number">2.0</span>, <span class="number">3.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(-<span class="number">1.0</span>, <span class="number">2.0</span>, <span class="number">4.0</span>, -<span class="number">7.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">14.0</span>, -<span class="number">2.0</span>, -<span class="number">5.0</span>, <span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line"></span><br><span class="line">        <span class="type">DCT</span> <span class="variable">dct</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">DCT</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;featuresDCT&quot;</span>)</span><br><span class="line">                .setInverse(<span class="literal">false</span>);</span><br><span class="line">        Dataset&lt;Row&gt; dctDf = dct.transform(df);</span><br><span class="line">        dctDf.select(<span class="string">&quot;featuresDCT&quot;</span>).show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="索引变换">索引变换</h2>
<hr />
<p>  索引变换有两种，一种是字符串到索引的变换，一种是索引到字符串的变换，简单理解就是将复杂的特征值变换为简单的按照特征值出现的频率排序的索引列表。</p>
<h3 id="spark-mllib中实现-9">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkIndex</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkIndex&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line"></span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="string">&quot;c&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;category&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 字符串到索引的变换</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">StringIndexer</span> <span class="variable">stringIndexer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryIndex&quot;</span>);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 索引到字符串的变换</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        <span class="type">IndexToString</span> <span class="variable">indexToString</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">IndexToString</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;index&quot;</span>);</span><br><span class="line"></span><br><span class="line">        Dataset&lt;Row&gt; categoryIndexDF = stringIndexer.fit(df).transform(df);</span><br><span class="line">        Dataset&lt;Row&gt; indexDF = indexToString.transform(categoryIndexDF);</span><br><span class="line">        indexDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="独热编码">独热编码</h2>
<hr />
<p>  独热编码（One-hot
encoding）是将一列标签索引映射到一列二进制向量，并且最多只有一个单值。</p>
<p>  独热编码往往被用来处理不是连续值的特征，如分类值等，因为算法分类器默认数据是连续的并且有序的，所以当输入特征随机分配的属性值或分类值时，我们需要找一种特征解决方案将这样的特征值进行变换。</p>
<p>  独热编码使用N位状态寄存器来对N个状态进行编码，每个状态都由他独立的寄存器位，并且在任意的时候其中只有一位有效，例如有以下特征
<span class="math display">\[
[male, female]
\]</span>
如果将上述特征用数字表示，在算法处理时效率会高很多，我们对该特征做简单的索引映射
<span class="math display">\[
[0,1]
\]</span>
因为分类器默认的算法数据是连续有序的，所以上述经过映射过的特征也不能直接在分类器中使用，我们采用独热编码的方式进行特征转换
<span class="math display">\[
[00, 10]
\]</span>
因此原来的特征内容被转换为一个稀疏特征，直接输入到分类器进行模型训练。</p>
<h3 id="spark-mllib中实现-10">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkOnehotEncode</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkOnehotEncode&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="string">&quot;b&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="string">&quot;c&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="string">&quot;a&quot;</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="string">&quot;c&quot;</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;category&quot;</span>, DataTypes.StringType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">StringIndexerModel</span> <span class="variable">indexer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StringIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;category&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; indexed = indexer.transform(df);</span><br><span class="line">        <span class="type">OneHotEncoder</span> <span class="variable">encoder</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">OneHotEncoder</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;categoryIndex&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;categoryVec&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; encoded = encoder.transform(indexed);</span><br><span class="line">        encoded.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="向量类型索引化">向量类型索引化</h2>
<hr />
<p>  向量类型索引化（Vector
Index）可以帮助指定向量数据集中的分类特征，它可以自动确定哪些特征值是分类的，并将原始值转换为类别索引。</p>
<p>  向量类型索引化的功能就是将特征中的类别特征重新进行编号，将向量内部原始的值离散化为索引值，用来提高决策树或随机森林等算法的模型分类效果。</p>
<h3 id="spark-mllib中实现-11">Spark MLlib中实现</h3>
<p>  在Spark
MLlib中，指定一列输入的向量列后需要指定maxCategrries参数，表明如果某个特征值不重复个数小于等于maxCategrries参数，那么VectorIndexer会将该特征进行从索引0开始的离散化操作。</p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkVectorIndexer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkVectorIndexer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">0.0</span>, <span class="number">0.0</span>)),</span><br><span class="line">                RowFactory.create(Vectors.dense(<span class="number">3.0</span>, -<span class="number">1.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">VectorIndexerModel</span> <span class="variable">vectorIndexerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorIndexer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;feat&quot;</span>)</span><br><span class="line">                .setMaxCategories(<span class="number">2</span>)</span><br><span class="line">                .fit(df);</span><br><span class="line">        Dataset&lt;Row&gt; featDF = vectorIndexerModel.transform(df);</span><br><span class="line">        featDF.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="相互作用">相互作用</h2>
<hr />
<p>  该特征变换采用两个向量类型的特征值进行变换后生成一个单个向量的特征，即将每个输入列中值的组合乘积后生成一个新的向量特征。</p>
<h3 id="spark-mllib中实现-12">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkInteraction</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkInteraction&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">4</span>, <span class="number">3</span>, <span class="number">8</span>, <span class="number">7</span>, <span class="number">9</span>, <span class="number">8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">3</span>, <span class="number">6</span>, <span class="number">1</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">6</span>),</span><br><span class="line">                RowFactory.create(<span class="number">4</span>, <span class="number">10</span>, <span class="number">8</span>, <span class="number">6</span>, <span class="number">9</span>, <span class="number">4</span>, <span class="number">5</span>),</span><br><span class="line">                RowFactory.create(<span class="number">5</span>, <span class="number">9</span>, <span class="number">2</span>, <span class="number">7</span>, <span class="number">10</span>, <span class="number">7</span>, <span class="number">3</span>),</span><br><span class="line">                RowFactory.create(<span class="number">6</span>, <span class="number">1</span>, <span class="number">1</span>, <span class="number">4</span>, <span class="number">2</span>, <span class="number">8</span>, <span class="number">4</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id1&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id2&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id3&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id4&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id5&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id6&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id7&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; df = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">VectorAssembler</span> <span class="variable">assembler1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorAssembler</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id2&quot;</span>, <span class="string">&quot;id3&quot;</span>, <span class="string">&quot;id4&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;vec1&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; assembled1 = assembler1.transform(df);</span><br><span class="line">        <span class="type">VectorAssembler</span> <span class="variable">assembler2</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">VectorAssembler</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id5&quot;</span>, <span class="string">&quot;id6&quot;</span>, <span class="string">&quot;id7&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;vec2&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; assembled2 = assembler2.transform(assembled1).select(<span class="string">&quot;id1&quot;</span>, <span class="string">&quot;vec1&quot;</span>, <span class="string">&quot;vec2&quot;</span>);</span><br><span class="line">        <span class="type">Interaction</span> <span class="variable">interaction</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Interaction</span>()</span><br><span class="line">                .setInputCols(<span class="keyword">new</span> <span class="title class_">String</span>[]&#123;<span class="string">&quot;id1&quot;</span>,<span class="string">&quot;vec1&quot;</span>,<span class="string">&quot;vec2&quot;</span>&#125;)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;interactedCol&quot;</span>);</span><br><span class="line">        Dataset&lt;Row&gt; interacted = interaction.transform(assembled2);</span><br><span class="line">        interacted.show(<span class="literal">false</span>);</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="泛数p-norm规范化">泛数p-norm规范化</h2>
<hr />
<p>  p-norm即p-泛数，机器学习算法中对特征进行P-泛数规范化操作，使得算法有更好的表现。</p>
<p>  p-泛数的定义在自定义p值的前提下进行泛数计算，常用的为2-泛数，即<span
class="math inline">\(L^2\)</span>，单位P-泛数的定义为 <span
class="math display">\[
\mid\mid x \mid\mid_p = (\mid x_1\mid^p + \mid x_2 \mid^p+\cdots+\mid
x_n\mid^p)^{\frac1p}
\]</span> 当p取1，2和<span
class="math inline">\(\infty\)</span>时的三种简单情形 <span
class="math display">\[
\begin{align}
&amp; 1-泛数(L^1):\mid\mid x \mid\mid = \mid x_1\mid + \mid x_2
\mid+\cdots+\mid x_n\mid
\\
&amp; 2-泛数(L^2):\mid\mid x \mid\mid_2 = (\mid x_1\mid^2 + \mid x_2
\mid^2+\cdots+\mid x_n\mid^2)^{\frac12}
\\
&amp; \infty-泛数(L^\infty):\mid\mid x \mid\mid_\infty =max (\mid
x_1\mid, \mid x_2 \mid,\cdots+\mid x_n\mid)
\end{align}
\]</span>
  对某个特征进行P-泛数规范即将该特征组成的特征向量计算其P-泛数，然后对特征向量中的每个元素除以P-泛数后组成新的特征向量。</p>
<h3 id="spark-mllib中实现-13">Spark MLlib中实现</h3>
<p><figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkNormalizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkNormalizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; l1NormData = normalizer.transform(dataFrame);</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.0 / ( |1.0| + |0.1| + |-8.0| ) 0.1 / ( |1.0| + |0.1| + |-8.0| ) -0.8 / ( |1.0| + |0.1| + |-8.0| )</span></span><br><span class="line"><span class="comment">         * 2.0 / ( |2.0| + |1.0| + |-4.0| ) 1.0 / ( |2.0| + |1.0| + |-4.0| ) -4.0 / ( |2.0| + |1.0| + |-4.0| )</span></span><br><span class="line"><span class="comment">         * 4.0 / ( |4.0| + |10.0| + |8.0| ) 10.0/ ( |4.0| + |10.0| + |8.0| )  8.0 / ( |4.0| + |10.0| + |8.0| )</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        l1NormData.show(<span class="literal">false</span>);</span><br><span class="line">        Dataset&lt;Row&gt; lInfNormData = normalizer.transform(dataFrame, normalizer.p().w(Double.POSITIVE_INFINITY));</span><br><span class="line">        <span class="comment">/**</span></span><br><span class="line"><span class="comment">         * 1.0 / max(1.0, 0.1, -8.0) ...</span></span><br><span class="line"><span class="comment">         * ...</span></span><br><span class="line"><span class="comment">         * */</span></span><br><span class="line">        lInfNormData.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></p>
<h2 id="z-score规范化">z-score规范化</h2>
<hr />
<p>  z-score规范化或称作零均值规范化是将特征进行基于特征值均值和标准差进行规范化的操作。特征v的z-score规范化被表示为
<span class="math display">\[
v`=\frac{v_i-avg_v}{\delta_v}
\]</span> 其中<span
class="math inline">\(avg_v\)</span>为特征v的平均值，<span
class="math inline">\(\delta_v\)</span>为特征的标准差。</p>
<p>  当特征v的最大值和最小值未知或有离群点影响最大最小规范化时z-score规范化是一个有效的特征规范化手段。</p>
<h3 id="spark-mllib中实现-14">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkStandardScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkStandardScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">StandardScalerModel</span> <span class="variable">standardScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StandardScaler</span>()</span><br><span class="line">                <span class="comment">//是否启用均值计算，将均值移到0，对稀疏矩阵不可用</span></span><br><span class="line">                .setWithMean(<span class="literal">false</span>)</span><br><span class="line">                <span class="comment">//是否将方差缩放到1</span></span><br><span class="line">                .setWithStd(<span class="literal">true</span>)</span><br><span class="line">          		.setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = standardScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="最大-最小规范化">最大-最小规范化</h2>
<hr />
<p>  最大-最小规范化是将特征向量的值线性地变换到指定最大-最小值之间。经常的我们在使用算法进行模型训练的时候，因为每个特征的取值大小不同或差距很大，这导致在算法训练的时候数值较大的特征对模型结果起决定性作用，为了解决这种问题所以引入最大最小规范化的特征处理方式，该方式使得特征值最后落在<span
class="math inline">\([0, 1]\)</span>范围内。</p>
<p>  常用的最大-最小规范化方式为 <span class="math display">\[
newValue=\frac{oldValue-minValue}{maxValue-minValue}\times
(E_{max}-E_{min})+E_{min}
\]</span> 其中<span class="math inline">\(E_{max}\)</span>和<span
class="math inline">\(E_{min}\)</span>是指定的区间范围。</p>
<h3 id="spark-mllib中实现-15">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkMinMaxScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkMinMaxScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">MinMaxScalerModel</span> <span class="variable">minMaxScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MinMaxScaler</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = minMaxScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="绝对值规范化">绝对值规范化</h2>
<hr />
<p>  绝对值规范化是将各个特征值除以该特征的最大绝对值，因此可以将特征值缩放到<span
class="math inline">\([-1,1]\)</span>之间，并且不会移动和居中中心点，所以不会破坏向量的稀疏性。但是唯一需要考虑的就是如果该最大绝对值是一个利群点，这种规范化方式就会很不合理。</p>
<h3 id="spark-mllib中实现-16">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkMaxAbsScaler</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkMaxAbsScaler&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, Vectors.dense(<span class="number">1.0</span>, <span class="number">0.1</span>, -<span class="number">8.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, Vectors.dense(<span class="number">2.0</span>, <span class="number">1.0</span>, -<span class="number">4.0</span>)),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, Vectors.dense(<span class="number">4.0</span>, <span class="number">10.0</span>, <span class="number">8.0</span>))</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;features&quot;</span>, <span class="keyword">new</span> <span class="title class_">VectorUDT</span>(), <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; dataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">MaxAbsScalerModel</span> <span class="variable">maxAbsScalerModel</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">MaxAbsScaler</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;features&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;scalerFeat&quot;</span>)</span><br><span class="line">                .fit(dataFrame);</span><br><span class="line">        Dataset&lt;Row&gt; scalerDF = maxAbsScalerModel.transform(dataFrame);</span><br><span class="line">        scalerDF.show(<span class="literal">false</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="分箱器">分箱器</h2>
<hr />
<p>  分箱器是将连续的特征值按照我们提供的数值区间按照<span
class="math inline">\([x,y)\)</span>进行切割，输出区间索引并生成新的特征。</p>
<h3 id="spark-mllib中实现-17">Spark MLlib中实现</h3>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">SparkBinarizer</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">SparkSession</span> <span class="variable">spark</span> <span class="operator">=</span> SparkSession</span><br><span class="line">                .builder()</span><br><span class="line">                .master(<span class="string">&quot;local&quot;</span>)</span><br><span class="line">                .appName(<span class="string">&quot;SparkBinarizer&quot;</span>)</span><br><span class="line">                .getOrCreate();</span><br><span class="line">        List&lt;Row&gt; data = Arrays.asList(</span><br><span class="line">                RowFactory.create(<span class="number">0</span>, <span class="number">0.1</span>),</span><br><span class="line">                RowFactory.create(<span class="number">1</span>, <span class="number">0.8</span>),</span><br><span class="line">                RowFactory.create(<span class="number">2</span>, <span class="number">0.2</span>)</span><br><span class="line">        );</span><br><span class="line">        <span class="type">StructType</span> <span class="variable">schema</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">StructType</span>(<span class="keyword">new</span> <span class="title class_">StructField</span>[]&#123;</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;id&quot;</span>, DataTypes.IntegerType, <span class="literal">false</span>, Metadata.empty()),</span><br><span class="line">                <span class="keyword">new</span> <span class="title class_">StructField</span>(<span class="string">&quot;feature&quot;</span>, DataTypes.DoubleType, <span class="literal">false</span>, Metadata.empty())</span><br><span class="line">        &#125;);</span><br><span class="line">        Dataset&lt;Row&gt; continuousDataFrame = spark.createDataFrame(data, schema);</span><br><span class="line">        <span class="type">Binarizer</span> <span class="variable">binarizer</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Binarizer</span>()</span><br><span class="line">                .setInputCol(<span class="string">&quot;feature&quot;</span>)</span><br><span class="line">                .setOutputCol(<span class="string">&quot;binarized_feature&quot;</span>)</span><br><span class="line">                .setThreshold(<span class="number">0.5</span>);</span><br><span class="line">        Dataset&lt;Row&gt; binarizedDataFrame = binarizer.transform(continuousDataFrame);</span><br><span class="line">        binarizedDataFrame.show();</span><br><span class="line">        spark.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<h2 id="hadamard乘积">Hadamard乘积</h2>
<hr />
<p>  将我们输入的每个向量乘以一个指定的权重向量来生成一个新的向量值。</p>
<h2 id="向量切片机">向量切片机</h2>
<hr />
<h2 id="r模型公式">R模型公式</h2>
<hr />
<h2 id="卡方特征选择器">卡方特征选择器</h2>
<hr />
<h2 id="局部敏感哈希">局部敏感哈希</h2>
<hr />
<h2 id="lsh运算">LSH运算</h2>
<hr />
<h2 id="lsh算法">LSH算法</h2>
<hr />
]]></content>
      <categories>
        <category>大数据</category>
      </categories>
      <tags>
        <tag>TF-IDF</tag>
      </tags>
  </entry>
  <entry>
    <title>Play Framework入门</title>
    <url>/2017/09/15/Play-Framework%E5%85%A5%E9%97%A8/</url>
    <content><![CDATA[<blockquote>
<p>博主环境（本文只讨论Play在Java下的开发）</p>
<p>JDK：1.8</p>
<p>Play：2.6</p>
</blockquote>
<h2 id="play是什么">Play是什么？</h2>
<hr />
<p>  Play是一种高效率的Java和Scala程序语言的Web应用开发框架，Play自身继承了所有Web应用程序开发需要的组件和API。</p>
<p>  Play框架被官方描述为轻量级、无状态、网络友好的框架，并且具有可预测和消耗最少资源，适用于可扩展的应用程序。</p>
<span id="more"></span>
<h2 id="创建一个新应用">创建一个新应用</h2>
<hr />
<p>  Play框架在<code>2.6</code>版本中是由sbt管理的，并且sbt工具版本需要<code>0.13.13</code>或更高，并且JDK版本必须为<code>1.8</code>。</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line">sbt <span class="keyword">new</span> playframework/<span class="keyword">play</span>-java-seed.g8</span><br></pre></td></tr></table></figure>
<p>初次运行该命令可能会下载许多第三方依赖，如果失败需要重试，直到下面的步骤</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line">This template generates a <span class="keyword">Play</span> Java project </span><br><span class="line"># 项目名称</span><br><span class="line"><span class="keyword">name</span> [<span class="keyword">play</span>-java-seed]: HelloPlay</span><br><span class="line"># 组织名称</span><br><span class="line">organization [<span class="keyword">com</span>.example]: <span class="keyword">com</span>.vnicl</span><br><span class="line"># 使用scala的版本，直接回车则使用默认版本</span><br><span class="line">scala_version [<span class="number">2.12</span>.<span class="number">2</span>]: </span><br><span class="line"># 使用<span class="keyword">play</span>的版本，直接回车则使用默认版本</span><br><span class="line">play_version [<span class="number">2.6</span>.<span class="number">5</span>]: </span><br></pre></td></tr></table></figure>
<p>然后进入项目根目录，运行<code>run</code>命令即可在浏览器中预览</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line">cd ./HelloPlay</span><br><span class="line"># 当前环境JDK版本必须为<span class="number">1.8</span>，否则会抛出错误：Unsupported major.minor version <span class="number">52.0</span></span><br><span class="line">sbt <span class="keyword">run</span></span><br></pre></td></tr></table></figure>
<p>也可以进入sbt控制台进行预览</p>
<figure class="highlight basic"><table><tr><td class="code"><pre><span class="line">cd ./HelloPlay</span><br><span class="line">sbt</span><br><span class="line"># 指定Web服务端口，默认端口为<span class="number">9000</span></span><br><span class="line">[HelloPlay] $ <span class="keyword">run</span> <span class="number">8080</span></span><br></pre></td></tr></table></figure>
<h2 id="项目结构解析">项目结构解析</h2>
<hr />
<h3 id="app">app</h3>
<p>  该目录包含可执行的项目源代码，默认里面包括三个包</p>
<table>
<thead>
<tr class="header">
<th>目录</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>app/controllers</td>
<td>所有类库源代码</td>
</tr>
<tr class="even">
<td>app/models</td>
<td>模型文件</td>
</tr>
<tr class="odd">
<td>app/views</td>
<td>视图文件</td>
</tr>
</tbody>
</table>
<h3 id="public">public</h3>
<p>  该目录包括所有的Web服务需要的静态资源，默认爆款三个文件夹</p>
<table>
<thead>
<tr class="header">
<th>目录</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>public/images</td>
<td>静态图片资源</td>
</tr>
<tr class="even">
<td>public/javascripts</td>
<td>视图文件需要引入的JS资源</td>
</tr>
<tr class="odd">
<td>public/stylesheets</td>
<td>视图文件需要引入的CSS样式表资源</td>
</tr>
</tbody>
</table>
<h3 id="conf">conf</h3>
<p>  该目录包含应用程序的配置文件，主要为下面两个配置文件</p>
<table>
<thead>
<tr class="header">
<th>文件</th>
<th>作用</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>conf/application.conf</td>
<td>应用的主配置文件</td>
</tr>
<tr class="even">
<td>conf/routes</td>
<td>静态路由定义文件</td>
</tr>
</tbody>
</table>
<h3 id="lib">lib</h3>
<p>  此目录包含没有通过sbt托管的依赖库，即任何第三方开发的Jar包。该目录下的所有Jar文件会自动添加到应用程序的类路径中。</p>
<h2 id="play中的mvc">Play中的MVC</h2>
<hr />
<p>  跟常规的MVC框架类似，在Play中，一个自定义的扩展类被称为一个控制器，该类中可以定义处理Web请求的方法并返回一个请求结果返回。</p>
<p>  一个控制器须要继承自<code>play.mvc.Controller</code>，<code>Controller</code>类中实现了常用的以下方法供使用</p>
<p>继承了<code>play.mvn.Results</code>，</p>
<p>控制器中的一个操作必须返回一个<code>play.mvc.Result</code>对象作为该操作的响应。</p>
]]></content>
      <categories>
        <category>JAVA</category>
      </categories>
      <tags>
        <tag>Play2</tag>
      </tags>
  </entry>
  <entry>
    <title>曲线拟合原理和实现</title>
    <url>/2018/10/10/%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/</url>
    <content><![CDATA[<h2 id="概述">概述</h2>
<hr />
<p>  现实世界中，变量间未必都有线性关系，如服药后血药浓度与时间的关系、疾病疗效与疗程长短的关系和毒物剂量与致死率的关系等常呈曲线关系。曲线拟合（Curve
Fitting）是指选择适当的曲线类型来拟合观测数据，并用拟合的<code>曲线方程</code>分析两变量间的关系。</p>
<p>  实际工作中，我们通过统计或实验观察得到一组可以在二维坐标系中表示的点<span
class="math inline">\((x_i, y_i)\)</span>，其中<span
class="math inline">\(x_i\)</span>为自变量，<span
class="math inline">\(y_i\)</span>为因变量，用二维散点图的方式绘制出来如下</p>
<center>
<img src="/2018/10/10/%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/sdt.png" class="" title="以散点图的方式表示在二维坐标系中的数据">
</center>
<p>曲线拟合的目的即寻找可以连续并近似地刻画或比拟该二维坐标系中所有离散点的一条曲线，表示所有离散点和坐标系之间直接的一种函数关系<span
class="math inline">\(y_i=f(x_i,
c_m)\)</span>。该曲线函数即我们需要找到的拟合函数，包括自变量<span
class="math inline">\(x_i\)</span>和<span
class="math inline">\(m\)</span>个拟合系数<span
class="math inline">\(c_m\)</span>组成，不同的拟合方式会有不同的拟合系数产生，所以曲线拟合就是求最优的拟合系数的问题。该拟合函数也被称为<code>拟合模型</code>。
<span id="more"></span>
  在日常工作生产中一般使用的拟合函数为<code>线形拟合</code>、<code>对数</code>、<code>多项式</code>、<code>幂函数</code>、<code>指数</code>和<code>移动平均</code>等几种，不同的拟合方式最终的结果亦不相同，需要根据提供离散数据组的分布和业务状况进行选择。其实很多数据软件中通常已经封装了曲线拟合的功能，以下展示分别为样例离散数据在<code>MacOs</code>系统中的<code>Number表格</code>实现的效果。</p>
<center>
<img src="/2018/10/10/%E6%9B%B2%E7%BA%BF%E6%8B%9F%E5%90%88%E5%8E%9F%E7%90%86%E5%92%8C%E5%AE%9E%E7%8E%B0/slqxnh.png" class="" title="曲线拟合示例">
</center>
<p>  由于该拟合模型会有不同个数的拟合系数<span
class="math inline">\(c_m\)</span>，并且最终的拟合模型也只能近似的拟合所有离散数据点，所以就涉及到一个最优化解的过程，故曲线拟合也是一个求最优结果的优化问题。最优化理论在人工智能领域频繁的被提及，所有机器学习相关算法其实都是最优化问题。在工程上常用的求最优解的方式有两种，<code>梯度</code>和<code>最小二乘法</code>，梯度的概念在之前的几篇文章中都有提及，如<a href="/2017/05/09/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BA/" title="支持向量机 (SVM)">支持向量机 (SVM)</a>等。在做拟合实践之前我们先来了解一下<code>最小二乘法</code>。</p>
<h2 id="最小二乘法">最小二乘法</h2>
<hr />
<p>  <code>最小二乘法</code>是一种优化技术，其中<code>最小</code>表现为在所求内容（可以理解为算法预测结果）与真实数据的误差达到最小，该优化技术也由该点出发，常用的误差计算方式为<code>残差平方和</code>，即
<span class="math display">\[
\epsilon = \sum_{i=1}^n{(f(x_i) - y_i)^2}
\]</span> 其中<span
class="math inline">\(f(x_i)\)</span>表示预测值，最小二乘法是通过最小化误差的平方和寻找数据的最佳函数匹配；而<code>二乘</code>的意思个人理解为在该优化技术最后会将待求解的最佳函数以矩阵的方式表现为两个矩阵的乘法，以方便最后<code>超参数</code>或<code>拟合系数</code>的计算。</p>
<p>  假定我们当前有一个超定方程组 <span class="math display">\[
\begin{equation}
\sum_{j=1}^nx_i^j\alpha_j = y_i \\
\begin{pmatrix}
i=1,2,3\cdots m \\
j=1,2,3\cdots n \\
\end{pmatrix}
\end{equation}
\]</span> 可以这样理解该超定方程组，<span
class="math inline">\(x_i^j\)</span>表示一个包含<span
class="math inline">\(n\)</span>个特征的<span
class="math inline">\(m\)</span>个样本数据如下： <span
class="math display">\[
\begin{pmatrix}
x_1^1 &amp; x_1^2 &amp; \cdots &amp; x_1^n \\
x_2^1 &amp; x_2^2 &amp; \cdots &amp; x_2^n \\
\vdots &amp; \ddots &amp; \vdots  &amp; \vdots \\
x_m^1 &amp; x_m^2 &amp; \cdots &amp; x_m^n \\
\end{pmatrix}
\]</span> <span
class="math inline">\(\alpha_j\)</span>表示待求的最优系数，<span
class="math inline">\(y_i\)</span>则是因变量，方程组如下： <span
class="math display">\[
\begin{pmatrix}
x_1^1\times\alpha_1 + x_1^2\times\alpha_2 &amp; \cdots &amp;
x_1^n\times\alpha_n = y_1 \\
x_2^1\times\alpha_1 + x_2^2\times\alpha_2 &amp; \cdots &amp;
x_2^n\times\alpha_n = y_2 \\
\vdots &amp; \ddots  &amp; \vdots \\
x_m^1\times\alpha_1 + x_m^2\times\alpha_2 &amp; \cdots &amp;
x_m^n\times\alpha_n = y_m \\
\end{pmatrix}
\]</span> 其中<span class="math inline">\(m\)</span>表示有<span
class="math inline">\(m\)</span>个等式，<span
class="math inline">\(n\)</span>表示有<span
class="math inline">\(n\)</span>个未知数<span
class="math inline">\(\alpha\)</span>，并且<span class="math inline">\(m
\gt n\)</span>，根据向量的特性，将该超定方程组向量化后为<span
class="math inline">\(x\alpha=y\)</span>（二乘） <span
class="math display">\[
x=\begin{bmatrix}
x_1^1 &amp; x_1^2 &amp; \cdots &amp; x_1^n \\
x_2^1 &amp; x_2^2 &amp; \cdots &amp; x_2^n \\
\vdots &amp; \ddots &amp; \vdots  &amp; \vdots \\
x_m^1 &amp; x_m^2 &amp; \cdots &amp; x_m^n \\
\end{bmatrix}
,\alpha=\begin{bmatrix}
\alpha_1 \\
\alpha_2 \\
\vdots \\
\alpha_n \\
\end{bmatrix}
,y=\begin{bmatrix}
y_1 \\
y_2 \\
\vdots \\
y_n \\
\end{bmatrix}
\]</span>
接下来我们用最小二乘法求解该方程组，根据上面提到的<code>最小</code>的最优理论，运用残差平方和则有
<span class="math display">\[
\epsilon(\alpha) = ||x\alpha-y||^2
\]</span> 我们的目的是使的<span
class="math inline">\(\epsilon(\alpha)\)</span>最小，对该函数进行微分求极值则有
<span class="math display">\[
x^Tx\times\hat \alpha=x^Ty
\]</span> 其中<span class="math inline">\(\hat
\alpha\)</span>表示当<span class="math inline">\(\alpha=\hat
\alpha\)</span>时，函数$() <span
class="math inline">\(取最小值，\)</span>$ = argmin(() ) <span
class="math display">\[
根据矩阵的特点，如果矩阵$x^Tx$非奇异则$\hat \alpha$有唯一解
\]</span> =(x<sup>Tx)</sup>{-1}x^Ty $$</p>
<h2 id="线性拟合">线性拟合</h2>
<hr />
<p>  所谓<code>线性拟合</code>意思为考虑最终的拟合模型表达式为 <span
class="math display">\[
f(a,b)=a+bx
\]</span> 假设给定一批离散数据如 <span class="math display">\[
\begin{equation}
(x_i,y_i) \\
i=1,2,3\cdots m \\
\end{equation}
\]</span> 即表示以<span
class="math inline">\(m\)</span>个数据点做曲线拟合。运用上面提到的最小二乘法的最优技术，使平方误差最小
<span class="math display">\[
\begin{equation}\begin{split}
\epsilon(a,b) &amp;=\sum_{i=1}^m(f(a,b) - y_i)^2 \\
&amp;=\sum_{i=1}^m(a+bx_i- y_i)^2 \\
\end{split}\end{equation}
\]</span> 运用微积分知识，计算<span
class="math inline">\(\epsilon(a,b)\)</span>的极小值要满足如下（分别对<span
class="math inline">\(a,b\)</span>求偏导数） <span
class="math display">\[
\begin{equation}\begin{split}
\frac {\partial \epsilon(a,b)} {\partial a}
&amp;=2\sum_{i=1}^m(a+bx_i-y_i) \\
&amp;=\sum_{i=1}^m(a+bx_i-y_i) \\
&amp;=0 \\
\frac {\partial \epsilon(a,b)} {\partial a}
&amp;=2\sum_{i=1}^m(a+bx_i-y_i)x_i \\
&amp;=\sum_{i=1}^m(a+bx_i-y_i)x_i \\
&amp;=0 \\
\end{split}\end{equation}
\]</span> 将上面的内容整理成矩阵的形式（二乘）如下 <span
class="math display">\[
\begin{pmatrix}
m &amp; \sum_{i=1}^m  x_i  \\
\sum_{i=1}^mx_i &amp; \sum_{i=1}^mx_i^2 \\
\end{pmatrix}
\times
\begin{pmatrix}
a \\
b \\
\end{pmatrix}
=
\begin{pmatrix}
\sum_{i=1}^my_i  \\
\sum_{i=1}^mx_iy_i \\
\end{pmatrix}
\]</span> 用消元法或克莱姆方法解出方程 <span class="math display">\[
\begin{equation}\begin{split}
a = &amp; \{\sum_{i=1}^my_i\sum_{i=1}^mx_i^2 -
\sum_{i=1}^mx_i\sum_{i=1}^mx_iy_i\} \div
\{m\sum_{i=1}^mx_i^2-(\sum_{i=1}^mx_i)^2\} \\
b = &amp; \{m\sum_{i=1}^mx_iy_i - \sum_{i=1}^mx_i\sum_{i=1}^my_i\} \div
\{m\sum_{i=1}^mx_i^2-(\sum_{i=1}^mx_i)^2\}
\end{split}\end{equation}
\]</span> 其中 <span class="math display">\[
\begin{equation}\begin{split}
m=&amp; 离散点的数量\\
\sum_{i=1}^mx_i=&amp; x_1+x_2+x_3 \cdots+x_i \\
\sum_{i=1}^my_i=&amp; y_1+y_2+y_3+\cdots+y_i\\
\sum_{i=1}^mx_i^2=&amp; x_1^2 + x_2^2+x_3^2 + \cdots+x_i^2\\
\sum_{i=1}^mx_iy_i=&amp; x_1y_1+x_2y_2+x_3y_3+\cdots + x_iy_i\\
\end{split}\end{equation}
\]</span></p>
<figure class="highlight java"><table><tr><td class="code"><pre><span class="line"><span class="type">double</span>[] x = <span class="keyword">new</span> <span class="title class_">double</span>[]&#123;<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, ··· ···, m&#125;;</span><br><span class="line"><span class="type">double</span>[] y = <span class="keyword">new</span> <span class="title class_">double</span>[]&#123;<span class="number">0.628289474</span>, <span class="number">0.537257824</span>, <span class="number">0.510469314</span>, ··· ···, <span class="number">0.441730635</span>&#125;;</span><br><span class="line"></span><br><span class="line"><span class="type">double</span> <span class="variable">sumX</span> <span class="operator">=</span> <span class="number">0d</span>;</span><br><span class="line"><span class="type">double</span> <span class="variable">sumY</span> <span class="operator">=</span> <span class="number">0d</span>;</span><br><span class="line"><span class="type">double</span> <span class="variable">sumXX</span> <span class="operator">=</span> <span class="number">0d</span>;</span><br><span class="line"><span class="type">double</span> <span class="variable">sumXY</span> <span class="operator">=</span> <span class="number">0d</span>;</span><br><span class="line"><span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; x.length; i ++)&#123;</span><br><span class="line">    sumX += x[i];</span><br><span class="line">  	sumY += y[i];</span><br><span class="line">  	sumXX += Math.pow(x[i], <span class="number">2d</span>);</span><br><span class="line">  	sumXY += x[i] * y[i];</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="type">double</span> <span class="variable">a</span> <span class="operator">=</span> (sumY * sumXX - sumX * sumXY) / (x.length * sumXX - Math.pow(sumX, <span class="number">2d</span>));</span><br><span class="line"><span class="type">double</span> <span class="variable">b</span> <span class="operator">=</span> (x.length * sumXY - sumX * sumY) / (x.length * sumXX - Math.pow(sumX, <span class="number">2d</span>));</span><br><span class="line"><span class="comment">//f(x) = a + bx</span></span><br><span class="line">System.out.println(<span class="string">&quot;f(x) = &quot;</span> + a + <span class="string">&quot; + &quot;</span> + b + <span class="string">&quot;x&quot;</span>);</span><br></pre></td></tr></table></figure>
<h2 id="幂函数拟合">幂函数拟合</h2>
<hr />
<p>待出稿</p>
<h2 id="多项式拟合">多项式拟合</h2>
<hr />
<p>待出稿</p>
<h2 id="拟合优度">拟合优度</h2>
<hr />
<p>待出稿</p>
]]></content>
      <categories>
        <category>算法应用</category>
      </categories>
      <tags>
        <tag>曲线拟合</tag>
        <tag>最小二乘法</tag>
        <tag>幂函数拟合</tag>
        <tag>多项式拟合</tag>
      </tags>
  </entry>
</search>
